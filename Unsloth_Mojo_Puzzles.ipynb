{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daver987/unsloth-mojo/blob/main/Unsloth_Mojo_Puzzles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unsloth Challenge Mapped to Mojo/Max"
      ],
      "metadata": {
        "id": "KmcSP-PxTAKK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uwPWn_fCGFo"
      },
      "source": [
        "We're still hiring on a rolling basis (interns, junior engs, senior)\n",
        "### Email me daniel at unsloth ai with your resume, Github repo, what you wanna work on, your past experience on projects (uni included). Do apply if you have implemented Llama in PyTorch from scratch :)\n",
        "\n",
        "### ðŸ¦¥ Unsloth is growing! Come join us :)\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a>\n",
        "\n",
        "Up to $500K USD salary + bonus equity, health care benefits + other benefits, USA relocation etc! Complete some puzzles and earn points!\n",
        "\n",
        "* We encourage you to use AI for coding!<ins> No experience or PhD / Masters needed</ins> - just get enough points for consideration!\n",
        "* There are <ins>negative points</ins> for incorrect submissions. Read each criteria! Read [Submission](#SUBMISSION) steps.\n",
        "\n",
        "| Role              | Compensation   | Role Description | Points Needed |\n",
        "| ----------------- | -------------- | ----------- | --- |\n",
        "| Founding Engineer | \\$400K to \\$500K & equity | Help push Unsloth forward - bug fixes, core features, UI, kernels, nearly anything! | 47 |\n",
        "| ML Engineer | \\$250K to \\$300K & equity | Help with FSDP2, Float8, Float4, kernels, Unsloth core and more! | 32 |\n",
        "| ML Intern | up to \\$150K py | Implementing specific features in Unsloth core. Can be remote.  | 18 |\n",
        "\n",
        "1. [Convert `nf4` to Triton](#NF4) [Difficulty: Hard] [Max points: 14]\n",
        "2. [Make `QLoRA` work with `FSDP2`](#FSDP2) [Difficulty: Medium to Hard] [Max points: 12]\n",
        "3. [Make `torch.compile` work without graph breaks for QLoRA](#COMPILE) [Difficulty: Easy to Medium] [Max points: 9]\n",
        "4. [Help solve ðŸ¦¥ Unsloth issues!](#ISSUES) [Difficulty: Varies] [Max points: 12]\n",
        "5. [Memory Efficient Backprop](#MATH) [Difficulty: Medium to Hard] [Max points: 10]\n",
        "6. [Submission steps](#SUBMISSION)\n",
        "\n",
        "### ðŸ¦¥ Who are we?\n",
        "* 1.58bit DeepSeek R1 GGUFs [Tweet](https://x.com/UnslothAI/status/1883899061893546254) and [HF Model Page](https://huggingface.co/unsloth/DeepSeek-R1-GGUF)\n",
        "* GRPO Llama 3.1 8B on a free Colab [Tweet](https://x.com/UnslothAI/status/1887562753126408210)\n",
        "* Gemma bug fixes [Tweet](https://x.com/danielhanchen/status/1765446273661075609) and bug fixes for Llama 3, Phi 3, Qwen 2.5 [Details](https://unsloth.ai/blog/phi3) Llama-fying Phi-4 [Details](https://unsloth.ai/blog/phi4)\n",
        "* Gradient accumulation bug fixes [Tweet](https://x.com/danielhanchen/status/1846235913443262891) 4bit Dynamic Quantization [Details](https://unsloth.ai/blog/dynamic-4bit)\n",
        "* Unsloth Gradient Checkpointing async offloads activations [Details](https://unsloth.ai/blog/long-context)\n",
        "* 30K Github Stars [Github](https://github.com/unslothai/unsloth) & 7 million monthly downloads on [Hugging Face](https://huggingface.co/unsloth)\n",
        "* PyTorch conference [video](https://www.youtube.com/watch?v=PdtKkc5jB4g) AI Engineer World's Fair [video](https://www.youtube.com/watch?v=pRM_P6UfdIc) GPU / CUDA MODE [talk](https://www.youtube.com/watch?v=hfb_AIhDYnA)\n",
        "\n",
        "\n",
        "### Clarifications:\n",
        "1. We'll compensate you if we interview you but don't hire you\n",
        "2. \\$100-\\$1000 bounties for Task 4\n",
        "3. Submissions must be Apache-2 licensed\n",
        "4. Task 4 involves solving Github issues for OSS Unsloth\n",
        "5. No time limit: rolling basis\n",
        "6. US based preferred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "F_rx9FYMOc2T"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EI_d4FLkR51i"
      },
      "outputs": [],
      "source": [
        "# Helpful functions used through the entire notebook\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import set_seed\n",
        "import time\n",
        "import inspect\n",
        "import os\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "HAS_BFLOAT16 = (major_version >= 8)\n",
        "from inspect import currentframe as _C, getframeinfo\n",
        "_F = lambda c: getframeinfo(c).lineno # Gets line number\n",
        "WARN = lambda x: print(f\"\\033[31m{x}\\033[0m\") # Red colored warnings\n",
        "\n",
        "# https://stackoverflow.com/questions/18425225/getting-the-name-of-a-variable-as-a-string\n",
        "def NAME(var):\n",
        "    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n",
        "    names = [var_name for var_name, var_val in callers_local_vars if var_val is var]\n",
        "    return names[0] if len(names) != 0 else \"\"\n",
        "\n",
        "def assert_same(x, y, line, dtype):\n",
        "    assert(x.dtype == dtype)\n",
        "    try: torch.testing.assert_close(x, y, check_stride = True)\n",
        "    except Exception as error:\n",
        "        raise RuntimeError(\n",
        "            f\"Failed allclose at line [{line}]: {NAME(x)}, {NAME(y)}\\n{str(error)}\"\n",
        "        )\n",
        "\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A) Convert `nf4` to Triton. (Original Challenge)"
      ],
      "metadata": {
        "id": "GnthZ-u_TMLc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoE2DGRZG2Ng"
      },
      "source": [
        "<a name=\"NF4\"></a>\n",
        "\n",
        "\n",
        "\n",
        "1. Goal: Convert a `nf4` quantized tensor into `fp16` or `bf16` into a *single* Triton kernel The double dequant of the `absmax` and weight forming must be done in 1 Triton kernel. Must work on Tesla T4.\n",
        "2. Must be faster than Unsloth's `fast_dequantize` by 1.15x or more, and not use large intermediate memory buffers.\n",
        "3. Must not use `torch.compile`, but can use `trace.enabled` to help on writing Triton kernels.\n",
        "4. Good material: [Unsloth `fast_dequantize` function](https://github.com/unslothai/unsloth/blob/main/unsloth/kernels/utils.py#L128), also [bitsandbytes `dequantize_blockwise`](https://github.com/bitsandbytes-foundation/bitsandbytes/blob/86b6c37a8ad448230cedb60753f63150b603a112/bitsandbytes/functional.py#L958)\n",
        "5. Use `test_dequantize_function` to test your implementation.\n",
        "6. No CUDA allowed. Custom CUDA inside of the Triton is allowed.\n",
        "7. Watch Tim's videos on Youtube: [8-bit Optimizers](https://www.youtube.com/watch?v=2ETNONas068)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WKQ9hdqNOXpe",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from bitsandbytes.nn import Linear4bit\n",
        "from transformers.activations import ACT2FN\n",
        "from unsloth.kernels.utils import fast_dequantize\n",
        "from peft.utils.integrations import dequantize_module_weight as peft_dequantize\n",
        "def unsloth_dequantize(weight):\n",
        "    return fast_dequantize(weight.weight, weight.weight.quant_state)\n",
        "\n",
        "def bnb_Linear4bit(hd, m, dtype = torch.float16):\n",
        "    return Linear4bit(\n",
        "        hd, m, bias = None,\n",
        "        compute_dtype       = dtype,\n",
        "        compress_statistics = True,\n",
        "        quant_type          = \"nf4\",\n",
        "    )\n",
        "\n",
        "# [NEW] as at 18th Feb 2025\n",
        "def assert_correct_bnb(weight, dtype):\n",
        "    assert(weight.weight.dtype == torch.uint8)\n",
        "    assert(weight.weight.quant_state.dtype == dtype)\n",
        "    assert(weight.weight.quant_state.absmax.dtype == torch.uint8)\n",
        "    assert(weight.weight.quant_state.code.dtype == torch.float32)\n",
        "    assert(weight.weight.quant_state.offset.dtype == torch.float32)\n",
        "    assert(weight.weight.quant_state.blocksize == 64)\n",
        "    assert(weight.weight.quant_state.state2.absmax.dtype == torch.float32)\n",
        "    assert(weight.weight.quant_state.state2.code.dtype == torch.float32)\n",
        "    assert(weight.weight.quant_state.state2.blocksize == 256)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, hd = 4096, m = 14336, dtype = torch.float16):\n",
        "        super().__init__()\n",
        "        self.gate_proj = bnb_Linear4bit(hd, m, dtype = dtype).to(\"cuda\")\n",
        "        self.up_proj   = bnb_Linear4bit(hd, m, dtype = dtype).to(\"cuda\")\n",
        "        self.down_proj = bnb_Linear4bit(m, hd, dtype = dtype).to(\"cuda\")\n",
        "        # [NEW] as at 18th Feb 2025\n",
        "        self.gate_proj.weight.quant_state.dtype = dtype\n",
        "        self.up_proj  .weight.quant_state.dtype = dtype\n",
        "        self.down_proj.weight.quant_state.dtype = dtype\n",
        "        self.act_fn = ACT2FN[\"silu\"]\n",
        "    def forward(self, x):\n",
        "        return self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
        "\n",
        "def mlp_forward(X, mlp, fx):\n",
        "    up   = X @ fx(mlp.  up_proj).t()\n",
        "    gate = X @ fx(mlp.gate_proj).t()\n",
        "    h = mlp.act_fn(gate) * up\n",
        "    down = h @ fx(mlp.down_proj).t()\n",
        "    return down\n",
        "\n",
        "def mlp_dequantize(X, mlp, fx):\n",
        "    a = fx(mlp.  up_proj).t(); torch.cuda.synchronize()\n",
        "    b = fx(mlp.gate_proj).t(); torch.cuda.synchronize()\n",
        "    c = fx(mlp.down_proj).t(); torch.cuda.synchronize()\n",
        "    return a, b, c\n",
        "\n",
        "def test_dequantize(dequantize_fx):\n",
        "    elapsed = 0\n",
        "    options = [\n",
        "        (2, 3333, 2048,  8192, 3407, torch.float16),\n",
        "        (5,  777, 1024,  4096, 3409, torch.bfloat16),\n",
        "        (3, 2048, 4096, 14336, 3408, torch.bfloat16),\n",
        "    ]\n",
        "    for (bsz, qlen, hd, m, seed, dt) in options:\n",
        "        set_seed(seed)\n",
        "        torch.set_default_dtype(torch.float32)\n",
        "        mlp = MLP(hd = hd, m = m, dtype = dt)\n",
        "        X = torch.randn((bsz, qlen, hd), device = \"cuda\", dtype = dt)\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "        # Warmup\n",
        "        for _ in range(2):\n",
        "            assert_same( mlp_forward(X, mlp, dequantize_fx), mlp(X), _F(_C()), dt)\n",
        "            # [NEW] as at 18th Feb 2025\n",
        "            assert_correct_bnb(mlp.  up_proj, dt)\n",
        "            assert_correct_bnb(mlp.gate_proj, dt)\n",
        "            assert_correct_bnb(mlp.down_proj, dt)\n",
        "            a, b, c = mlp_dequantize(X, mlp, dequantize_fx)\n",
        "            A, B, C = mlp_dequantize(X, mlp, unsloth_dequantize)\n",
        "            assert_same(a, A, _F(_C()), dt)\n",
        "            assert_same(b, B, _F(_C()), dt)\n",
        "            assert_same(c, C, _F(_C()), dt)\n",
        "\n",
        "        # Benchmarking\n",
        "        torch.cuda.synchronize()\n",
        "        start = time.time()\n",
        "        for _ in range(1000): mlp_dequantize(X, mlp, dequantize_fx)\n",
        "        elapsed += time.time() - start\n",
        "    return elapsed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9EiO1cu2YKB"
      },
      "source": [
        "For example, we can test our implementation via:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM8q3rDX1XfZ",
        "outputId": "65c15de0-1539-4a1d-ffe8-ab2c70137198"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.02012038230896"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from unsloth.kernels.utils import fast_dequantize\n",
        "def unsloth_dequantize(weight):\n",
        "    return fast_dequantize(weight.weight, weight.weight.quant_state)\n",
        "test_dequantize(unsloth_dequantize)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: The above time is on a L4 GPU On a T4 it comes out at 3.9 s"
      ],
      "metadata": {
        "id": "9qGWHWWJW2nP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nETwlex22lMN"
      },
      "source": [
        "The elapsed time for our implementation over 1000 trials is 5.38 seconds or so.\n",
        "\n",
        "PEFT also has one, which should be mostly identical to Unsloth's version, albeit slightly slower."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu5RShLO1h-Y",
        "outputId": "9c53c0e5-7699-410c-a40b-34bc06891bf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.842420816421509"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from peft.utils.integrations import dequantize_module_weight as peft_dequantize\n",
        "test_dequantize(peft_dequantize)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above time is on a L4"
      ],
      "metadata": {
        "id": "4Gq3ZMd-XH7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unsloth Harness"
      ],
      "metadata": {
        "id": "w0hSfb0qWe-I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE5pUaSN3JcM"
      },
      "source": [
        "Write your Triton kernel below, and test it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9ThmhbT2GPi"
      },
      "outputs": [],
      "source": [
        "from triton import jit\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "@triton.jit\n",
        "def _your_dequantize_nf4_kernel():\n",
        "    ### TRITON CODE GOES HERE\n",
        "    return\n",
        "\n",
        "def _your_dequantize_nf4(weight, quant_state):\n",
        "    ### SETUP TRITON LAUNCH HERE\n",
        "    return None\n",
        "\n",
        "def your_dequantize_nf4(weight):\n",
        "    return _your_dequantize_nf4(weight.weight.data, weight.weight.quant_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvvEm6ZH35fB"
      },
      "outputs": [],
      "source": [
        "### TEST IT BELOW:\n",
        "# test_dequantize(your_dequantize_nf4)\n",
        "\n",
        "### CALCULATE SPEEDUP (hopefully 1.15x faster or more)\n",
        "# test_dequantize(unsloth_dequantize) / test_dequantize(your_dequantize_nf4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYaff1Ror8R_"
      },
      "source": [
        "## Marking Criteria for A) Max points = 14\n",
        "```python\n",
        "if attemped_A:\n",
        "    A_score = 0\n",
        "    if single_triton_kernel: A_score += 3\n",
        "    speedup = old_time / new_time\n",
        "    if speedup <= 1.00: A_score -= 3\n",
        "    if speedup >= 1.05: A_score += 1\n",
        "    if speedup >= 1.10: A_score += 2\n",
        "    if speedup >= 1.15: A_score += 2\n",
        "    if kernel_works_in_torch_compile: A_score += 1\n",
        "    else: A_score -= 1\n",
        "    if custom_asm_works: A_score += 3\n",
        "    if uses_cache_eviction: A_score += 1\n",
        "    if tested_in_f16_and_bf16: A_score += 1\n",
        "    else: A_score -= 1\n",
        "    final_score += A_score\n",
        "else:\n",
        "    final_score += 0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NF4 â†’ fp16 Dequant in Mojo (Unsloth Puzzle A, Mojo Edition â€“ T4 vs L4)\n",
        "\n",
        "This is a Mojo GPU implementation of Unslothâ€™s **â€œConvert `nf4` to Tritonâ€** puzzle (Task A), but written as straight Mojo kernels instead of Triton/CUDA.\n",
        "\n",
        "> **Goal:** Dequantize bitsandbytes-style `nf4` weights (with double-quant stats) into `fp16` using a **single custom GPU kernel**, no `torch.compile`, and benchmark under the same workload as Unslothâ€™s `test_dequantize`.\n",
        "\n",
        "### What the kernels do\n",
        "\n",
        "All variants implement full **bitsandbytes / Unsloth NF4** semantics:\n",
        "\n",
        "* `blocksize = 64` (64 weights per NF4 block, 32 bytes of codes)\n",
        "* `state2.blocksize = 256` (256 blocks per outer scale)\n",
        "* Standard NF4 16-entry codebook\n",
        "* Double dequantization:\n",
        "\n",
        "  * `absmax_q` â†’ `state2.code` â†’ `state2.absmax` â†’ `offset`\n",
        "\n",
        "Two â€œfinalâ€ Mojo kernels:\n",
        "\n",
        "1. **Warp-per-NF4-block kernel (shared scale + packed store)**\n",
        "\n",
        "   * 256 threads per block (8 warps).\n",
        "   * **1 warp = 1 NF4 block** (64 weights = 32 bytes).\n",
        "   * Lane 0 per warp dequantizes the blockâ€™s fp32 scale once and writes it to shared memory; all 32 lanes reuse it.\n",
        "   * Each lane handles **1 NF4 byte â†’ 2 `fp16` values**, packs them into a single `u32`, and does **one 32-bit store**.\n",
        "\n",
        "2. **2D tiled kernel (1024 threads + packed store)**\n",
        "\n",
        "   * 2D tiling over `(rows, cols)` with `256 Ã— 4 = 1024` threads per block.\n",
        "   * **1 thread = 1 NF4 byte â†’ 2 `fp16` values â†’ 1 `u32` store**.\n",
        "   * Recomputes the scale per element (no shared scale), but has very regular memory access and high occupancy.\n",
        "\n",
        "Both are **plain Mojo** using `DeviceContext` â€“ no C++, no raw CUDA, no `torch.compile`.\n",
        "\n",
        "---\n",
        "\n",
        "### Benchmark harness (exact same workload as Unsloth)\n",
        "\n",
        "I reuse Unslothâ€™s `test_dequantize` structure, but replace `fast_dequantize` with my Mojo kernel wrapper:\n",
        "\n",
        "* Three `(hd, m)` configs:\n",
        "\n",
        "  * `(2048, 8192)`\n",
        "  * `(1024, 4096)`\n",
        "  * `(4096, 14336)`\n",
        "* For each config, dequantize three matrices:\n",
        "\n",
        "  * `up_proj   : (m, hd)`\n",
        "  * `gate_proj : (m, hd)`\n",
        "  * `down_proj : (hd, m)`\n",
        "* Each matrix: **1000 dequant calls**, with `torch.cuda.synchronize()` in the original harness.\n",
        "* Total: **9000 dequants** per run.\n",
        "* For Mojo, I mirror this: same shapes, same 3Ã—3Ã—1000 structure, and time only the kernel launches using `ctx.execution_time` with fixed device buffers.\n",
        "\n",
        "Correctness is checked twice:\n",
        "\n",
        "* Mojo CPU reference vs Mojo GPU (bit-accurate in fp16).\n",
        "* Earlier in the process, Mojo GPU vs Unslothâ€™s `fast_dequantize` outputs.\n",
        "\n",
        "---\n",
        "\n",
        "### T4 vs L4: performance comparison\n",
        "\n",
        "Below are **end-to-end `test_dequantize` workloads** (3 configs Ã— 3 matrices Ã— 1000 calls), measured on Colab T4 and L4:\n",
        "\n",
        "#### Baselines\n",
        "\n",
        "* **Unsloth Triton reference** (original notebook, T4):\n",
        "  â‰ˆ **5.32 s**\n",
        "* **Unsloth `fast_dequantize` (CUDA C)**\n",
        "\n",
        "  * T4: â‰ˆ **3.90 s** (from Unslothâ€™s updated note)\n",
        "  * L4: measured â‰ˆ **3.02 s**\n",
        "* **PEFT dequant (CUDA C)** on L4: â‰ˆ **3.84 s**\n",
        "\n",
        "#### Mojo kernels â€“ T4 (Tesla T4)\n",
        "\n",
        "* **Warp-per-NF4-block (shared scale + packed store)**\n",
        "  â†’ **â‰ˆ 4.50 s** total\n",
        "  â†’ **speedup vs Triton ref ~1.18Ã—**\n",
        "\n",
        "* **2D tiled + packed 32-bit store (1024 threads/block)**\n",
        "  â†’ **â‰ˆ 4.27 s** total\n",
        "  â†’ **speedup vs Triton ref ~1.24Ã—**\n",
        "  â†’ Within ~10% of Unslothâ€™s internal CUDA fast path (3.9 s) on this GPU.\n",
        "\n",
        "On T4 the **2D packed kernel wins**: large CTAs and very simple per-thread control flow beat the warp-per-block design, even though that one does less math per element.\n",
        "\n",
        "#### Mojo kernels â€“ L4 (NVIDIA L4)\n",
        "\n",
        "Same harness, just on L4:\n",
        "\n",
        "* **Unsloth `fast_dequantize` (CUDA C)**\n",
        "  â†’ `test_dequantize(unsloth_dequantize) â‰ˆ 3.02 s`\n",
        "\n",
        "* **Warp-per-NF4-block (shared scale + packed store)**\n",
        "  â†’ **â‰ˆ 2.47 s** total\n",
        "  â†’ **speedup vs Triton ref ~2.15Ã—**\n",
        "  â†’ **speedup vs CUDA fast_dequantize ~1.22Ã—**\n",
        "\n",
        "* **2D tiled + packed 32-bit store (1024 threads/block)**\n",
        "  â†’ **â‰ˆ 2.60 s** total\n",
        "  â†’ **speedup vs Triton ref ~2.05Ã—**\n",
        "  â†’ **speedup vs CUDA fast_dequantize ~1.16Ã—**\n",
        "\n",
        "On **L4**, the ranking **flips**:\n",
        "\n",
        "* The **warp-per-NF4-block kernel** becomes the fastest:\n",
        "\n",
        "  * 1 warp = 1 NF4 block,\n",
        "  * shared scale per block,\n",
        "  * one packed 32-bit store per byte.\n",
        "* The 2D packed kernel is still very strong, but now slightly behind the warp version.\n",
        "\n",
        "In terms of effective bandwidth on the largest config (4096Ã—14336 â‰ˆ 58.7M weights), the warp kernel is in the **200â€“250 GB/s** ballpark on L4, which is right where a memory-bound kernel should be on this card.\n",
        "\n",
        "---\n",
        "\n",
        "### TL;DR\n",
        "\n",
        "* On **T4**, the 2D 1024-thread Mojo kernel with packed `u32` stores beats the Triton reference by ~**1.2â€“1.3Ã—** and gets close to Unslothâ€™s CUDA fast path.\n",
        "* On **L4**, both Mojo kernels are **2Ã— faster** than the original Triton harness, and the **warp-per-NF4-block** Mojo kernel is actually **~1.2Ã— faster** than Unslothâ€™s current CUDA `fast_dequantize`.\n",
        "* All of this is done in **pure Mojo**, no C++/CUDA and no `torch.compile` just hand-written kernels and a simple timing harness that mirrors the original `test_dequantize` structure.\n",
        "\n",
        "For me, this was mainly a â€œcan I do this in Mojo, and how close can I getâ€ experiment. The fun twist is that on L4 the answer turned out to be: *closer than expected, and in some cases actually ahead of the C/CUDA implementation it was inspired by.*\n",
        "\n",
        "## Also of Note\n",
        "\n",
        "The bitsandbytesâ€™ CUDA fast path is implemented as **two kernels** (one to dequantize the stats into fp32 scales, and a second to dequantize the NF4 weights), whereas the Mojo kernels here fuse both stages into a **single GPU kernel** with no large intermediate buffers, and still comes out faster on an L4 for the same `test_dequantize` workload.\n",
        "\n",
        "\n",
        "## Background and Reason\n",
        "\n",
        "I'm a software engineer with a core background in web development and some Python, and Iâ€™ve always had a strong drive to understand how things work at a deeper level. When I first learned about Mojo and the Modular teamâ€™s mission to make GPU programming more approachable, I started following their progress closely.\n",
        "\n",
        "Lately Iâ€™ve been experimenting with max, custom ops, and other lower-level pieces of the stack. When I came across this notebook, I decided to treat it as a personal challenge: could someone without prior GPU-kernel experience pick up Mojo and become productive quickly, and could that same person build something competitive with highly optimized, hand-tuned kernels?\n",
        "\n",
        "After roughly seven hours of work, Iâ€™m happy with the result. The kernel I built is  competitive on T4 and 1.3x faster on L4. The process reinforced my belief that Mojo successfully lowers the barrier to entry by pairing a Python-like feel with low-level control when needed.\n",
        "\n",
        "\n",
        "David Robertson  \n",
        "info@drobetson.pro  \n",
        "github.com/daver987"
      ],
      "metadata": {
        "id": "UMyRVMkdl3ia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install mojo"
      ],
      "metadata": {
        "id": "1G-8lh-rCeo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mojo --index-url https://dl.modular.com/public/nightly/python/simple/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Y5MpAXh1UxZd",
        "outputId": "4d5549a2-c495-473a-9907-794739e369e3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://dl.modular.com/public/nightly/python/simple/\n",
            "Collecting mojo\n",
            "  Downloading https://dl.modular.com/public/nightly/python/mojo-0.26.1.0.dev2025120505-py3-none-manylinux_2_34_x86_64.whl (21.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.9/21.9 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mojo-compiler==0.26.1.0.dev2025120505 (from mojo)\n",
            "  Downloading https://dl.modular.com/public/nightly/python/mojo_compiler-0.26.1.0.dev2025120505-py3-none-manylinux_2_34_x86_64.whl (99.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.8/99.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mblack==26.1.0.dev2025120505 (from mojo)\n",
            "  Downloading https://dl.modular.com/public/nightly/python/mblack-26.1.0.dev2025120505-py3-none-any.whl (146 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m146.6/146.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mojo-lldb-libs==0.26.1.0.dev2025120505 (from mojo)\n",
            "  Downloading https://dl.modular.com/public/nightly/python/mojo_lldb_libs-0.26.1.0.dev2025120505-py3-none-manylinux_2_34_x86_64.whl (84.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.3/84.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from mblack==26.1.0.dev2025120505->mojo) (8.3.1)\n",
            "Collecting mypy-extensions>=0.4.3 (from mblack==26.1.0.dev2025120505->mojo)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from mblack==26.1.0.dev2025120505->mojo)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.12/dist-packages (from mblack==26.1.0.dev2025120505->mojo) (4.5.0)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: mojo-lldb-libs, mojo-compiler, pathspec, mypy-extensions, mblack, mojo\n",
            "Successfully installed mblack-26.1.0.dev2025120505 mojo-0.26.1.0.dev2025120505 mojo-compiler-0.26.1.0.dev2025120505 mojo-lldb-libs-0.26.1.0.dev2025120505 mypy-extensions-1.1.0 pathspec-0.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check that mojo is available and import notebook"
      ],
      "metadata": {
        "id": "FCCpcex8VYoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mojo.notebook"
      ],
      "metadata": {
        "id": "1Mq432ioVFkX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check that we are on the GPU"
      ],
      "metadata": {
        "id": "krpKVRjqVjLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%mojo\n",
        "\n",
        "from gpu.host import DeviceContext\n",
        "\n",
        "fn kernel():\n",
        "    print(\"Hello from the GPU\")\n",
        "\n",
        "def main():\n",
        "    with DeviceContext() as ctx:\n",
        "        ctx.enqueue_function_checked[kernel, kernel](grid_dim=1, block_dim=1)\n",
        "        ctx.synchronize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFzWDyc5VqgL",
        "outputId": "f45b361e-2ad4-45fd-a45d-2594ddd87732"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from the GPU\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kernel - 2D Tiling 32 bit Store **L4** GPU"
      ],
      "metadata": {
        "id": "5VZ31H3MU6iU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%mojo\n",
        "from gpu import block_idx, thread_idx, barrier\n",
        "from gpu.host import DeviceContext\n",
        "from gpu.memory import AddressSpace\n",
        "from memory import UnsafePointer, stack_allocation, bitcast\n",
        "from math import fma, ceildiv\n",
        "\n",
        "#######################\n",
        "# Types and Constants #\n",
        "#######################\n",
        "\n",
        "comptime packed_dtype = DType.uint8\n",
        "comptime f32_dtype = DType.float32\n",
        "comptime f16_dtype = DType.float16\n",
        "comptime u32_dtype = DType.uint32\n",
        "comptime u16_dtype = DType.uint16\n",
        "\n",
        "comptime U8 = Scalar[packed_dtype]\n",
        "comptime F32 = Scalar[f32_dtype]\n",
        "comptime F16 = Scalar[f16_dtype]\n",
        "comptime U32 = Scalar[u32_dtype]\n",
        "comptime U16 = Scalar[u16_dtype]\n",
        "\n",
        "# Bitsandbytes NF4 codebook\n",
        "comptime NF4_TABLE = InlineArray[F32, 16](\n",
        "    -1.0,\n",
        "    -0.6961928009986877,\n",
        "    -0.5250730514526367,\n",
        "    -0.39491748809814453,\n",
        "    -0.28444138169288635,\n",
        "    -0.18477343022823334,\n",
        "    -0.09105003625154495,\n",
        "    0.0,\n",
        "    0.07958029955625534,\n",
        "    0.16093020141124725,\n",
        "    0.24611230194568634,\n",
        "    0.33791524171829224,\n",
        "    0.44070982933044434,\n",
        "    0.5626170039176941,\n",
        "    0.7229568362236023,\n",
        "    1.0,\n",
        ")\n",
        "\n",
        "# NF4 layout / block structure\n",
        "comptime BLOCKSIZE_W = 64  # weights per NF4 block\n",
        "comptime BLOCKSIZE_W_SHIFT = 6  # log2(64) for bit shift\n",
        "comptime STATE2_BLOCKSIZE = 256  # absmax entries per state2 scale\n",
        "comptime STATE2_SHIFT = 8  # log2(256) for bit shift\n",
        "\n",
        "# 2D tiling: each thread handles 1 byte = 2 weights\n",
        "# Output as packed 32-bit (2 x fp16)\n",
        "comptime TILE_BYTES_X = 256  # bytes per block in X (= 512 weights)\n",
        "comptime TILE_ROWS = 4  # rows per block\n",
        "comptime THREADS_X = 256\n",
        "comptime THREADS_Y = 4\n",
        "# Total: 1024 threads per block, each outputs 32 bits (2 fp16)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# GPU kernel: PACKED 32-bit STORE\n",
        "#   - Each thread handles 1 packed byte = 2 weights\n",
        "#   - Outputs a single 32-bit word (2 x fp16 packed)\n",
        "#   - 256Ã—4 = 1024 threads per CUDA block\n",
        "#   - Shared memory for NF4 codebook\n",
        "# ---------------------------------------------------\n",
        "\n",
        "\n",
        "fn nf4_dequant_kernel_packed(\n",
        "    packed_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    out_ptr: UnsafePointer[U32, MutAnyOrigin],  # Output as packed 32-bit words\n",
        "    n_rows: Int,\n",
        "    n_bytes_per_row: Int,  # n_cols // 2\n",
        "    blocks_per_row: Int,\n",
        "    groups_per_row: Int,\n",
        "):\n",
        "    # Shared memory for NF4 codebook (16 values)\n",
        "    var shared_nf4 = stack_allocation[\n",
        "        16, F32, address_space = AddressSpace.SHARED\n",
        "    ]()\n",
        "\n",
        "    # First 16 threads of first row load the NF4 codebook\n",
        "    var tx = Int(thread_idx.x)\n",
        "    var ty = Int(thread_idx.y)\n",
        "    if ty == 0 and tx < 16:\n",
        "        shared_nf4[tx] = NF4_TABLE[tx]\n",
        "\n",
        "    barrier()\n",
        "\n",
        "    # 2D position: (row, byte_idx within row)\n",
        "    var row = Int(block_idx.x) * TILE_ROWS + ty\n",
        "    var byte_idx = Int(block_idx.y) * TILE_BYTES_X + tx\n",
        "\n",
        "    if row >= n_rows or byte_idx >= n_bytes_per_row:\n",
        "        return\n",
        "\n",
        "    # Read the packed byte\n",
        "    var packed_byte: U8 = packed_ptr[row * n_bytes_per_row + byte_idx]\n",
        "    var packed_int: Int = Int(packed_byte)\n",
        "\n",
        "    # Extract low and high nibbles\n",
        "    var lo_idx: Int = packed_int & 0x0F\n",
        "    var hi_idx: Int = (packed_int >> 4) & 0x0F\n",
        "\n",
        "    # NF4 lookup from shared memory\n",
        "    var v0_norm: F32 = shared_nf4[lo_idx]\n",
        "    var v1_norm: F32 = shared_nf4[hi_idx]\n",
        "\n",
        "    # Column index for weight 0 (col0 = byte_idx * 2)\n",
        "    var col0 = byte_idx << 1  # byte_idx * 2\n",
        "\n",
        "    # Compute block/group indices using bit shifts\n",
        "    var block_id = col0 >> BLOCKSIZE_W_SHIFT  # col0 // 64\n",
        "    var absmax_idx = row * blocks_per_row + block_id\n",
        "\n",
        "    # First-level dequant: absmax_q -> code2 lookup\n",
        "    var q_scale: U8 = absmax_q_ptr[absmax_idx]\n",
        "    var code_val: F32 = code2_ptr[Int(q_scale)]\n",
        "\n",
        "    # Second-level dequant: group scale\n",
        "    var group_id = block_id >> STATE2_SHIFT  # block_id // 256\n",
        "    var group_idx = row * groups_per_row + group_id\n",
        "    var scale_base: F32 = scale2_ptr[group_idx]\n",
        "\n",
        "    # Final scale = code2[absmax_q] * scale2 + offset\n",
        "    var scale: F32 = fma(code_val, scale_base, offset)\n",
        "\n",
        "    # Dequantized values\n",
        "    var v0: F32 = v0_norm * scale\n",
        "    var v1: F32 = v1_norm * scale\n",
        "\n",
        "    # Convert to fp16\n",
        "    var h0: F16 = F16(v0)\n",
        "    var h1: F16 = F16(v1)\n",
        "\n",
        "    # Bitcast to u16\n",
        "    var b0: U16 = bitcast[u16_dtype](h0)\n",
        "    var b1: U16 = bitcast[u16_dtype](h1)\n",
        "\n",
        "    # Pack into 32-bit word: [h1:h0] (h0 in low 16 bits, h1 in high 16 bits)\n",
        "    var packed_out: U32 = (U32(b1) << 16) | U32(b0)\n",
        "\n",
        "    # Output word index (one 32-bit word per byte = 2 weights)\n",
        "    # word_stride = n_bytes_per_row (since each byte -> one 32-bit word)\n",
        "    var word_idx = row * n_bytes_per_row + byte_idx\n",
        "\n",
        "    out_ptr[word_idx] = packed_out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# CPU reference (same logic, stores as fp16 pairs)\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn nf4_dequant_cpu_packed(\n",
        "    packed: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    output: UnsafePointer[\n",
        "        F16, MutAnyOrigin\n",
        "    ],  # CPU uses F16 for easier verification\n",
        "    n_rows: Int,\n",
        "    n_cols: Int,\n",
        "):\n",
        "    var n_bytes_per_row = n_cols >> 1\n",
        "    var blocks_per_row = (n_cols + BLOCKSIZE_W - 1) >> BLOCKSIZE_W_SHIFT\n",
        "    var groups_per_row = (blocks_per_row + STATE2_BLOCKSIZE - 1) >> STATE2_SHIFT\n",
        "\n",
        "    for row in range(n_rows):\n",
        "        var row_packed_base = row * n_bytes_per_row\n",
        "        var row_out_base = row * n_cols\n",
        "        var row_absmax_base = row * blocks_per_row\n",
        "        var row_group_base = row * groups_per_row\n",
        "\n",
        "        for byte_idx in range(n_bytes_per_row):\n",
        "            var packed_byte: U8 = packed[row_packed_base + byte_idx]\n",
        "            var packed_int: Int = Int(packed_byte)\n",
        "\n",
        "            var lo_idx: Int = packed_int & 0x0F\n",
        "            var hi_idx: Int = (packed_int >> 4) & 0x0F\n",
        "\n",
        "            var v0_norm: F32 = NF4_TABLE[lo_idx]\n",
        "            var v1_norm: F32 = NF4_TABLE[hi_idx]\n",
        "\n",
        "            var col0 = byte_idx << 1\n",
        "            var block_id = col0 >> BLOCKSIZE_W_SHIFT\n",
        "            var absmax_idx = row_absmax_base + block_id\n",
        "\n",
        "            var q_scale: U8 = absmax_q[absmax_idx]\n",
        "            var code_val: F32 = code2[Int(q_scale)]\n",
        "\n",
        "            var group_id = block_id >> STATE2_SHIFT\n",
        "            var group_idx = row_group_base + group_id\n",
        "            var scale_base: F32 = scale2[group_idx]\n",
        "\n",
        "            var scale: F32 = fma(code_val, scale_base, offset)\n",
        "\n",
        "            var v0: F32 = v0_norm * scale\n",
        "            var v1: F32 = v1_norm * scale\n",
        "\n",
        "            output[row_out_base + col0] = F16(v0)\n",
        "            output[row_out_base + col0 + 1] = F16(v1)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Correctness check\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def run_correctness_test(ctx: DeviceContext):\n",
        "    # Use a small 2D test case: 4 rows Ã— 128 cols\n",
        "    var n_rows: Int = 4\n",
        "    var n_cols: Int = 128\n",
        "    var n_weights: Int = n_rows * n_cols\n",
        "    var n_bytes: Int = n_weights // 2\n",
        "    var n_bytes_per_row: Int = n_cols // 2\n",
        "\n",
        "    var blocks_per_row = ceildiv(n_cols, BLOCKSIZE_W)\n",
        "    var n_absmax = n_rows * blocks_per_row\n",
        "    var groups_per_row = ceildiv(blocks_per_row, STATE2_BLOCKSIZE)\n",
        "    var n_scale2 = n_rows * groups_per_row\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_absmax)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "    var out_cpu_host = ctx.enqueue_create_host_buffer[f16_dtype](n_weights)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Fill deterministic pattern\n",
        "    for i in range(n_bytes):\n",
        "        var lo: Int = i % 16\n",
        "        var hi: Int = (i + 1) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    for i in range(n_absmax):\n",
        "        absmax_host[i] = U8(i % 16)\n",
        "\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    # CPU ref\n",
        "    nf4_dequant_cpu_packed(\n",
        "        packed_host.unsafe_ptr(),\n",
        "        absmax_host.unsafe_ptr(),\n",
        "        code2_host.unsafe_ptr(),\n",
        "        scale2_host.unsafe_ptr(),\n",
        "        F32(offset),\n",
        "        out_cpu_host.unsafe_ptr(),\n",
        "        n_rows,\n",
        "        n_cols,\n",
        "    )\n",
        "\n",
        "    # Device buffers\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_absmax)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    # Output buffer: n_bytes 32-bit words (each = 2 fp16)\n",
        "    var out_dev = ctx.enqueue_create_buffer[u32_dtype](n_bytes)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "\n",
        "    # 2D grid: grid_x = rows/TILE_ROWS, grid_y = bytes_per_row/TILE_BYTES_X\n",
        "    var grid_x: Int = ceildiv(n_rows, TILE_ROWS)\n",
        "    var grid_y: Int = ceildiv(n_bytes_per_row, TILE_BYTES_X)\n",
        "\n",
        "    ctx.enqueue_function_checked[\n",
        "        nf4_dequant_kernel_packed, nf4_dequant_kernel_packed\n",
        "    ](\n",
        "        packed_dev,\n",
        "        absmax_dev,\n",
        "        code2_dev,\n",
        "        scale2_dev,\n",
        "        F32(offset),\n",
        "        out_dev,\n",
        "        n_rows,\n",
        "        n_bytes_per_row,\n",
        "        blocks_per_row,\n",
        "        groups_per_row,\n",
        "        grid_dim=(grid_x, grid_y),\n",
        "        block_dim=(THREADS_X, THREADS_Y),\n",
        "    )\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Compare: unpack 32-bit GPU output to fp16 pairs\n",
        "    with out_dev.map_to_host() as out_gpu_host:\n",
        "        var max_abs_diff: F32 = 0.0\n",
        "\n",
        "        print(\"idx\\tCPU\\t\\tGPU\\t\\tdiff\")\n",
        "        for i in range(n_bytes):\n",
        "            var packed_word: U32 = out_gpu_host[i]\n",
        "            var b0: U16 = U16(packed_word & 0xFFFF)\n",
        "            var b1: U16 = U16((packed_word >> 16) & 0xFFFF)\n",
        "            var gpu_v0: F16 = bitcast[f16_dtype](b0)\n",
        "            var gpu_v1: F16 = bitcast[f16_dtype](b1)\n",
        "\n",
        "            var idx0 = i * 2\n",
        "            var idx1 = idx0 + 1\n",
        "\n",
        "            var cpu_v0: F32 = F32(out_cpu_host[idx0])\n",
        "            var cpu_v1: F32 = F32(out_cpu_host[idx1])\n",
        "            var gpu_f0: F32 = F32(gpu_v0)\n",
        "            var gpu_f1: F32 = F32(gpu_v1)\n",
        "\n",
        "            var diff0: F32 = cpu_v0 - gpu_f0\n",
        "            var diff1: F32 = cpu_v1 - gpu_f1\n",
        "\n",
        "            if diff0 < 0.0:\n",
        "                diff0 = -diff0\n",
        "            if diff1 < 0.0:\n",
        "                diff1 = -diff1\n",
        "\n",
        "            if diff0 > max_abs_diff:\n",
        "                max_abs_diff = diff0\n",
        "            if diff1 > max_abs_diff:\n",
        "                max_abs_diff = diff1\n",
        "\n",
        "            if i < 8:\n",
        "                print(idx0, \"\\t\", cpu_v0, \"\\t\", gpu_f0, \"\\t\", cpu_v0 - gpu_f0)\n",
        "                print(idx1, \"\\t\", cpu_v1, \"\\t\", gpu_f1, \"\\t\", cpu_v1 - gpu_f1)\n",
        "\n",
        "        print(\"max_abs_diff =\", max_abs_diff)\n",
        "        print(\n",
        "            \"Correctness test PASSED!\" if max_abs_diff\n",
        "            < 1e-3 else \"Correctness test FAILED!\"\n",
        "        )\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Benchmark a single weight matrix\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn bench_layer_packed(\n",
        "    ctx: DeviceContext,\n",
        "    n_rows: Int,\n",
        "    n_cols: Int,\n",
        "    num_iters: Int,\n",
        ") raises -> Float64:\n",
        "    \"\"\"\n",
        "    Benchmark packed 32-bit store kernel.\n",
        "    Returns: seconds (total time for num_iters iterations)\n",
        "    \"\"\"\n",
        "    var n_weights = n_rows * n_cols\n",
        "    var n_bytes = n_weights // 2\n",
        "    var n_bytes_per_row = n_cols // 2\n",
        "\n",
        "    var blocks_per_row = ceildiv(n_cols, BLOCKSIZE_W)\n",
        "    var n_absmax = n_rows * blocks_per_row\n",
        "    var groups_per_row = ceildiv(blocks_per_row, STATE2_BLOCKSIZE)\n",
        "    var n_scale2 = n_rows * groups_per_row\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_absmax)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Fill patterns\n",
        "    for i in range(n_bytes):\n",
        "        var lo: Int = i % 16\n",
        "        var hi: Int = (i + 1) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    for i in range(n_absmax):\n",
        "        absmax_host[i] = U8(i % 16)\n",
        "\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    # Device buffers\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_absmax)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    var out_dev = ctx.enqueue_create_buffer[u32_dtype](n_bytes)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # 2D grid\n",
        "    var grid_x: Int = ceildiv(n_rows, TILE_ROWS)\n",
        "    var grid_y: Int = ceildiv(n_bytes_per_row, TILE_BYTES_X)\n",
        "\n",
        "    # Compile once\n",
        "    var compiled_kernel = ctx.compile_function_checked[\n",
        "        nf4_dequant_kernel_packed, nf4_dequant_kernel_packed\n",
        "    ]()\n",
        "\n",
        "    @always_inline\n",
        "    @parameter\n",
        "    fn run_kernel(bench_ctx: DeviceContext) raises:\n",
        "        bench_ctx.enqueue_function_checked(\n",
        "            compiled_kernel,\n",
        "            packed_dev,\n",
        "            absmax_dev,\n",
        "            code2_dev,\n",
        "            scale2_dev,\n",
        "            F32(offset),\n",
        "            out_dev,\n",
        "            n_rows,\n",
        "            n_bytes_per_row,\n",
        "            blocks_per_row,\n",
        "            groups_per_row,\n",
        "            grid_dim=(grid_x, grid_y),\n",
        "            block_dim=(THREADS_X, THREADS_Y),\n",
        "        )\n",
        "\n",
        "    # Warmup\n",
        "    run_kernel(ctx)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    var total_ns = ctx.execution_time[run_kernel](num_iters)\n",
        "    var seconds: Float64 = Float64(total_ns) / 1e9\n",
        "\n",
        "    return seconds\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Unsloth-like benchmark harness\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def main():\n",
        "    with DeviceContext() as ctx:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"NF4 Dequantization Benchmark (Mojo Packed 32-bit Store) L4 GPU\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        print(\"\\n--- Correctness Test ---\")\n",
        "        run_correctness_test(ctx)\n",
        "\n",
        "        var NUM_ITERS_PER_LAYER: Int = 1000\n",
        "\n",
        "        print(\"\\n--- Unsloth-style Dequant Bench ---\")\n",
        "        print(\"Each layer runs\", NUM_ITERS_PER_LAYER, \"kernel launches.\")\n",
        "        print(\n",
        "            \"Using packed 32-bit store kernel: \",\n",
        "            THREADS_X,\n",
        "            \"x\",\n",
        "            THREADS_Y,\n",
        "            \" = 1024 threads/block\",\n",
        "        )\n",
        "        print(\"Each thread: 1 byte -> 2 fp16 -> 1 x 32-bit store\")\n",
        "        print(\"\\nDevice:\", ctx.api())\n",
        "\n",
        "        var total_time: Float64 = 0.0\n",
        "\n",
        "        # Config 1: hd=2048, m=8192\n",
        "        var hd1: Int = 2048\n",
        "        var m1: Int = 8192\n",
        "        print(\"\\nConfig 1: rows=\", hd1, \", cols=\", m1, \", n_weights=\", hd1 * m1)\n",
        "\n",
        "        var t1_up = bench_layer_packed(ctx, hd1, m1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t1_up, \" s\")\n",
        "        var t1_gate = bench_layer_packed(ctx, hd1, m1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t1_gate, \" s\")\n",
        "        var t1_down = bench_layer_packed(ctx, hd1, m1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t1_down, \" s\")\n",
        "\n",
        "        var config1_time = t1_up + t1_gate + t1_down\n",
        "        print(\"  Config 1 total: \", config1_time, \" s\")\n",
        "        total_time += config1_time\n",
        "\n",
        "        # Config 2: hd=1024, m=4096\n",
        "        var hd2: Int = 1024\n",
        "        var m2: Int = 4096\n",
        "        print(\"\\nConfig 2: rows=\", hd2, \", cols=\", m2, \", n_weights=\", hd2 * m2)\n",
        "\n",
        "        var t2_up = bench_layer_packed(ctx, hd2, m2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t2_up, \" s\")\n",
        "        var t2_gate = bench_layer_packed(ctx, hd2, m2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t2_gate, \" s\")\n",
        "        var t2_down = bench_layer_packed(ctx, hd2, m2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t2_down, \" s\")\n",
        "\n",
        "        var config2_time = t2_up + t2_gate + t2_down\n",
        "        print(\"  Config 2 total: \", config2_time, \" s\")\n",
        "        total_time += config2_time\n",
        "\n",
        "        # Config 3: hd=4096, m=14336\n",
        "        var hd3: Int = 4096\n",
        "        var m3: Int = 14336\n",
        "        print(\"\\nConfig 3: rows=\", hd3, \", cols=\", m3, \", n_weights=\", hd3 * m3)\n",
        "\n",
        "        var t3_up = bench_layer_packed(ctx, hd3, m3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t3_up, \" s\")\n",
        "        var t3_gate = bench_layer_packed(ctx, hd3, m3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t3_gate, \" s\")\n",
        "        var t3_down = bench_layer_packed(ctx, hd3, m3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t3_down, \" s\")\n",
        "\n",
        "        var config3_time = t3_up + t3_gate + t3_down\n",
        "        print(\"  Config 3 total: \", config3_time, \" s\")\n",
        "        total_time += config3_time\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"TOTAL Mojo NF4 dequant time:\", total_time, \"seconds\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        var unsloth_time: Float64 = 5.320246934890747\n",
        "        var speedup = unsloth_time / total_time\n",
        "        print(\"\\nUnsloth Triton time (ref): \", unsloth_time, \" s\")\n",
        "        print(\"Mojo kernel time:          \", total_time, \" s\")\n",
        "        print(\"Speedup (Triton / Mojo):   \", speedup, \"x\")\n",
        "\n",
        "        if speedup >= 1.15:\n",
        "            print(\"\\nâœ… SUCCESS: Achieved >= 1.15x speedup!\")\n",
        "        else:\n",
        "            print(\"\\nâŒ Need more optimization to reach 1.15x speedup\")\n"
      ],
      "metadata": {
        "id": "tfENexugl6ub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bbc110d-fc92-4a8f-df62-8cd351c1dedd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "NF4 Dequantization Benchmark (Mojo Packed 32-bit Store) L4 GPU\n",
            "============================================================\n",
            "\n",
            "--- Correctness Test ---\n",
            "idx\tCPU\t\tGPU\t\tdiff\n",
            "0 \t -0.010002136 \t -0.010002136 \t 0.0\n",
            "1 \t -0.0069618225 \t -0.0069618225 \t 0.0\n",
            "2 \t -0.0069618225 \t -0.0069618225 \t 0.0\n",
            "3 \t -0.0052490234 \t -0.0052490234 \t 0.0\n",
            "4 \t -0.0052490234 \t -0.0052490234 \t 0.0\n",
            "5 \t -0.0039482117 \t -0.0039482117 \t 0.0\n",
            "6 \t -0.0039482117 \t -0.0039482117 \t 0.0\n",
            "7 \t -0.0028438568 \t -0.0028438568 \t 0.0\n",
            "8 \t -0.0028438568 \t -0.0028438568 \t 0.0\n",
            "9 \t -0.0018472672 \t -0.0018472672 \t 0.0\n",
            "10 \t -0.0018472672 \t -0.0018472672 \t 0.0\n",
            "11 \t -0.00091028214 \t -0.00091028214 \t 0.0\n",
            "12 \t -0.00091028214 \t -0.00091028214 \t 0.0\n",
            "13 \t 0.0 \t 0.0 \t 0.0\n",
            "14 \t 0.0 \t 0.0 \t 0.0\n",
            "15 \t 0.0007958412 \t 0.0007958412 \t 0.0\n",
            "max_abs_diff = 0.0\n",
            "Correctness test PASSED!\n",
            "\n",
            "--- Unsloth-style Dequant Bench ---\n",
            "Each layer runs 1000 kernel launches.\n",
            "Using packed 32-bit store kernel:  256 x 4  = 1024 threads/block\n",
            "Each thread: 1 byte -> 2 fp16 -> 1 x 32-bit store\n",
            "\n",
            "Device: cuda\n",
            "\n",
            "Config 1: rows= 2048 , cols= 8192 , n_weights= 16777216\n",
            "  up_proj   :  0.13700711  s\n",
            "  gate_proj :  0.147153915  s\n",
            "  down_proj :  0.147892227  s\n",
            "  Config 1 total:  0.43205325199999994  s\n",
            "\n",
            "Config 2: rows= 1024 , cols= 4096 , n_weights= 4194304\n",
            "  up_proj   :  0.03583488  s\n",
            "  gate_proj :  0.02942464  s\n",
            "  down_proj :  0.027154432  s\n",
            "  Config 2 total:  0.092413952  s\n",
            "\n",
            "Config 3: rows= 4096 , cols= 14336 , n_weights= 58720256\n",
            "  up_proj   :  0.698252258  s\n",
            "  gate_proj :  0.708264953  s\n",
            "  down_proj :  0.70719281  s\n",
            "  Config 3 total:  2.113710021  s\n",
            "\n",
            "============================================================\n",
            "TOTAL Mojo NF4 dequant time: 2.638177225 seconds\n",
            "============================================================\n",
            "\n",
            "Unsloth Triton time (ref):  5.320246934890747  s\n",
            "Mojo kernel time:           2.638177225  s\n",
            "Speedup (Triton / Mojo):    2.0166374284770603 x\n",
            "\n",
            "âœ… SUCCESS: Achieved >= 1.15x speedup!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Warp per NF4 block **L4** GPU"
      ],
      "metadata": {
        "id": "O0JtfUskrtrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%mojo\n",
        "from gpu import block_idx, thread_idx, barrier\n",
        "from gpu.host import DeviceContext\n",
        "from gpu.memory import AddressSpace\n",
        "from memory import UnsafePointer, stack_allocation, bitcast\n",
        "from math import fma, ceildiv\n",
        "\n",
        "# -----------------------------\n",
        "# Types and constants\n",
        "# -----------------------------\n",
        "\n",
        "comptime packed_dtype = DType.uint8\n",
        "comptime f32_dtype = DType.float32\n",
        "comptime f16_dtype = DType.float16\n",
        "comptime u32_dtype = DType.uint32\n",
        "comptime u16_dtype = DType.uint16\n",
        "\n",
        "comptime U8 = Scalar[packed_dtype]\n",
        "comptime F32 = Scalar[f32_dtype]\n",
        "comptime F16 = Scalar[f16_dtype]\n",
        "comptime U32 = Scalar[u32_dtype]\n",
        "comptime U16 = Scalar[u16_dtype]\n",
        "\n",
        "# Bitsandbytes NF4 codebook\n",
        "comptime NF4_TABLE = InlineArray[F32, 16](\n",
        "    -1.0,\n",
        "    -0.6961928009986877,\n",
        "    -0.5250730514526367,\n",
        "    -0.39491748809814453,\n",
        "    -0.28444138169288635,\n",
        "    -0.18477343022823334,\n",
        "    -0.09105003625154495,\n",
        "    0.0,\n",
        "    0.07958029955625534,\n",
        "    0.16093020141124725,\n",
        "    0.24611230194568634,\n",
        "    0.33791524171829224,\n",
        "    0.44070982933044434,\n",
        "    0.5626170039176941,\n",
        "    0.7229568362236023,\n",
        "    1.0,\n",
        ")\n",
        "\n",
        "# NF4 layout / block structure\n",
        "comptime BLOCKSIZE_W = 64  # weights per NF4 block = 32 bytes\n",
        "comptime BYTES_PER_NF4_BLOCK = 32  # 64 weights / 2 = 32 bytes\n",
        "comptime STATE2_BLOCKSIZE = 256  # absmax entries per state2 scale\n",
        "comptime STATE2_SHIFT = 8  # log2(256) for bit shift\n",
        "\n",
        "# Warp-based tiling:\n",
        "# - 1 warp (32 threads) = 1 NF4 block (32 bytes = 64 weights)\n",
        "# - Each thread handles 1 byte = 2 weights\n",
        "# - Lane 0 computes scale, broadcasts via shared memory\n",
        "comptime WARP_SIZE = 32\n",
        "comptime WARPS_PER_BLOCK = 8  # 8 warps per CUDA block = 256 threads\n",
        "comptime THREADS_PER_BLOCK = WARP_SIZE * WARPS_PER_BLOCK  # 256\n",
        "\n",
        "# Each CUDA block handles 8 NF4 blocks (8 warps Ã— 32 bytes = 256 bytes = 512 weights)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# GPU kernel: WARP-PER-NF4-BLOCK with shared scale\n",
        "#   - 1 warp = 1 NF4 block (32 bytes = 64 weights)\n",
        "#   - Lane 0 computes scale once, stores to shared_scale[warp_id]\n",
        "#   - All 32 lanes read scale from shared, unpack, multiply, pack, store\n",
        "#   - Eliminates 31/32 redundant scale loads/computes per NF4 block\n",
        "# ------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "fn nf4_dequant_kernel_warp(\n",
        "    packed_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    out_ptr: UnsafePointer[U32, MutAnyOrigin],\n",
        "    n_nf4_blocks: Int,  # total NF4 blocks = n_weights / 64\n",
        "    n_bytes: Int,  # total bytes = n_weights / 2\n",
        "    groups_per_row: Int,  # for 1D layout: ceildiv(n_absmax, STATE2_BLOCKSIZE)\n",
        "):\n",
        "    # Shared memory for NF4 codebook (16 values)\n",
        "    var shared_nf4 = stack_allocation[\n",
        "        16, F32, address_space = AddressSpace.SHARED\n",
        "    ]()\n",
        "    # Shared memory for per-warp scales (one per warp in this CUDA block)\n",
        "    var shared_scale = stack_allocation[\n",
        "        WARPS_PER_BLOCK, F32, address_space = AddressSpace.SHARED\n",
        "    ]()\n",
        "\n",
        "    var tid = Int(thread_idx.x)\n",
        "    var warp_id = tid >> 5  # tid // 32\n",
        "    var lane_id = tid & 31  # tid % 32\n",
        "\n",
        "    # First 16 threads load the NF4 codebook\n",
        "    if tid < 16:\n",
        "        shared_nf4[tid] = NF4_TABLE[tid]\n",
        "\n",
        "    barrier()\n",
        "\n",
        "    # Global NF4 block index for this warp\n",
        "    var nf4_block_idx = Int(block_idx.x) * WARPS_PER_BLOCK + warp_id\n",
        "\n",
        "    if nf4_block_idx >= n_nf4_blocks:\n",
        "        return\n",
        "\n",
        "    # Lane 0 computes the scale for this NF4 block\n",
        "    if lane_id == 0:\n",
        "        # absmax_q for this NF4 block\n",
        "        var q_scale: U8 = absmax_q_ptr[nf4_block_idx]\n",
        "        var code_val: F32 = code2_ptr[Int(q_scale)]\n",
        "\n",
        "        # Group index for second-level scale\n",
        "        var group_id = nf4_block_idx >> STATE2_SHIFT  # nf4_block_idx // 256\n",
        "        var scale_base: F32 = scale2_ptr[group_id]\n",
        "\n",
        "        # Final scale = code2[absmax_q] * scale2 + offset\n",
        "        var scale: F32 = fma(code_val, scale_base, offset)\n",
        "        shared_scale[warp_id] = scale\n",
        "\n",
        "    barrier()\n",
        "\n",
        "    # All lanes read the scale from shared memory\n",
        "    var scale: F32 = shared_scale[warp_id]\n",
        "\n",
        "    # Global byte index for this thread\n",
        "    var byte_idx = nf4_block_idx * BYTES_PER_NF4_BLOCK + lane_id\n",
        "\n",
        "    if byte_idx >= n_bytes:\n",
        "        return\n",
        "\n",
        "    # Read the packed byte\n",
        "    var packed_byte: U8 = packed_ptr[byte_idx]\n",
        "    var packed_int: Int = Int(packed_byte)\n",
        "\n",
        "    # Extract low and high nibbles\n",
        "    var lo_idx: Int = packed_int & 0x0F\n",
        "    var hi_idx: Int = (packed_int >> 4) & 0x0F\n",
        "\n",
        "    # NF4 lookup from shared memory\n",
        "    var v0_norm: F32 = shared_nf4[lo_idx]\n",
        "    var v1_norm: F32 = shared_nf4[hi_idx]\n",
        "\n",
        "    # Dequantized values (just multiply by scale - no per-thread loads!)\n",
        "    var v0: F32 = v0_norm * scale\n",
        "    var v1: F32 = v1_norm * scale\n",
        "\n",
        "    # Convert to fp16\n",
        "    var h0: F16 = F16(v0)\n",
        "    var h1: F16 = F16(v1)\n",
        "\n",
        "    # Bitcast to u16\n",
        "    var b0: U16 = bitcast[u16_dtype](h0)\n",
        "    var b1: U16 = bitcast[u16_dtype](h1)\n",
        "\n",
        "    # Pack into 32-bit word: [h1:h0]\n",
        "    var packed_out: U32 = (U32(b1) << 16) | U32(b0)\n",
        "\n",
        "    # Store (one 32-bit word per byte)\n",
        "    out_ptr[byte_idx] = packed_out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# CPU reference (flat 1D layout)\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn nf4_dequant_cpu(\n",
        "    packed: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    output: UnsafePointer[F16, MutAnyOrigin],\n",
        "    n_bytes: Int,\n",
        "):\n",
        "    for byte_idx in range(n_bytes):\n",
        "        var packed_byte: U8 = packed[byte_idx]\n",
        "        var packed_int: Int = Int(packed_byte)\n",
        "\n",
        "        var lo_idx: Int = packed_int & 0x0F\n",
        "        var hi_idx: Int = (packed_int >> 4) & 0x0F\n",
        "\n",
        "        var v0_norm: F32 = NF4_TABLE[lo_idx]\n",
        "        var v1_norm: F32 = NF4_TABLE[hi_idx]\n",
        "\n",
        "        # NF4 block index for this byte\n",
        "        var nf4_block_idx = byte_idx >> 5  # byte_idx // 32\n",
        "\n",
        "        var q_scale: U8 = absmax_q[nf4_block_idx]\n",
        "        var code_val: F32 = code2[Int(q_scale)]\n",
        "\n",
        "        var group_id = nf4_block_idx >> STATE2_SHIFT\n",
        "        var scale_base: F32 = scale2[group_id]\n",
        "\n",
        "        var scale: F32 = fma(code_val, scale_base, offset)\n",
        "\n",
        "        var v0: F32 = v0_norm * scale\n",
        "        var v1: F32 = v1_norm * scale\n",
        "\n",
        "        var out_idx = byte_idx << 1  # byte_idx * 2\n",
        "        output[out_idx] = F16(v0)\n",
        "        output[out_idx + 1] = F16(v1)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Correctness check\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def run_correctness_test(ctx: DeviceContext):\n",
        "    # Small test: 512 weights = 8 NF4 blocks = 256 bytes\n",
        "    var n_weights: Int = 512\n",
        "    var n_bytes: Int = n_weights // 2\n",
        "    var n_nf4_blocks: Int = n_weights // BLOCKSIZE_W\n",
        "    var n_scale2: Int = ceildiv(n_nf4_blocks, STATE2_BLOCKSIZE)\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "    var groups_per_row: Int = n_scale2  # 1D layout\n",
        "\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_nf4_blocks)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "    var out_cpu_host = ctx.enqueue_create_host_buffer[f16_dtype](n_weights)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Fill deterministic pattern\n",
        "    for i in range(n_bytes):\n",
        "        var lo: Int = i % 16\n",
        "        var hi: Int = (i + 1) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    for i in range(n_nf4_blocks):\n",
        "        absmax_host[i] = U8(i % 16)\n",
        "\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    # CPU ref\n",
        "    nf4_dequant_cpu(\n",
        "        packed_host.unsafe_ptr(),\n",
        "        absmax_host.unsafe_ptr(),\n",
        "        code2_host.unsafe_ptr(),\n",
        "        scale2_host.unsafe_ptr(),\n",
        "        F32(offset),\n",
        "        out_cpu_host.unsafe_ptr(),\n",
        "        n_bytes,\n",
        "    )\n",
        "\n",
        "    # Device buffers\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_nf4_blocks)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    var out_dev = ctx.enqueue_create_buffer[u32_dtype](n_bytes)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "\n",
        "    # Grid: each CUDA block handles WARPS_PER_BLOCK NF4 blocks\n",
        "    var grid_size: Int = ceildiv(n_nf4_blocks, WARPS_PER_BLOCK)\n",
        "\n",
        "    ctx.enqueue_function_checked[\n",
        "        nf4_dequant_kernel_warp, nf4_dequant_kernel_warp\n",
        "    ](\n",
        "        packed_dev,\n",
        "        absmax_dev,\n",
        "        code2_dev,\n",
        "        scale2_dev,\n",
        "        F32(offset),\n",
        "        out_dev,\n",
        "        n_nf4_blocks,\n",
        "        n_bytes,\n",
        "        groups_per_row,\n",
        "        grid_dim=grid_size,\n",
        "        block_dim=THREADS_PER_BLOCK,\n",
        "    )\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Compare\n",
        "    with out_dev.map_to_host() as out_gpu_host:\n",
        "        var max_abs_diff: F32 = 0.0\n",
        "\n",
        "        print(\"idx\\tCPU\\t\\tGPU\\t\\tdiff\")\n",
        "        for i in range(n_bytes):\n",
        "            var packed_word: U32 = out_gpu_host[i]\n",
        "            var b0: U16 = U16(packed_word & 0xFFFF)\n",
        "            var b1: U16 = U16((packed_word >> 16) & 0xFFFF)\n",
        "            var gpu_v0: F16 = bitcast[f16_dtype](b0)\n",
        "            var gpu_v1: F16 = bitcast[f16_dtype](b1)\n",
        "\n",
        "            var idx0 = i * 2\n",
        "            var idx1 = idx0 + 1\n",
        "\n",
        "            var cpu_v0: F32 = F32(out_cpu_host[idx0])\n",
        "            var cpu_v1: F32 = F32(out_cpu_host[idx1])\n",
        "            var gpu_f0: F32 = F32(gpu_v0)\n",
        "            var gpu_f1: F32 = F32(gpu_v1)\n",
        "\n",
        "            var diff0: F32 = cpu_v0 - gpu_f0\n",
        "            var diff1: F32 = cpu_v1 - gpu_f1\n",
        "\n",
        "            if diff0 < 0.0:\n",
        "                diff0 = -diff0\n",
        "            if diff1 < 0.0:\n",
        "                diff1 = -diff1\n",
        "\n",
        "            if diff0 > max_abs_diff:\n",
        "                max_abs_diff = diff0\n",
        "            if diff1 > max_abs_diff:\n",
        "                max_abs_diff = diff1\n",
        "\n",
        "            if i < 8:\n",
        "                print(idx0, \"\\t\", cpu_v0, \"\\t\", gpu_f0, \"\\t\", cpu_v0 - gpu_f0)\n",
        "                print(idx1, \"\\t\", cpu_v1, \"\\t\", gpu_f1, \"\\t\", cpu_v1 - gpu_f1)\n",
        "\n",
        "        print(\"max_abs_diff =\", max_abs_diff)\n",
        "        print(\n",
        "            \"Correctness test PASSED!\" if max_abs_diff\n",
        "            < 1e-3 else \"Correctness test FAILED!\"\n",
        "        )\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Benchmark a single weight matrix\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn bench_layer_warp(\n",
        "    ctx: DeviceContext,\n",
        "    n_weights: Int,\n",
        "    num_iters: Int,\n",
        ") raises -> Float64:\n",
        "    \"\"\"\n",
        "    Benchmark warp-per-NF4-block kernel.\n",
        "    Returns: seconds (total time for num_iters iterations)\n",
        "    \"\"\"\n",
        "    var n_bytes = n_weights // 2\n",
        "    var n_nf4_blocks = n_weights // BLOCKSIZE_W\n",
        "    var n_scale2 = ceildiv(n_nf4_blocks, STATE2_BLOCKSIZE)\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "    var groups_per_row = n_scale2\n",
        "\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_nf4_blocks)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Fill patterns\n",
        "    for i in range(n_bytes):\n",
        "        var lo: Int = i % 16\n",
        "        var hi: Int = (i + 1) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    for i in range(n_nf4_blocks):\n",
        "        absmax_host[i] = U8(i % 16)\n",
        "\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    # Device buffers\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_nf4_blocks)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    var out_dev = ctx.enqueue_create_buffer[u32_dtype](n_bytes)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Grid size\n",
        "    var grid_size: Int = ceildiv(n_nf4_blocks, WARPS_PER_BLOCK)\n",
        "\n",
        "    # Compile once\n",
        "    var compiled_kernel = ctx.compile_function_checked[\n",
        "        nf4_dequant_kernel_warp, nf4_dequant_kernel_warp\n",
        "    ]()\n",
        "\n",
        "    @always_inline\n",
        "    @parameter\n",
        "    fn run_kernel(bench_ctx: DeviceContext) raises:\n",
        "        bench_ctx.enqueue_function_checked(\n",
        "            compiled_kernel,\n",
        "            packed_dev,\n",
        "            absmax_dev,\n",
        "            code2_dev,\n",
        "            scale2_dev,\n",
        "            F32(offset),\n",
        "            out_dev,\n",
        "            n_nf4_blocks,\n",
        "            n_bytes,\n",
        "            groups_per_row,\n",
        "            grid_dim=grid_size,\n",
        "            block_dim=THREADS_PER_BLOCK,\n",
        "        )\n",
        "\n",
        "    # Warmup\n",
        "    run_kernel(ctx)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    var total_ns = ctx.execution_time[run_kernel](num_iters)\n",
        "    var seconds: Float64 = Float64(total_ns) / 1e9\n",
        "\n",
        "    return seconds\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Unsloth-like benchmark harness\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def main():\n",
        "    with DeviceContext() as ctx:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"NF4 Dequantization Benchmark (Warp-per-NF4-Block) L4\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        print(\"\\n--- Correctness Test ---\")\n",
        "        run_correctness_test(ctx)\n",
        "\n",
        "        var NUM_ITERS_PER_LAYER: Int = 1000\n",
        "\n",
        "        print(\"\\n--- Unsloth-style Dequant Bench ---\")\n",
        "        print(\"Each layer runs\", NUM_ITERS_PER_LAYER, \"kernel launches.\")\n",
        "        print(\"Kernel: 1 warp = 1 NF4 block, lane 0 computes shared scale\")\n",
        "        print(\n",
        "            \"Threads per block:\",\n",
        "            THREADS_PER_BLOCK,\n",
        "            \"(\",\n",
        "            WARPS_PER_BLOCK,\n",
        "            \"warps)\",\n",
        "        )\n",
        "        print(\"\\nDevice:\", ctx.api())\n",
        "\n",
        "        var total_time: Float64 = 0.0\n",
        "\n",
        "        # Config 1: hd=2048, m=8192\n",
        "        var hd1: Int = 2048\n",
        "        var m1: Int = 8192\n",
        "        var n_w1: Int = hd1 * m1\n",
        "        print(\"\\nConfig 1: hd=\", hd1, \", m=\", m1, \", n_weights=\", n_w1)\n",
        "\n",
        "        var t1_up = bench_layer_warp(ctx, n_w1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t1_up, \" s\")\n",
        "        var t1_gate = bench_layer_warp(ctx, n_w1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t1_gate, \" s\")\n",
        "        var t1_down = bench_layer_warp(ctx, n_w1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t1_down, \" s\")\n",
        "\n",
        "        var config1_time = t1_up + t1_gate + t1_down\n",
        "        print(\"  Config 1 total: \", config1_time, \" s\")\n",
        "        total_time += config1_time\n",
        "\n",
        "        # Config 2: hd=1024, m=4096\n",
        "        var hd2: Int = 1024\n",
        "        var m2: Int = 4096\n",
        "        var n_w2: Int = hd2 * m2\n",
        "        print(\"\\nConfig 2: hd=\", hd2, \", m=\", m2, \", n_weights=\", n_w2)\n",
        "\n",
        "        var t2_up = bench_layer_warp(ctx, n_w2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t2_up, \" s\")\n",
        "        var t2_gate = bench_layer_warp(ctx, n_w2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t2_gate, \" s\")\n",
        "        var t2_down = bench_layer_warp(ctx, n_w2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t2_down, \" s\")\n",
        "\n",
        "        var config2_time = t2_up + t2_gate + t2_down\n",
        "        print(\"  Config 2 total: \", config2_time, \" s\")\n",
        "        total_time += config2_time\n",
        "\n",
        "        # Config 3: hd=4096, m=14336\n",
        "        var hd3: Int = 4096\n",
        "        var m3: Int = 14336\n",
        "        var n_w3: Int = hd3 * m3\n",
        "        print(\"\\nConfig 3: hd=\", hd3, \", m=\", m3, \", n_weights=\", n_w3)\n",
        "\n",
        "        var t3_up = bench_layer_warp(ctx, n_w3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t3_up, \" s\")\n",
        "        var t3_gate = bench_layer_warp(ctx, n_w3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t3_gate, \" s\")\n",
        "        var t3_down = bench_layer_warp(ctx, n_w3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t3_down, \" s\")\n",
        "\n",
        "        var config3_time = t3_up + t3_gate + t3_down\n",
        "        print(\"  Config 3 total: \", config3_time, \" s\")\n",
        "        total_time += config3_time\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"TOTAL Mojo NF4 dequant time:\", total_time, \"seconds\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        var unsloth_time: Float64 = 5.320246934890747\n",
        "        var speedup = unsloth_time / total_time\n",
        "        print(\"\\nUnsloth Triton time (ref): \", unsloth_time, \" s\")\n",
        "        print(\"Mojo kernel time:          \", total_time, \" s\")\n",
        "        print(\"Speedup (Triton / Mojo):   \", speedup, \"x\")\n",
        "\n",
        "        if speedup >= 1.15:\n",
        "            print(\"\\n SUCCESS: Achieved >= 1.15x speedup!\")\n",
        "        else:\n",
        "            print(\"\\n Need more optimization to reach 1.15x speedup\")\n"
      ],
      "metadata": {
        "id": "y__F8DgzrziZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d19894f0-516d-4657-d38f-03fff4faecf0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "NF4 Dequantization Benchmark (Warp-per-NF4-Block) L4\n",
            "============================================================\n",
            "\n",
            "--- Correctness Test ---\n",
            "idx\tCPU\t\tGPU\t\tdiff\n",
            "0 \t -0.010002136 \t -0.010002136 \t 0.0\n",
            "1 \t -0.0069618225 \t -0.0069618225 \t 0.0\n",
            "2 \t -0.0069618225 \t -0.0069618225 \t 0.0\n",
            "3 \t -0.0052490234 \t -0.0052490234 \t 0.0\n",
            "4 \t -0.0052490234 \t -0.0052490234 \t 0.0\n",
            "5 \t -0.0039482117 \t -0.0039482117 \t 0.0\n",
            "6 \t -0.0039482117 \t -0.0039482117 \t 0.0\n",
            "7 \t -0.0028438568 \t -0.0028438568 \t 0.0\n",
            "8 \t -0.0028438568 \t -0.0028438568 \t 0.0\n",
            "9 \t -0.0018472672 \t -0.0018472672 \t 0.0\n",
            "10 \t -0.0018472672 \t -0.0018472672 \t 0.0\n",
            "11 \t -0.00091028214 \t -0.00091028214 \t 0.0\n",
            "12 \t -0.00091028214 \t -0.00091028214 \t 0.0\n",
            "13 \t 0.0 \t 0.0 \t 0.0\n",
            "14 \t 0.0 \t 0.0 \t 0.0\n",
            "15 \t 0.0007958412 \t 0.0007958412 \t 0.0\n",
            "max_abs_diff = 0.0\n",
            "Correctness test PASSED!\n",
            "\n",
            "--- Unsloth-style Dequant Bench ---\n",
            "Each layer runs 1000 kernel launches.\n",
            "Kernel: 1 warp = 1 NF4 block, lane 0 computes shared scale\n",
            "Threads per block: 256 ( 8 warps)\n",
            "\n",
            "Device: cuda\n",
            "\n",
            "Config 1: hd= 2048 , m= 8192 , n_weights= 16777216\n",
            "  up_proj   :  0.134756347  s\n",
            "  gate_proj :  0.14079898  s\n",
            "  down_proj :  0.138979324  s\n",
            "  Config 1 total:  0.414534651  s\n",
            "\n",
            "Config 2: hd= 1024 , m= 4096 , n_weights= 4194304\n",
            "  up_proj   :  0.030687231  s\n",
            "  gate_proj :  0.025921535  s\n",
            "  down_proj :  0.023461887  s\n",
            "  Config 2 total:  0.08007065299999999  s\n",
            "\n",
            "Config 3: hd= 4096 , m= 14336 , n_weights= 58720256\n",
            "  up_proj   :  0.660671508  s\n",
            "  gate_proj :  0.664179687  s\n",
            "  down_proj :  0.663739379  s\n",
            "  Config 3 total:  1.9885905739999998  s\n",
            "\n",
            "============================================================\n",
            "TOTAL Mojo NF4 dequant time: 2.4831958779999996 seconds\n",
            "============================================================\n",
            "\n",
            "Unsloth Triton time (ref):  5.320246934890747  s\n",
            "Mojo kernel time:           2.4831958779999996  s\n",
            "Speedup (Triton / Mojo):    2.1424999058776417 x\n",
            "\n",
            " SUCCESS: Achieved >= 1.15x speedup!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kernel - 2D Tiling 32 bit Store **T4** GPU"
      ],
      "metadata": {
        "id": "KGOFCVoia_6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%mojo\n",
        "from gpu import block_idx, thread_idx, barrier\n",
        "from gpu.host import DeviceContext\n",
        "from gpu.memory import AddressSpace\n",
        "from memory import UnsafePointer, stack_allocation, bitcast\n",
        "from math import fma, ceildiv\n",
        "\n",
        "#######################\n",
        "# Types and Constants #\n",
        "#######################\n",
        "\n",
        "comptime packed_dtype = DType.uint8\n",
        "comptime f32_dtype = DType.float32\n",
        "comptime f16_dtype = DType.float16\n",
        "comptime u32_dtype = DType.uint32\n",
        "comptime u16_dtype = DType.uint16\n",
        "\n",
        "comptime U8 = Scalar[packed_dtype]\n",
        "comptime F32 = Scalar[f32_dtype]\n",
        "comptime F16 = Scalar[f16_dtype]\n",
        "comptime U32 = Scalar[u32_dtype]\n",
        "comptime U16 = Scalar[u16_dtype]\n",
        "\n",
        "# Bitsandbytes NF4 codebook\n",
        "comptime NF4_TABLE = InlineArray[F32, 16](\n",
        "    -1.0,\n",
        "    -0.6961928009986877,\n",
        "    -0.5250730514526367,\n",
        "    -0.39491748809814453,\n",
        "    -0.28444138169288635,\n",
        "    -0.18477343022823334,\n",
        "    -0.09105003625154495,\n",
        "    0.0,\n",
        "    0.07958029955625534,\n",
        "    0.16093020141124725,\n",
        "    0.24611230194568634,\n",
        "    0.33791524171829224,\n",
        "    0.44070982933044434,\n",
        "    0.5626170039176941,\n",
        "    0.7229568362236023,\n",
        "    1.0,\n",
        ")\n",
        "\n",
        "# NF4 layout / block structure\n",
        "comptime BLOCKSIZE_W = 64  # weights per NF4 block\n",
        "comptime BLOCKSIZE_W_SHIFT = 6  # log2(64) for bit shift\n",
        "comptime STATE2_BLOCKSIZE = 256  # absmax entries per state2 scale\n",
        "comptime STATE2_SHIFT = 8  # log2(256) for bit shift\n",
        "\n",
        "# 2D tiling: each thread handles 1 byte = 2 weights\n",
        "# Output as packed 32-bit (2 x fp16)\n",
        "comptime TILE_BYTES_X = 256  # bytes per block in X (= 512 weights)\n",
        "comptime TILE_ROWS = 4  # rows per block\n",
        "comptime THREADS_X = 256\n",
        "comptime THREADS_Y = 4\n",
        "# Total: 1024 threads per block, each outputs 32 bits (2 fp16)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# GPU kernel: PACKED 32-bit STORE\n",
        "#   - Each thread handles 1 packed byte = 2 weights\n",
        "#   - Outputs a single 32-bit word (2 x fp16 packed)\n",
        "#   - 256Ã—4 = 1024 threads per CUDA block\n",
        "#   - Shared memory for NF4 codebook\n",
        "# ---------------------------------------------------\n",
        "\n",
        "\n",
        "fn nf4_dequant_kernel_packed(\n",
        "    packed_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    out_ptr: UnsafePointer[U32, MutAnyOrigin],  # Output as packed 32-bit words\n",
        "    n_rows: Int,\n",
        "    n_bytes_per_row: Int,  # n_cols // 2\n",
        "    blocks_per_row: Int,\n",
        "    groups_per_row: Int,\n",
        "):\n",
        "    # Shared memory for NF4 codebook (16 values)\n",
        "    var shared_nf4 = stack_allocation[\n",
        "        16, F32, address_space = AddressSpace.SHARED\n",
        "    ]()\n",
        "\n",
        "    # First 16 threads of first row load the NF4 codebook\n",
        "    var tx = Int(thread_idx.x)\n",
        "    var ty = Int(thread_idx.y)\n",
        "    if ty == 0 and tx < 16:\n",
        "        shared_nf4[tx] = NF4_TABLE[tx]\n",
        "\n",
        "    barrier()\n",
        "\n",
        "    # 2D position: (row, byte_idx within row)\n",
        "    var row = Int(block_idx.x) * TILE_ROWS + ty\n",
        "    var byte_idx = Int(block_idx.y) * TILE_BYTES_X + tx\n",
        "\n",
        "    if row >= n_rows or byte_idx >= n_bytes_per_row:\n",
        "        return\n",
        "\n",
        "    # Read the packed byte\n",
        "    var packed_byte: U8 = packed_ptr[row * n_bytes_per_row + byte_idx]\n",
        "    var packed_int: Int = Int(packed_byte)\n",
        "\n",
        "    # Extract low and high nibbles\n",
        "    var lo_idx: Int = packed_int & 0x0F\n",
        "    var hi_idx: Int = (packed_int >> 4) & 0x0F\n",
        "\n",
        "    # NF4 lookup from shared memory\n",
        "    var v0_norm: F32 = shared_nf4[lo_idx]\n",
        "    var v1_norm: F32 = shared_nf4[hi_idx]\n",
        "\n",
        "    # Column index for weight 0 (col0 = byte_idx * 2)\n",
        "    var col0 = byte_idx << 1  # byte_idx * 2\n",
        "\n",
        "    # Compute block/group indices using bit shifts\n",
        "    var block_id = col0 >> BLOCKSIZE_W_SHIFT  # col0 // 64\n",
        "    var absmax_idx = row * blocks_per_row + block_id\n",
        "\n",
        "    # First-level dequant: absmax_q -> code2 lookup\n",
        "    var q_scale: U8 = absmax_q_ptr[absmax_idx]\n",
        "    var code_val: F32 = code2_ptr[Int(q_scale)]\n",
        "\n",
        "    # Second-level dequant: group scale\n",
        "    var group_id = block_id >> STATE2_SHIFT  # block_id // 256\n",
        "    var group_idx = row * groups_per_row + group_id\n",
        "    var scale_base: F32 = scale2_ptr[group_idx]\n",
        "\n",
        "    # Final scale = code2[absmax_q] * scale2 + offset\n",
        "    var scale: F32 = fma(code_val, scale_base, offset)\n",
        "\n",
        "    # Dequantized values\n",
        "    var v0: F32 = v0_norm * scale\n",
        "    var v1: F32 = v1_norm * scale\n",
        "\n",
        "    # Convert to fp16\n",
        "    var h0: F16 = F16(v0)\n",
        "    var h1: F16 = F16(v1)\n",
        "\n",
        "    # Bitcast to u16\n",
        "    var b0: U16 = bitcast[u16_dtype](h0)\n",
        "    var b1: U16 = bitcast[u16_dtype](h1)\n",
        "\n",
        "    # Pack into 32-bit word: [h1:h0] (h0 in low 16 bits, h1 in high 16 bits)\n",
        "    var packed_out: U32 = (U32(b1) << 16) | U32(b0)\n",
        "\n",
        "    # Output word index (one 32-bit word per byte = 2 weights)\n",
        "    # word_stride = n_bytes_per_row (since each byte -> one 32-bit word)\n",
        "    var word_idx = row * n_bytes_per_row + byte_idx\n",
        "\n",
        "    out_ptr[word_idx] = packed_out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# CPU reference (same logic, stores as fp16 pairs)\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn nf4_dequant_cpu_packed(\n",
        "    packed: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    output: UnsafePointer[\n",
        "        F16, MutAnyOrigin\n",
        "    ],  # CPU uses F16 for easier verification\n",
        "    n_rows: Int,\n",
        "    n_cols: Int,\n",
        "):\n",
        "    var n_bytes_per_row = n_cols >> 1\n",
        "    var blocks_per_row = (n_cols + BLOCKSIZE_W - 1) >> BLOCKSIZE_W_SHIFT\n",
        "    var groups_per_row = (blocks_per_row + STATE2_BLOCKSIZE - 1) >> STATE2_SHIFT\n",
        "\n",
        "    for row in range(n_rows):\n",
        "        var row_packed_base = row * n_bytes_per_row\n",
        "        var row_out_base = row * n_cols\n",
        "        var row_absmax_base = row * blocks_per_row\n",
        "        var row_group_base = row * groups_per_row\n",
        "\n",
        "        for byte_idx in range(n_bytes_per_row):\n",
        "            var packed_byte: U8 = packed[row_packed_base + byte_idx]\n",
        "            var packed_int: Int = Int(packed_byte)\n",
        "\n",
        "            var lo_idx: Int = packed_int & 0x0F\n",
        "            var hi_idx: Int = (packed_int >> 4) & 0x0F\n",
        "\n",
        "            var v0_norm: F32 = NF4_TABLE[lo_idx]\n",
        "            var v1_norm: F32 = NF4_TABLE[hi_idx]\n",
        "\n",
        "            var col0 = byte_idx << 1\n",
        "            var block_id = col0 >> BLOCKSIZE_W_SHIFT\n",
        "            var absmax_idx = row_absmax_base + block_id\n",
        "\n",
        "            var q_scale: U8 = absmax_q[absmax_idx]\n",
        "            var code_val: F32 = code2[Int(q_scale)]\n",
        "\n",
        "            var group_id = block_id >> STATE2_SHIFT\n",
        "            var group_idx = row_group_base + group_id\n",
        "            var scale_base: F32 = scale2[group_idx]\n",
        "\n",
        "            var scale: F32 = fma(code_val, scale_base, offset)\n",
        "\n",
        "            var v0: F32 = v0_norm * scale\n",
        "            var v1: F32 = v1_norm * scale\n",
        "\n",
        "            output[row_out_base + col0] = F16(v0)\n",
        "            output[row_out_base + col0 + 1] = F16(v1)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Correctness check\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def run_correctness_test(ctx: DeviceContext):\n",
        "    # Use a small 2D test case: 4 rows Ã— 128 cols\n",
        "    var n_rows: Int = 4\n",
        "    var n_cols: Int = 128\n",
        "    var n_weights: Int = n_rows * n_cols\n",
        "    var n_bytes: Int = n_weights // 2\n",
        "    var n_bytes_per_row: Int = n_cols // 2\n",
        "\n",
        "    var blocks_per_row = ceildiv(n_cols, BLOCKSIZE_W)\n",
        "    var n_absmax = n_rows * blocks_per_row\n",
        "    var groups_per_row = ceildiv(blocks_per_row, STATE2_BLOCKSIZE)\n",
        "    var n_scale2 = n_rows * groups_per_row\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_absmax)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "    var out_cpu_host = ctx.enqueue_create_host_buffer[f16_dtype](n_weights)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Fill deterministic pattern\n",
        "    for i in range(n_bytes):\n",
        "        var lo: Int = i % 16\n",
        "        var hi: Int = (i + 1) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    for i in range(n_absmax):\n",
        "        absmax_host[i] = U8(i % 16)\n",
        "\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    # CPU ref\n",
        "    nf4_dequant_cpu_packed(\n",
        "        packed_host.unsafe_ptr(),\n",
        "        absmax_host.unsafe_ptr(),\n",
        "        code2_host.unsafe_ptr(),\n",
        "        scale2_host.unsafe_ptr(),\n",
        "        F32(offset),\n",
        "        out_cpu_host.unsafe_ptr(),\n",
        "        n_rows,\n",
        "        n_cols,\n",
        "    )\n",
        "\n",
        "    # Device buffers\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_absmax)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    # Output buffer: n_bytes 32-bit words (each = 2 fp16)\n",
        "    var out_dev = ctx.enqueue_create_buffer[u32_dtype](n_bytes)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "\n",
        "    # 2D grid: grid_x = rows/TILE_ROWS, grid_y = bytes_per_row/TILE_BYTES_X\n",
        "    var grid_x: Int = ceildiv(n_rows, TILE_ROWS)\n",
        "    var grid_y: Int = ceildiv(n_bytes_per_row, TILE_BYTES_X)\n",
        "\n",
        "    ctx.enqueue_function_checked[\n",
        "        nf4_dequant_kernel_packed, nf4_dequant_kernel_packed\n",
        "    ](\n",
        "        packed_dev,\n",
        "        absmax_dev,\n",
        "        code2_dev,\n",
        "        scale2_dev,\n",
        "        F32(offset),\n",
        "        out_dev,\n",
        "        n_rows,\n",
        "        n_bytes_per_row,\n",
        "        blocks_per_row,\n",
        "        groups_per_row,\n",
        "        grid_dim=(grid_x, grid_y),\n",
        "        block_dim=(THREADS_X, THREADS_Y),\n",
        "    )\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Compare: unpack 32-bit GPU output to fp16 pairs\n",
        "    with out_dev.map_to_host() as out_gpu_host:\n",
        "        var max_abs_diff: F32 = 0.0\n",
        "\n",
        "        print(\"idx\\tCPU\\t\\tGPU\\t\\tdiff\")\n",
        "        for i in range(n_bytes):\n",
        "            var packed_word: U32 = out_gpu_host[i]\n",
        "            var b0: U16 = U16(packed_word & 0xFFFF)\n",
        "            var b1: U16 = U16((packed_word >> 16) & 0xFFFF)\n",
        "            var gpu_v0: F16 = bitcast[f16_dtype](b0)\n",
        "            var gpu_v1: F16 = bitcast[f16_dtype](b1)\n",
        "\n",
        "            var idx0 = i * 2\n",
        "            var idx1 = idx0 + 1\n",
        "\n",
        "            var cpu_v0: F32 = F32(out_cpu_host[idx0])\n",
        "            var cpu_v1: F32 = F32(out_cpu_host[idx1])\n",
        "            var gpu_f0: F32 = F32(gpu_v0)\n",
        "            var gpu_f1: F32 = F32(gpu_v1)\n",
        "\n",
        "            var diff0: F32 = cpu_v0 - gpu_f0\n",
        "            var diff1: F32 = cpu_v1 - gpu_f1\n",
        "\n",
        "            if diff0 < 0.0:\n",
        "                diff0 = -diff0\n",
        "            if diff1 < 0.0:\n",
        "                diff1 = -diff1\n",
        "\n",
        "            if diff0 > max_abs_diff:\n",
        "                max_abs_diff = diff0\n",
        "            if diff1 > max_abs_diff:\n",
        "                max_abs_diff = diff1\n",
        "\n",
        "            if i < 8:\n",
        "                print(idx0, \"\\t\", cpu_v0, \"\\t\", gpu_f0, \"\\t\", cpu_v0 - gpu_f0)\n",
        "                print(idx1, \"\\t\", cpu_v1, \"\\t\", gpu_f1, \"\\t\", cpu_v1 - gpu_f1)\n",
        "\n",
        "        print(\"max_abs_diff =\", max_abs_diff)\n",
        "        print(\n",
        "            \"Correctness test PASSED!\" if max_abs_diff\n",
        "            < 1e-3 else \"Correctness test FAILED!\"\n",
        "        )\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Benchmark a single weight matrix\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn bench_layer_packed(\n",
        "    ctx: DeviceContext,\n",
        "    n_rows: Int,\n",
        "    n_cols: Int,\n",
        "    num_iters: Int,\n",
        ") raises -> Float64:\n",
        "    \"\"\"\n",
        "    Benchmark packed 32-bit store kernel.\n",
        "    Returns: seconds (total time for num_iters iterations)\n",
        "    \"\"\"\n",
        "    var n_weights = n_rows * n_cols\n",
        "    var n_bytes = n_weights // 2\n",
        "    var n_bytes_per_row = n_cols // 2\n",
        "\n",
        "    var blocks_per_row = ceildiv(n_cols, BLOCKSIZE_W)\n",
        "    var n_absmax = n_rows * blocks_per_row\n",
        "    var groups_per_row = ceildiv(blocks_per_row, STATE2_BLOCKSIZE)\n",
        "    var n_scale2 = n_rows * groups_per_row\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_absmax)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Fill patterns\n",
        "    for i in range(n_bytes):\n",
        "        var lo: Int = i % 16\n",
        "        var hi: Int = (i + 1) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    for i in range(n_absmax):\n",
        "        absmax_host[i] = U8(i % 16)\n",
        "\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    # Device buffers\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_absmax)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    var out_dev = ctx.enqueue_create_buffer[u32_dtype](n_bytes)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # 2D grid\n",
        "    var grid_x: Int = ceildiv(n_rows, TILE_ROWS)\n",
        "    var grid_y: Int = ceildiv(n_bytes_per_row, TILE_BYTES_X)\n",
        "\n",
        "    # Compile once\n",
        "    var compiled_kernel = ctx.compile_function_checked[\n",
        "        nf4_dequant_kernel_packed, nf4_dequant_kernel_packed\n",
        "    ]()\n",
        "\n",
        "    @always_inline\n",
        "    @parameter\n",
        "    fn run_kernel(bench_ctx: DeviceContext) raises:\n",
        "        bench_ctx.enqueue_function_checked(\n",
        "            compiled_kernel,\n",
        "            packed_dev,\n",
        "            absmax_dev,\n",
        "            code2_dev,\n",
        "            scale2_dev,\n",
        "            F32(offset),\n",
        "            out_dev,\n",
        "            n_rows,\n",
        "            n_bytes_per_row,\n",
        "            blocks_per_row,\n",
        "            groups_per_row,\n",
        "            grid_dim=(grid_x, grid_y),\n",
        "            block_dim=(THREADS_X, THREADS_Y),\n",
        "        )\n",
        "\n",
        "    # Warmup\n",
        "    run_kernel(ctx)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    var total_ns = ctx.execution_time[run_kernel](num_iters)\n",
        "    var seconds: Float64 = Float64(total_ns) / 1e9\n",
        "\n",
        "    return seconds\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Unsloth-like benchmark harness\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def main():\n",
        "    with DeviceContext() as ctx:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"NF4 Dequantization Benchmark (Mojo Packed 32-bit Store) T4 GPU\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        print(\"\\n--- Correctness Test ---\")\n",
        "        run_correctness_test(ctx)\n",
        "\n",
        "        var NUM_ITERS_PER_LAYER: Int = 1000\n",
        "\n",
        "        print(\"\\n--- Unsloth-style Dequant Bench ---\")\n",
        "        print(\"Each layer runs\", NUM_ITERS_PER_LAYER, \"kernel launches.\")\n",
        "        print(\n",
        "            \"Using packed 32-bit store kernel: \",\n",
        "            THREADS_X,\n",
        "            \"x\",\n",
        "            THREADS_Y,\n",
        "            \" = 1024 threads/block\",\n",
        "        )\n",
        "        print(\"Each thread: 1 byte -> 2 fp16 -> 1 x 32-bit store\")\n",
        "        print(\"\\nDevice:\", ctx.api())\n",
        "\n",
        "        var total_time: Float64 = 0.0\n",
        "\n",
        "        # Config 1: hd=2048, m=8192\n",
        "        var hd1: Int = 2048\n",
        "        var m1: Int = 8192\n",
        "        print(\"\\nConfig 1: rows=\", hd1, \", cols=\", m1, \", n_weights=\", hd1 * m1)\n",
        "\n",
        "        var t1_up = bench_layer_packed(ctx, hd1, m1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t1_up, \" s\")\n",
        "        var t1_gate = bench_layer_packed(ctx, hd1, m1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t1_gate, \" s\")\n",
        "        var t1_down = bench_layer_packed(ctx, hd1, m1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t1_down, \" s\")\n",
        "\n",
        "        var config1_time = t1_up + t1_gate + t1_down\n",
        "        print(\"  Config 1 total: \", config1_time, \" s\")\n",
        "        total_time += config1_time\n",
        "\n",
        "        # Config 2: hd=1024, m=4096\n",
        "        var hd2: Int = 1024\n",
        "        var m2: Int = 4096\n",
        "        print(\"\\nConfig 2: rows=\", hd2, \", cols=\", m2, \", n_weights=\", hd2 * m2)\n",
        "\n",
        "        var t2_up = bench_layer_packed(ctx, hd2, m2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t2_up, \" s\")\n",
        "        var t2_gate = bench_layer_packed(ctx, hd2, m2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t2_gate, \" s\")\n",
        "        var t2_down = bench_layer_packed(ctx, hd2, m2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t2_down, \" s\")\n",
        "\n",
        "        var config2_time = t2_up + t2_gate + t2_down\n",
        "        print(\"  Config 2 total: \", config2_time, \" s\")\n",
        "        total_time += config2_time\n",
        "\n",
        "        # Config 3: hd=4096, m=14336\n",
        "        var hd3: Int = 4096\n",
        "        var m3: Int = 14336\n",
        "        print(\"\\nConfig 3: rows=\", hd3, \", cols=\", m3, \", n_weights=\", hd3 * m3)\n",
        "\n",
        "        var t3_up = bench_layer_packed(ctx, hd3, m3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t3_up, \" s\")\n",
        "        var t3_gate = bench_layer_packed(ctx, hd3, m3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t3_gate, \" s\")\n",
        "        var t3_down = bench_layer_packed(ctx, hd3, m3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t3_down, \" s\")\n",
        "\n",
        "        var config3_time = t3_up + t3_gate + t3_down\n",
        "        print(\"  Config 3 total: \", config3_time, \" s\")\n",
        "        total_time += config3_time\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"TOTAL Mojo NF4 dequant time:\", total_time, \"seconds\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        var unsloth_time: Float64 = 5.320246934890747\n",
        "        var speedup = unsloth_time / total_time\n",
        "        print(\"\\nUnsloth Triton time (ref): \", unsloth_time, \" s\")\n",
        "        print(\"Mojo kernel time:          \", total_time, \" s\")\n",
        "        print(\"Speedup (Triton / Mojo):   \", speedup, \"x\")\n",
        "\n",
        "        if speedup >= 1.15:\n",
        "            print(\"\\nâœ… SUCCESS: Achieved >= 1.15x speedup!\")\n",
        "        else:\n",
        "            print(\"\\nâŒ Need more optimization to reach 1.15x speedup\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc5df6f6-3172-4cbb-a771-6eb5992269cd",
        "id": "0kWa4xwma0cz"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "NF4 Dequantization Benchmark (Mojo Packed 32-bit Store) T4 GPU\n",
            "============================================================\n",
            "\n",
            "--- Correctness Test ---\n",
            "idx\tCPU\t\tGPU\t\tdiff\n",
            "0 \t -0.010002136 \t -0.010002136 \t 0.0\n",
            "1 \t -0.0069618225 \t -0.0069618225 \t 0.0\n",
            "2 \t -0.0069618225 \t -0.0069618225 \t 0.0\n",
            "3 \t -0.0052490234 \t -0.0052490234 \t 0.0\n",
            "4 \t -0.0052490234 \t -0.0052490234 \t 0.0\n",
            "5 \t -0.0039482117 \t -0.0039482117 \t 0.0\n",
            "6 \t -0.0039482117 \t -0.0039482117 \t 0.0\n",
            "7 \t -0.0028438568 \t -0.0028438568 \t 0.0\n",
            "8 \t -0.0028438568 \t -0.0028438568 \t 0.0\n",
            "9 \t -0.0018472672 \t -0.0018472672 \t 0.0\n",
            "10 \t -0.0018472672 \t -0.0018472672 \t 0.0\n",
            "11 \t -0.00091028214 \t -0.00091028214 \t 0.0\n",
            "12 \t -0.00091028214 \t -0.00091028214 \t 0.0\n",
            "13 \t 0.0 \t 0.0 \t 0.0\n",
            "14 \t 0.0 \t 0.0 \t 0.0\n",
            "15 \t 0.0007958412 \t 0.0007958412 \t 0.0\n",
            "max_abs_diff = 0.0\n",
            "Correctness test PASSED!\n",
            "\n",
            "--- Unsloth-style Dequant Bench ---\n",
            "Each layer runs 1000 kernel launches.\n",
            "Using packed 32-bit store kernel:  256 x 4  = 1024 threads/block\n",
            "Each thread: 1 byte -> 2 fp16 -> 1 x 32-bit store\n",
            "\n",
            "Device: cuda\n",
            "\n",
            "Config 1: rows= 2048 , cols= 8192 , n_weights= 16777216\n",
            "  up_proj   :  0.371830871  s\n",
            "  gate_proj :  0.28608789  s\n",
            "  down_proj :  0.281579345  s\n",
            "  Config 1 total:  0.939498106  s\n",
            "\n",
            "Config 2: rows= 1024 , cols= 4096 , n_weights= 4194304\n",
            "  up_proj   :  0.071737854  s\n",
            "  gate_proj :  0.071549949  s\n",
            "  down_proj :  0.071703201  s\n",
            "  Config 2 total:  0.21499100399999999  s\n",
            "\n",
            "Config 3: rows= 4096 , cols= 14336 , n_weights= 58720256\n",
            "  up_proj   :  1.080463867  s\n",
            "  gate_proj :  1.08239685  s\n",
            "  down_proj :  1.084506835  s\n",
            "  Config 3 total:  3.247367552  s\n",
            "\n",
            "============================================================\n",
            "TOTAL Mojo NF4 dequant time: 4.401856662 seconds\n",
            "============================================================\n",
            "\n",
            "Unsloth Triton time (ref):  5.320246934890747  s\n",
            "Mojo kernel time:           4.401856662  s\n",
            "Speedup (Triton / Mojo):    1.2086370237402217 x\n",
            "\n",
            "âœ… SUCCESS: Achieved >= 1.15x speedup!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Warp per NF4 block **T4** GPU"
      ],
      "metadata": {
        "id": "0ozzcVnXbIog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%mojo\n",
        "from gpu import block_idx, thread_idx, barrier\n",
        "from gpu.host import DeviceContext\n",
        "from gpu.memory import AddressSpace\n",
        "from memory import UnsafePointer, stack_allocation, bitcast\n",
        "from math import fma, ceildiv\n",
        "\n",
        "# -----------------------------\n",
        "# Types and constants\n",
        "# -----------------------------\n",
        "\n",
        "comptime packed_dtype = DType.uint8\n",
        "comptime f32_dtype = DType.float32\n",
        "comptime f16_dtype = DType.float16\n",
        "comptime u32_dtype = DType.uint32\n",
        "comptime u16_dtype = DType.uint16\n",
        "\n",
        "comptime U8 = Scalar[packed_dtype]\n",
        "comptime F32 = Scalar[f32_dtype]\n",
        "comptime F16 = Scalar[f16_dtype]\n",
        "comptime U32 = Scalar[u32_dtype]\n",
        "comptime U16 = Scalar[u16_dtype]\n",
        "\n",
        "# Bitsandbytes NF4 codebook\n",
        "comptime NF4_TABLE = InlineArray[F32, 16](\n",
        "    -1.0,\n",
        "    -0.6961928009986877,\n",
        "    -0.5250730514526367,\n",
        "    -0.39491748809814453,\n",
        "    -0.28444138169288635,\n",
        "    -0.18477343022823334,\n",
        "    -0.09105003625154495,\n",
        "    0.0,\n",
        "    0.07958029955625534,\n",
        "    0.16093020141124725,\n",
        "    0.24611230194568634,\n",
        "    0.33791524171829224,\n",
        "    0.44070982933044434,\n",
        "    0.5626170039176941,\n",
        "    0.7229568362236023,\n",
        "    1.0,\n",
        ")\n",
        "\n",
        "# NF4 layout / block structure\n",
        "comptime BLOCKSIZE_W = 64  # weights per NF4 block = 32 bytes\n",
        "comptime BYTES_PER_NF4_BLOCK = 32  # 64 weights / 2 = 32 bytes\n",
        "comptime STATE2_BLOCKSIZE = 256  # absmax entries per state2 scale\n",
        "comptime STATE2_SHIFT = 8  # log2(256) for bit shift\n",
        "\n",
        "# Warp-based tiling:\n",
        "# - 1 warp (32 threads) = 1 NF4 block (32 bytes = 64 weights)\n",
        "# - Each thread handles 1 byte = 2 weights\n",
        "# - Lane 0 computes scale, broadcasts via shared memory\n",
        "comptime WARP_SIZE = 32\n",
        "comptime WARPS_PER_BLOCK = 8  # 8 warps per CUDA block = 256 threads\n",
        "comptime THREADS_PER_BLOCK = WARP_SIZE * WARPS_PER_BLOCK  # 256\n",
        "\n",
        "# Each CUDA block handles 8 NF4 blocks (8 warps Ã— 32 bytes = 256 bytes = 512 weights)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# GPU kernel: WARP-PER-NF4-BLOCK with shared scale\n",
        "#   - 1 warp = 1 NF4 block (32 bytes = 64 weights)\n",
        "#   - Lane 0 computes scale once, stores to shared_scale[warp_id]\n",
        "#   - All 32 lanes read scale from shared, unpack, multiply, pack, store\n",
        "#   - Eliminates 31/32 redundant scale loads/computes per NF4 block\n",
        "# ------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "fn nf4_dequant_kernel_warp(\n",
        "    packed_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    out_ptr: UnsafePointer[U32, MutAnyOrigin],\n",
        "    n_nf4_blocks: Int,  # total NF4 blocks = n_weights / 64\n",
        "    n_bytes: Int,  # total bytes = n_weights / 2\n",
        "    groups_per_row: Int,  # for 1D layout: ceildiv(n_absmax, STATE2_BLOCKSIZE)\n",
        "):\n",
        "    # Shared memory for NF4 codebook (16 values)\n",
        "    var shared_nf4 = stack_allocation[\n",
        "        16, F32, address_space = AddressSpace.SHARED\n",
        "    ]()\n",
        "    # Shared memory for per-warp scales (one per warp in this CUDA block)\n",
        "    var shared_scale = stack_allocation[\n",
        "        WARPS_PER_BLOCK, F32, address_space = AddressSpace.SHARED\n",
        "    ]()\n",
        "\n",
        "    var tid = Int(thread_idx.x)\n",
        "    var warp_id = tid >> 5  # tid // 32\n",
        "    var lane_id = tid & 31  # tid % 32\n",
        "\n",
        "    # First 16 threads load the NF4 codebook\n",
        "    if tid < 16:\n",
        "        shared_nf4[tid] = NF4_TABLE[tid]\n",
        "\n",
        "    barrier()\n",
        "\n",
        "    # Global NF4 block index for this warp\n",
        "    var nf4_block_idx = Int(block_idx.x) * WARPS_PER_BLOCK + warp_id\n",
        "\n",
        "    if nf4_block_idx >= n_nf4_blocks:\n",
        "        return\n",
        "\n",
        "    # Lane 0 computes the scale for this NF4 block\n",
        "    if lane_id == 0:\n",
        "        # absmax_q for this NF4 block\n",
        "        var q_scale: U8 = absmax_q_ptr[nf4_block_idx]\n",
        "        var code_val: F32 = code2_ptr[Int(q_scale)]\n",
        "\n",
        "        # Group index for second-level scale\n",
        "        var group_id = nf4_block_idx >> STATE2_SHIFT  # nf4_block_idx // 256\n",
        "        var scale_base: F32 = scale2_ptr[group_id]\n",
        "\n",
        "        # Final scale = code2[absmax_q] * scale2 + offset\n",
        "        var scale: F32 = fma(code_val, scale_base, offset)\n",
        "        shared_scale[warp_id] = scale\n",
        "\n",
        "    barrier()\n",
        "\n",
        "    # All lanes read the scale from shared memory\n",
        "    var scale: F32 = shared_scale[warp_id]\n",
        "\n",
        "    # Global byte index for this thread\n",
        "    var byte_idx = nf4_block_idx * BYTES_PER_NF4_BLOCK + lane_id\n",
        "\n",
        "    if byte_idx >= n_bytes:\n",
        "        return\n",
        "\n",
        "    # Read the packed byte\n",
        "    var packed_byte: U8 = packed_ptr[byte_idx]\n",
        "    var packed_int: Int = Int(packed_byte)\n",
        "\n",
        "    # Extract low and high nibbles\n",
        "    var lo_idx: Int = packed_int & 0x0F\n",
        "    var hi_idx: Int = (packed_int >> 4) & 0x0F\n",
        "\n",
        "    # NF4 lookup from shared memory\n",
        "    var v0_norm: F32 = shared_nf4[lo_idx]\n",
        "    var v1_norm: F32 = shared_nf4[hi_idx]\n",
        "\n",
        "    # Dequantized values (just multiply by scale - no per-thread loads!)\n",
        "    var v0: F32 = v0_norm * scale\n",
        "    var v1: F32 = v1_norm * scale\n",
        "\n",
        "    # Convert to fp16\n",
        "    var h0: F16 = F16(v0)\n",
        "    var h1: F16 = F16(v1)\n",
        "\n",
        "    # Bitcast to u16\n",
        "    var b0: U16 = bitcast[u16_dtype](h0)\n",
        "    var b1: U16 = bitcast[u16_dtype](h1)\n",
        "\n",
        "    # Pack into 32-bit word: [h1:h0]\n",
        "    var packed_out: U32 = (U32(b1) << 16) | U32(b0)\n",
        "\n",
        "    # Store (one 32-bit word per byte)\n",
        "    out_ptr[byte_idx] = packed_out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# CPU reference (flat 1D layout)\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn nf4_dequant_cpu(\n",
        "    packed: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    output: UnsafePointer[F16, MutAnyOrigin],\n",
        "    n_bytes: Int,\n",
        "):\n",
        "    for byte_idx in range(n_bytes):\n",
        "        var packed_byte: U8 = packed[byte_idx]\n",
        "        var packed_int: Int = Int(packed_byte)\n",
        "\n",
        "        var lo_idx: Int = packed_int & 0x0F\n",
        "        var hi_idx: Int = (packed_int >> 4) & 0x0F\n",
        "\n",
        "        var v0_norm: F32 = NF4_TABLE[lo_idx]\n",
        "        var v1_norm: F32 = NF4_TABLE[hi_idx]\n",
        "\n",
        "        # NF4 block index for this byte\n",
        "        var nf4_block_idx = byte_idx >> 5  # byte_idx // 32\n",
        "\n",
        "        var q_scale: U8 = absmax_q[nf4_block_idx]\n",
        "        var code_val: F32 = code2[Int(q_scale)]\n",
        "\n",
        "        var group_id = nf4_block_idx >> STATE2_SHIFT\n",
        "        var scale_base: F32 = scale2[group_id]\n",
        "\n",
        "        var scale: F32 = fma(code_val, scale_base, offset)\n",
        "\n",
        "        var v0: F32 = v0_norm * scale\n",
        "        var v1: F32 = v1_norm * scale\n",
        "\n",
        "        var out_idx = byte_idx << 1  # byte_idx * 2\n",
        "        output[out_idx] = F16(v0)\n",
        "        output[out_idx + 1] = F16(v1)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Correctness check\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def run_correctness_test(ctx: DeviceContext):\n",
        "    # Small test: 512 weights = 8 NF4 blocks = 256 bytes\n",
        "    var n_weights: Int = 512\n",
        "    var n_bytes: Int = n_weights // 2\n",
        "    var n_nf4_blocks: Int = n_weights // BLOCKSIZE_W\n",
        "    var n_scale2: Int = ceildiv(n_nf4_blocks, STATE2_BLOCKSIZE)\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "    var groups_per_row: Int = n_scale2  # 1D layout\n",
        "\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_nf4_blocks)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "    var out_cpu_host = ctx.enqueue_create_host_buffer[f16_dtype](n_weights)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Fill deterministic pattern\n",
        "    for i in range(n_bytes):\n",
        "        var lo: Int = i % 16\n",
        "        var hi: Int = (i + 1) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    for i in range(n_nf4_blocks):\n",
        "        absmax_host[i] = U8(i % 16)\n",
        "\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    # CPU ref\n",
        "    nf4_dequant_cpu(\n",
        "        packed_host.unsafe_ptr(),\n",
        "        absmax_host.unsafe_ptr(),\n",
        "        code2_host.unsafe_ptr(),\n",
        "        scale2_host.unsafe_ptr(),\n",
        "        F32(offset),\n",
        "        out_cpu_host.unsafe_ptr(),\n",
        "        n_bytes,\n",
        "    )\n",
        "\n",
        "    # Device buffers\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_nf4_blocks)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    var out_dev = ctx.enqueue_create_buffer[u32_dtype](n_bytes)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "\n",
        "    # Grid: each CUDA block handles WARPS_PER_BLOCK NF4 blocks\n",
        "    var grid_size: Int = ceildiv(n_nf4_blocks, WARPS_PER_BLOCK)\n",
        "\n",
        "    ctx.enqueue_function_checked[\n",
        "        nf4_dequant_kernel_warp, nf4_dequant_kernel_warp\n",
        "    ](\n",
        "        packed_dev,\n",
        "        absmax_dev,\n",
        "        code2_dev,\n",
        "        scale2_dev,\n",
        "        F32(offset),\n",
        "        out_dev,\n",
        "        n_nf4_blocks,\n",
        "        n_bytes,\n",
        "        groups_per_row,\n",
        "        grid_dim=grid_size,\n",
        "        block_dim=THREADS_PER_BLOCK,\n",
        "    )\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Compare\n",
        "    with out_dev.map_to_host() as out_gpu_host:\n",
        "        var max_abs_diff: F32 = 0.0\n",
        "\n",
        "        print(\"idx\\tCPU\\t\\tGPU\\t\\tdiff\")\n",
        "        for i in range(n_bytes):\n",
        "            var packed_word: U32 = out_gpu_host[i]\n",
        "            var b0: U16 = U16(packed_word & 0xFFFF)\n",
        "            var b1: U16 = U16((packed_word >> 16) & 0xFFFF)\n",
        "            var gpu_v0: F16 = bitcast[f16_dtype](b0)\n",
        "            var gpu_v1: F16 = bitcast[f16_dtype](b1)\n",
        "\n",
        "            var idx0 = i * 2\n",
        "            var idx1 = idx0 + 1\n",
        "\n",
        "            var cpu_v0: F32 = F32(out_cpu_host[idx0])\n",
        "            var cpu_v1: F32 = F32(out_cpu_host[idx1])\n",
        "            var gpu_f0: F32 = F32(gpu_v0)\n",
        "            var gpu_f1: F32 = F32(gpu_v1)\n",
        "\n",
        "            var diff0: F32 = cpu_v0 - gpu_f0\n",
        "            var diff1: F32 = cpu_v1 - gpu_f1\n",
        "\n",
        "            if diff0 < 0.0:\n",
        "                diff0 = -diff0\n",
        "            if diff1 < 0.0:\n",
        "                diff1 = -diff1\n",
        "\n",
        "            if diff0 > max_abs_diff:\n",
        "                max_abs_diff = diff0\n",
        "            if diff1 > max_abs_diff:\n",
        "                max_abs_diff = diff1\n",
        "\n",
        "            if i < 8:\n",
        "                print(idx0, \"\\t\", cpu_v0, \"\\t\", gpu_f0, \"\\t\", cpu_v0 - gpu_f0)\n",
        "                print(idx1, \"\\t\", cpu_v1, \"\\t\", gpu_f1, \"\\t\", cpu_v1 - gpu_f1)\n",
        "\n",
        "        print(\"max_abs_diff =\", max_abs_diff)\n",
        "        print(\n",
        "            \"Correctness test PASSED!\" if max_abs_diff\n",
        "            < 1e-3 else \"Correctness test FAILED!\"\n",
        "        )\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Benchmark a single weight matrix\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn bench_layer_warp(\n",
        "    ctx: DeviceContext,\n",
        "    n_weights: Int,\n",
        "    num_iters: Int,\n",
        ") raises -> Float64:\n",
        "    \"\"\"\n",
        "    Benchmark warp-per-NF4-block kernel.\n",
        "    Returns: seconds (total time for num_iters iterations)\n",
        "    \"\"\"\n",
        "    var n_bytes = n_weights // 2\n",
        "    var n_nf4_blocks = n_weights // BLOCKSIZE_W\n",
        "    var n_scale2 = ceildiv(n_nf4_blocks, STATE2_BLOCKSIZE)\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "    var groups_per_row = n_scale2\n",
        "\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_nf4_blocks)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Fill patterns\n",
        "    for i in range(n_bytes):\n",
        "        var lo: Int = i % 16\n",
        "        var hi: Int = (i + 1) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    for i in range(n_nf4_blocks):\n",
        "        absmax_host[i] = U8(i % 16)\n",
        "\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    # Device buffers\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_bytes)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_nf4_blocks)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    var out_dev = ctx.enqueue_create_buffer[u32_dtype](n_bytes)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Grid size\n",
        "    var grid_size: Int = ceildiv(n_nf4_blocks, WARPS_PER_BLOCK)\n",
        "\n",
        "    # Compile once\n",
        "    var compiled_kernel = ctx.compile_function_checked[\n",
        "        nf4_dequant_kernel_warp, nf4_dequant_kernel_warp\n",
        "    ]()\n",
        "\n",
        "    @always_inline\n",
        "    @parameter\n",
        "    fn run_kernel(bench_ctx: DeviceContext) raises:\n",
        "        bench_ctx.enqueue_function_checked(\n",
        "            compiled_kernel,\n",
        "            packed_dev,\n",
        "            absmax_dev,\n",
        "            code2_dev,\n",
        "            scale2_dev,\n",
        "            F32(offset),\n",
        "            out_dev,\n",
        "            n_nf4_blocks,\n",
        "            n_bytes,\n",
        "            groups_per_row,\n",
        "            grid_dim=grid_size,\n",
        "            block_dim=THREADS_PER_BLOCK,\n",
        "        )\n",
        "\n",
        "    # Warmup\n",
        "    run_kernel(ctx)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    var total_ns = ctx.execution_time[run_kernel](num_iters)\n",
        "    var seconds: Float64 = Float64(total_ns) / 1e9\n",
        "\n",
        "    return seconds\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Unsloth-like benchmark harness\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def main():\n",
        "    with DeviceContext() as ctx:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"NF4 Dequantization Benchmark (Warp-per-NF4-Block) T4\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        print(\"\\n--- Correctness Test ---\")\n",
        "        run_correctness_test(ctx)\n",
        "\n",
        "        var NUM_ITERS_PER_LAYER: Int = 1000\n",
        "\n",
        "        print(\"\\n--- Unsloth-style Dequant Bench ---\")\n",
        "        print(\"Each layer runs\", NUM_ITERS_PER_LAYER, \"kernel launches.\")\n",
        "        print(\"Kernel: 1 warp = 1 NF4 block, lane 0 computes shared scale\")\n",
        "        print(\n",
        "            \"Threads per block:\",\n",
        "            THREADS_PER_BLOCK,\n",
        "            \"(\",\n",
        "            WARPS_PER_BLOCK,\n",
        "            \"warps)\",\n",
        "        )\n",
        "        print(\"\\nDevice:\", ctx.api())\n",
        "\n",
        "        var total_time: Float64 = 0.0\n",
        "\n",
        "        # Config 1: hd=2048, m=8192\n",
        "        var hd1: Int = 2048\n",
        "        var m1: Int = 8192\n",
        "        var n_w1: Int = hd1 * m1\n",
        "        print(\"\\nConfig 1: hd=\", hd1, \", m=\", m1, \", n_weights=\", n_w1)\n",
        "\n",
        "        var t1_up = bench_layer_warp(ctx, n_w1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t1_up, \" s\")\n",
        "        var t1_gate = bench_layer_warp(ctx, n_w1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t1_gate, \" s\")\n",
        "        var t1_down = bench_layer_warp(ctx, n_w1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t1_down, \" s\")\n",
        "\n",
        "        var config1_time = t1_up + t1_gate + t1_down\n",
        "        print(\"  Config 1 total: \", config1_time, \" s\")\n",
        "        total_time += config1_time\n",
        "\n",
        "        # Config 2: hd=1024, m=4096\n",
        "        var hd2: Int = 1024\n",
        "        var m2: Int = 4096\n",
        "        var n_w2: Int = hd2 * m2\n",
        "        print(\"\\nConfig 2: hd=\", hd2, \", m=\", m2, \", n_weights=\", n_w2)\n",
        "\n",
        "        var t2_up = bench_layer_warp(ctx, n_w2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t2_up, \" s\")\n",
        "        var t2_gate = bench_layer_warp(ctx, n_w2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t2_gate, \" s\")\n",
        "        var t2_down = bench_layer_warp(ctx, n_w2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t2_down, \" s\")\n",
        "\n",
        "        var config2_time = t2_up + t2_gate + t2_down\n",
        "        print(\"  Config 2 total: \", config2_time, \" s\")\n",
        "        total_time += config2_time\n",
        "\n",
        "        # Config 3: hd=4096, m=14336\n",
        "        var hd3: Int = 4096\n",
        "        var m3: Int = 14336\n",
        "        var n_w3: Int = hd3 * m3\n",
        "        print(\"\\nConfig 3: hd=\", hd3, \", m=\", m3, \", n_weights=\", n_w3)\n",
        "\n",
        "        var t3_up = bench_layer_warp(ctx, n_w3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t3_up, \" s\")\n",
        "        var t3_gate = bench_layer_warp(ctx, n_w3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t3_gate, \" s\")\n",
        "        var t3_down = bench_layer_warp(ctx, n_w3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t3_down, \" s\")\n",
        "\n",
        "        var config3_time = t3_up + t3_gate + t3_down\n",
        "        print(\"  Config 3 total: \", config3_time, \" s\")\n",
        "        total_time += config3_time\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"TOTAL Mojo NF4 dequant time:\", total_time, \"seconds\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        var unsloth_time: Float64 = 5.320246934890747\n",
        "        var speedup = unsloth_time / total_time\n",
        "        print(\"\\nUnsloth Triton time (ref): \", unsloth_time, \" s\")\n",
        "        print(\"Mojo kernel time:          \", total_time, \" s\")\n",
        "        print(\"Speedup (Triton / Mojo):   \", speedup, \"x\")\n",
        "\n",
        "        if speedup >= 1.15:\n",
        "            print(\"\\n SUCCESS: Achieved >= 1.15x speedup!\")\n",
        "        else:\n",
        "            print(\"\\n Need more optimization to reach 1.15x speedup\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ce1000-c652-4aaf-a8cc-e970534c47a0",
        "collapsed": true,
        "id": "OAe2wyoobLJ_"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "NF4 Dequantization Benchmark (Warp-per-NF4-Block) T4\n",
            "============================================================\n",
            "\n",
            "--- Correctness Test ---\n",
            "idx\tCPU\t\tGPU\t\tdiff\n",
            "0 \t -0.010002136 \t -0.010002136 \t 0.0\n",
            "1 \t -0.0069618225 \t -0.0069618225 \t 0.0\n",
            "2 \t -0.0069618225 \t -0.0069618225 \t 0.0\n",
            "3 \t -0.0052490234 \t -0.0052490234 \t 0.0\n",
            "4 \t -0.0052490234 \t -0.0052490234 \t 0.0\n",
            "5 \t -0.0039482117 \t -0.0039482117 \t 0.0\n",
            "6 \t -0.0039482117 \t -0.0039482117 \t 0.0\n",
            "7 \t -0.0028438568 \t -0.0028438568 \t 0.0\n",
            "8 \t -0.0028438568 \t -0.0028438568 \t 0.0\n",
            "9 \t -0.0018472672 \t -0.0018472672 \t 0.0\n",
            "10 \t -0.0018472672 \t -0.0018472672 \t 0.0\n",
            "11 \t -0.00091028214 \t -0.00091028214 \t 0.0\n",
            "12 \t -0.00091028214 \t -0.00091028214 \t 0.0\n",
            "13 \t 0.0 \t 0.0 \t 0.0\n",
            "14 \t 0.0 \t 0.0 \t 0.0\n",
            "15 \t 0.0007958412 \t 0.0007958412 \t 0.0\n",
            "max_abs_diff = 0.0\n",
            "Correctness test PASSED!\n",
            "\n",
            "--- Unsloth-style Dequant Bench ---\n",
            "Each layer runs 1000 kernel launches.\n",
            "Kernel: 1 warp = 1 NF4 block, lane 0 computes shared scale\n",
            "Threads per block: 256 ( 8 warps)\n",
            "\n",
            "Device: cuda\n",
            "\n",
            "Config 1: hd= 2048 , m= 8192 , n_weights= 16777216\n",
            "  up_proj   :  0.406881134  s\n",
            "  gate_proj :  0.316723968  s\n",
            "  down_proj :  0.317738555  s\n",
            "  Config 1 total:  1.041343657  s\n",
            "\n",
            "Config 2: hd= 1024 , m= 4096 , n_weights= 4194304\n",
            "  up_proj   :  0.084346878  s\n",
            "  gate_proj :  0.085194046  s\n",
            "  down_proj :  0.082380668  s\n",
            "  Config 2 total:  0.25192159199999997  s\n",
            "\n",
            "Config 3: hd= 4096 , m= 14336 , n_weights= 58720256\n",
            "  up_proj   :  1.12642041  s\n",
            "  gate_proj :  1.128503295  s\n",
            "  down_proj :  1.131995117  s\n",
            "  Config 3 total:  3.386918822  s\n",
            "\n",
            "============================================================\n",
            "TOTAL Mojo NF4 dequant time: 4.680184071 seconds\n",
            "============================================================\n",
            "\n",
            "Unsloth Triton time (ref):  5.320246934890747  s\n",
            "Mojo kernel time:           4.680184071  s\n",
            "Speedup (Triton / Mojo):    1.1367601902362756 x\n",
            "\n",
            " Need more optimization to reach 1.15x speedup\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other Kernel Versions"
      ],
      "metadata": {
        "id": "nn5e1TCDVoYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kernel 0 â€“ Naive Flat Grid (Baseline, ~25.3 s)\n",
        "\n",
        "This is the first working Mojo kernel: a 1D flat grid with 256 threads per block, each thread handling a single NF4 byte (two weights), no shared memory, no tiling. Itâ€™s simple and good for validating the NF4 + double-dequant math and the timing harness, but on a T4 it lands around 25.3 seconds for the Unsloth test_dequantize workload. roughly 5Ã— slower than the Triton reference and a  â€œstarting pointâ€ to compare the later optimized versions against."
      ],
      "metadata": {
        "id": "WZgSUBs4YeH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%mojo\n",
        "from gpu import block_idx, thread_idx, block_dim\n",
        "from gpu.host import DeviceContext\n",
        "from memory import UnsafePointer\n",
        "from math import fma, ceildiv\n",
        "\n",
        "\n",
        "#######################\n",
        "# Types and Constants #\n",
        "#######################\n",
        "\n",
        "comptime packed_dtype = DType.uint8\n",
        "comptime f32_dtype = DType.float32\n",
        "comptime f16_dtype = DType.float16\n",
        "\n",
        "comptime U8 = Scalar[packed_dtype]\n",
        "comptime F32 = Scalar[f32_dtype]\n",
        "comptime F16 = Scalar[f16_dtype]\n",
        "\n",
        "# Bitsandbytes NF4 codebook\n",
        "comptime NF4_TABLE = InlineArray[F32, 16](\n",
        "    -1.0,\n",
        "    -0.6961928009986877,\n",
        "    -0.5250730514526367,\n",
        "    -0.39491748809814453,\n",
        "    -0.28444138169288635,\n",
        "    -0.18477343022823334,\n",
        "    -0.09105003625154495,\n",
        "    0.0,\n",
        "    0.07958029955625534,\n",
        "    0.16093020141124725,\n",
        "    0.24611230194568634,\n",
        "    0.33791524171829224,\n",
        "    0.44070982933044434,\n",
        "    0.5626170039176941,\n",
        "    0.7229568362236023,\n",
        "    1.0,\n",
        ")\n",
        "\n",
        "# NF4 layout / block structure\n",
        "comptime BLOCKSIZE_W = 64  # weights per NF4 block\n",
        "comptime PAIRS_PER_BLOCK = BLOCKSIZE_W // 2  # 32 bytes per 64 weights\n",
        "comptime STATE2_BLOCKSIZE = 256  # absmax entries per state2 scale\n",
        "\n",
        "# Kernel launch config\n",
        "comptime THREADS_PER_BLOCK = 256  # Flat grid: 256 threads per CUDA block\n",
        "\n",
        "\n",
        "########################################################\n",
        "# GPU kernel: FLAT GRID approach                       #\n",
        "#   - Each thread handles 1 byte (2 weights) globally  #\n",
        "#   - 256 threads per CUDA block for high occupancy.   #\n",
        "#   - No shared memory, no barrier                     #\n",
        "########################################################\n",
        "\n",
        "\n",
        "fn nf4_dequant_kernel(\n",
        "    packed_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    out_ptr: UnsafePointer[F16, MutAnyOrigin],\n",
        "    n_pairs: Int,  # total bytes (2 weights per byte)\n",
        "    n_weights: Int,  # total weights\n",
        "):\n",
        "    # Global thread ID = byte index (pair index)\n",
        "    var tid = Int(block_idx.x) * THREADS_PER_BLOCK + Int(thread_idx.x)\n",
        "    if tid >= n_pairs:\n",
        "        return\n",
        "\n",
        "    # Which NF4 block (64 weights = 32 bytes) does this byte belong to?\n",
        "    var absmax_idx = tid // PAIRS_PER_BLOCK\n",
        "\n",
        "    # Dequantize the absmax scale\n",
        "    var q_abs: U8 = absmax_q_ptr[absmax_idx]\n",
        "    var code_val: F32 = code2_ptr[Int(q_abs)]\n",
        "\n",
        "    # Second-level scale index (one per 256 absmax entries)\n",
        "    var scale_idx = absmax_idx >> 8  # absmax_idx // 256\n",
        "    var scale_base: F32 = scale2_ptr[scale_idx]\n",
        "    var scale: F32 = fma(code_val, scale_base, offset)\n",
        "\n",
        "    # Unpack two nf4 4-bit codes from this byte\n",
        "    var packed_val: U8 = packed_ptr[tid]\n",
        "    var packed_int: Int = Int(packed_val)\n",
        "\n",
        "    var hi_idx: Int = (packed_int >> 4) & 0x0F\n",
        "    var lo_idx: Int = packed_int & 0x0F\n",
        "\n",
        "    var v0: F32 = NF4_TABLE[hi_idx] * scale\n",
        "    var v1: F32 = NF4_TABLE[lo_idx] * scale\n",
        "\n",
        "    var i0: Int = tid * 2\n",
        "    var i1: Int = i0 + 1\n",
        "\n",
        "    if i0 < n_weights:\n",
        "        out_ptr[i0] = F16(v0)\n",
        "    if i1 < n_weights:\n",
        "        out_ptr[i1] = F16(v1)\n",
        "\n",
        "\n",
        "############################################\n",
        "# CPU reference - uses same math as kernel #\n",
        "############################################\n",
        "\n",
        "\n",
        "fn nf4_dequant_cpu(\n",
        "    packed: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    output: UnsafePointer[F16, MutAnyOrigin],\n",
        "    n_pairs: Int,\n",
        "    n_weights: Int,\n",
        "):\n",
        "    # Iterate over all bytes (pairs)\n",
        "    for tid in range(n_pairs):\n",
        "        # Which NF4 block does this byte belong to?\n",
        "        var absmax_idx = tid // PAIRS_PER_BLOCK\n",
        "\n",
        "        # Dequantize the absmax scale (double quant)\n",
        "        var q_abs: U8 = absmax_q[absmax_idx]\n",
        "        var code_val: F32 = code2[Int(q_abs)]\n",
        "\n",
        "        var scale_idx = absmax_idx >> 8\n",
        "        var scale_base: F32 = scale2[scale_idx]\n",
        "        var scale: F32 = fma(code_val, scale_base, offset)\n",
        "\n",
        "        # Unpack two nf4 4-bit codes\n",
        "        var packed_val: U8 = packed[tid]\n",
        "        var packed_int: Int = Int(packed_val)\n",
        "\n",
        "        var hi_idx: Int = (packed_int >> 4) & 0x0F\n",
        "        var lo_idx: Int = packed_int & 0x0F\n",
        "\n",
        "        var v0: F32 = NF4_TABLE[hi_idx] * scale\n",
        "        var v1: F32 = NF4_TABLE[lo_idx] * scale\n",
        "\n",
        "        var i0: Int = tid * 2\n",
        "        var i1: Int = i0 + 1\n",
        "\n",
        "        if i0 < n_weights:\n",
        "            output[i0] = F16(v0)\n",
        "        if i1 < n_weights:\n",
        "            output[i1] = F16(v1)\n",
        "\n",
        "\n",
        "#####################\n",
        "# Correctness Check #\n",
        "#####################\n",
        "\n",
        "def run_correctness_test(ctx: DeviceContext):\n",
        "    var n_weights: Int = 64\n",
        "    var n_pairs: Int = n_weights // 2\n",
        "    var n_absmax: Int = ceildiv(n_weights, BLOCKSIZE_W)\n",
        "    var n_scale2: Int = ceildiv(n_absmax, STATE2_BLOCKSIZE)\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_pairs)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_absmax)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "    var out_cpu_host = ctx.enqueue_create_host_buffer[f16_dtype](n_weights)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Fill deterministic pattern\n",
        "    for i in range(n_pairs):\n",
        "        var hi: Int = i % 16\n",
        "        var lo: Int = (15 - i) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    absmax_host[0] = U8(3)\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    # CPU ref\n",
        "    var packed_ptr = packed_host.unsafe_ptr()\n",
        "    var absmax_ptr = absmax_host.unsafe_ptr()\n",
        "    var code2_ptr = code2_host.unsafe_ptr()\n",
        "    var scale2_ptr = scale2_host.unsafe_ptr()\n",
        "    var out_cpu_ptr = out_cpu_host.unsafe_ptr()\n",
        "\n",
        "    nf4_dequant_cpu(\n",
        "        packed_ptr,\n",
        "        absmax_ptr,\n",
        "        code2_ptr,\n",
        "        scale2_ptr,\n",
        "        F32(offset),\n",
        "        out_cpu_ptr,\n",
        "        n_pairs,\n",
        "        n_weights,\n",
        "    )\n",
        "\n",
        "    # Device buffers\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_pairs)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_absmax)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    var out_dev = ctx.enqueue_create_buffer[f16_dtype](n_weights)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "\n",
        "    # Launch kernel: flat grid, 256 threads/block\n",
        "    var blocks: Int = ceildiv(n_pairs, THREADS_PER_BLOCK)\n",
        "\n",
        "    ctx.enqueue_function_checked[nf4_dequant_kernel, nf4_dequant_kernel](\n",
        "        packed_dev,\n",
        "        absmax_dev,\n",
        "        code2_dev,\n",
        "        scale2_dev,\n",
        "        F32(offset),\n",
        "        out_dev,\n",
        "        n_pairs,\n",
        "        n_weights,\n",
        "        grid_dim=blocks,\n",
        "        block_dim=THREADS_PER_BLOCK,\n",
        "    )\n",
        "    ctx.synchronize()\n",
        "\n",
        "    with out_dev.map_to_host() as out_gpu_host:\n",
        "        var max_abs_diff: F32 = 0.0\n",
        "\n",
        "        print(\"idx\\tCPU\\t\\tGPU\\t\\tdiff\")\n",
        "        for i in range(n_weights):\n",
        "            var cpu_val: F32 = F32(out_cpu_host[i])\n",
        "            var gpu_val: F32 = F32(out_gpu_host[i])\n",
        "            var diff: F32 = cpu_val - gpu_val\n",
        "            if diff < 0.0:\n",
        "                if -diff > max_abs_diff:\n",
        "                    max_abs_diff = -diff\n",
        "            else:\n",
        "                if diff > max_abs_diff:\n",
        "                    max_abs_diff = diff\n",
        "\n",
        "            if i < 16:\n",
        "                print(i, \"\\t\", cpu_val, \"\\t\", gpu_val, \"\\t\", diff)\n",
        "\n",
        "        print(\"max_abs_diff =\", max_abs_diff)\n",
        "        print(\n",
        "            \"Correctness test PASSED!\" if max_abs_diff\n",
        "            < 1e-3 else \"Correctness test FAILED!\"\n",
        "        )\n",
        "\n",
        "\n",
        "####################################\n",
        "# Benchmark a single weight matrix #\n",
        "####################################\n",
        "\n",
        "\n",
        "fn bench_layer(\n",
        "    ctx: DeviceContext,\n",
        "    n_weights: Int,\n",
        "    num_iters: Int,\n",
        ") raises -> Float64:\n",
        "    \"\"\"\n",
        "    Returns: seconds (total time for num_iters iterations)\n",
        "    \"\"\"\n",
        "    var n_pairs = n_weights // 2\n",
        "    var n_absmax = ceildiv(n_weights, BLOCKSIZE_W)\n",
        "    var n_scale2 = ceildiv(n_absmax, STATE2_BLOCKSIZE)\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_pairs)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_absmax)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    for i in range(n_pairs):\n",
        "        var hi: Int = i % 16\n",
        "        var lo: Int = (15 - i) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    for i in range(n_absmax):\n",
        "        absmax_host[i] = U8(i % 16)\n",
        "\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_pairs)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_absmax)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    var out_dev = ctx.enqueue_create_buffer[f16_dtype](n_weights)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Flat grid: 256 threads per block, blocks = ceildiv(n_pairs, 256)\n",
        "    var blocks: Int = ceildiv(n_pairs, THREADS_PER_BLOCK)\n",
        "\n",
        "    # Compile once\n",
        "    var compiled_kernel = ctx.compile_function_checked[\n",
        "        nf4_dequant_kernel, nf4_dequant_kernel\n",
        "    ]()\n",
        "\n",
        "    @always_inline\n",
        "    @parameter\n",
        "    fn run_kernel(bench_ctx: DeviceContext) raises:\n",
        "        bench_ctx.enqueue_function_checked(\n",
        "            compiled_kernel,\n",
        "            packed_dev,\n",
        "            absmax_dev,\n",
        "            code2_dev,\n",
        "            scale2_dev,\n",
        "            F32(offset),\n",
        "            out_dev,\n",
        "            n_pairs,\n",
        "            n_weights,\n",
        "            grid_dim=blocks,\n",
        "            block_dim=THREADS_PER_BLOCK,\n",
        "        )\n",
        "\n",
        "    # Warmup\n",
        "    run_kernel(ctx)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    var total_ns = ctx.execution_time[run_kernel](num_iters)\n",
        "    var seconds: Float64 = Float64(total_ns) / 1e9\n",
        "\n",
        "    return seconds\n",
        "\n",
        "\n",
        "###################################\n",
        "# Unsloth-like benchmark harness  #\n",
        "###################################\n",
        "\n",
        "\n",
        "def main():\n",
        "    with DeviceContext() as ctx:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"NF4 Dequantization Benchmark (Mojo kernel)\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        print(\"\\n--- Correctness Test ---\")\n",
        "        run_correctness_test(ctx)\n",
        "\n",
        "        # How many dequant kernel launches per layer we time.\n",
        "        var NUM_ITERS_PER_LAYER: Int = 1000\n",
        "\n",
        "        print(\"\\n--- Unsloth-style Dequant Bench ---\")\n",
        "        print(\"Each layer runs\", NUM_ITERS_PER_LAYER, \"kernel launches.\")\n",
        "        print(\"\\nDevice:\", ctx.api())\n",
        "\n",
        "        var total_time: Float64 = 0.0\n",
        "\n",
        "        # Config 1: hd=2048, m=8192\n",
        "        var hd1: Int = 2048\n",
        "        var m1: Int = 8192\n",
        "        var n_w1: Int = hd1 * m1\n",
        "        print(\"\\nConfig 1: hd=\", hd1, \", m=\", m1, \", n_weights=\", n_w1)\n",
        "\n",
        "        var t1_up = bench_layer(ctx, n_w1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t1_up, \" s\")\n",
        "        var t1_gate = bench_layer(ctx, n_w1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t1_gate, \" s\")\n",
        "        var t1_down = bench_layer(ctx, n_w1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t1_down, \" s\")\n",
        "\n",
        "        var config1_time = t1_up + t1_gate + t1_down\n",
        "        print(\"  Config 1 total: \", config1_time, \" s\")\n",
        "        total_time += config1_time\n",
        "\n",
        "        # Config 2: hd=1024, m=4096\n",
        "        var hd2: Int = 1024\n",
        "        var m2: Int = 4096\n",
        "        var n_w2: Int = hd2 * m2\n",
        "        print(\"\\nConfig 2: hd=\", hd2, \", m=\", m2, \", n_weights=\", n_w2)\n",
        "\n",
        "        var t2_up = bench_layer(ctx, n_w2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t2_up, \" s\")\n",
        "        var t2_gate = bench_layer(ctx, n_w2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t2_gate, \" s\")\n",
        "        var t2_down = bench_layer(ctx, n_w2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t2_down, \" s\")\n",
        "\n",
        "        var config2_time = t2_up + t2_gate + t2_down\n",
        "        print(\"  Config 2 total: \", config2_time, \" s\")\n",
        "        total_time += config2_time\n",
        "\n",
        "        # Config 3: hd=4096, m=14336\n",
        "        var hd3: Int = 4096\n",
        "        var m3: Int = 14336\n",
        "        var n_w3: Int = hd3 * m3\n",
        "        print(\"\\nConfig 3: hd=\", hd3, \", m=\", m3, \", n_weights=\", n_w3)\n",
        "\n",
        "        var t3_up = bench_layer(ctx, n_w3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t3_up, \" s\")\n",
        "        var t3_gate = bench_layer(ctx, n_w3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t3_gate, \" s\")\n",
        "        var t3_down = bench_layer(ctx, n_w3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t3_down, \" s\")\n",
        "\n",
        "        var config3_time = t3_up + t3_gate + t3_down\n",
        "        print(\"  Config 3 total: \", config3_time, \" s\")\n",
        "        total_time += config3_time\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"TOTAL Mojo NF4 dequant time:\", total_time, \"seconds\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Compare to Unsloth Triton reference time\n",
        "        var unsloth_time: Float64 = 5.320246934890747\n",
        "        var speedup = unsloth_time / total_time\n",
        "        print(\"\\nUnsloth Triton time (ref): \", unsloth_time, \" s\")\n",
        "        print(\"Mojo kernel time:          \", total_time, \" s\")\n",
        "        print(\"Speedup (Triton / Mojo):   \", speedup, \"x\")\n",
        "\n",
        "        if speedup >= 1.15:\n",
        "            print(\"\\n SUCCESS: Achieved >= 1.15x speedup!\")\n",
        "        else:\n",
        "            print(\"\\n Need more optimization to reach 1.15x speedup\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oJuPMvfwdPLO",
        "outputId": "aae688f3-6580-4960-cd2b-a9636d45e14c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "NF4 Dequantization Benchmark (Mojo kernel)\n",
            "============================================================\n",
            "\n",
            "--- Correctness Test ---\n",
            "idx\tCPU\t\tGPU\t\tdiff\n",
            "0 \t -0.45996094 \t -0.45996094 \t 0.0\n",
            "1 \t 0.45996094 \t 0.45996094 \t 0.0\n",
            "2 \t -0.3203125 \t -0.3203125 \t 0.0\n",
            "3 \t 0.33251953 \t 0.33251953 \t 0.0\n",
            "4 \t -0.24157715 \t -0.24157715 \t 0.0\n",
            "5 \t 0.25878906 \t 0.25878906 \t 0.0\n",
            "6 \t -0.18164062 \t -0.18164062 \t 0.0\n",
            "7 \t 0.20275879 \t 0.20275879 \t 0.0\n",
            "8 \t -0.13085937 \t -0.13085937 \t 0.0\n",
            "9 \t 0.15539551 \t 0.15539551 \t 0.0\n",
            "10 \t -0.08502197 \t -0.08502197 \t 0.0\n",
            "11 \t 0.113220215 \t 0.113220215 \t 0.0\n",
            "12 \t -0.041870117 \t -0.041870117 \t 0.0\n",
            "13 \t 0.074035645 \t 0.074035645 \t 0.0\n",
            "14 \t 0.0 \t 0.0 \t 0.0\n",
            "15 \t 0.036621094 \t 0.036621094 \t 0.0\n",
            "max_abs_diff = 0.0\n",
            "Correctness test PASSED!\n",
            "\n",
            "--- Unsloth-style Dequant Bench ---\n",
            "Each layer runs 1000 kernel launches.\n",
            "\n",
            "Device: cuda\n",
            "\n",
            "Config 1: hd= 2048 , m= 8192 , n_weights= 16777216\n",
            "  up_proj   :  0.52246936  s\n",
            "  gate_proj :  0.535773193  s\n",
            "  down_proj :  0.534033386  s\n",
            "  Config 1 total:  1.5922759389999999  s\n",
            "\n",
            "Config 2: hd= 1024 , m= 4096 , n_weights= 4194304\n",
            "  up_proj   :  0.123978752  s\n",
            "  gate_proj :  0.121881599  s\n",
            "  down_proj :  0.121892768  s\n",
            "  Config 2 total:  0.36775311899999996  s\n",
            "\n",
            "Config 3: hd= 4096 , m= 14336 , n_weights= 58720256\n",
            "  up_proj   :  1.961680908  s\n",
            "  gate_proj :  1.96628894  s\n",
            "  down_proj :  1.967535156  s\n",
            "  Config 3 total:  5.895505004  s\n",
            "\n",
            "============================================================\n",
            "TOTAL Mojo NF4 dequant time: 7.855534062 seconds\n",
            "============================================================\n",
            "\n",
            "Unsloth Triton time (ref):  5.320246934890747  s\n",
            "Mojo kernel time:           7.855534062  s\n",
            "Speedup (Triton / Mojo):    0.6772610102509344 x\n",
            "\n",
            " Need more optimization to reach 1.15x speedup\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 32 threads per block, 1 block per NF4 block\n",
        "\n",
        "Each thread handles 1 byte â‡’ 2 weights.\n",
        "\n",
        "Uses shared memory + barrier to compute scale once per NF4 block.\n",
        "\n",
        "**Time** 12.728195903"
      ],
      "metadata": {
        "id": "H9MiGLVDu0-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%mojo\n",
        "from gpu import block_idx, thread_idx, block_dim, barrier\n",
        "from gpu.host import DeviceContext\n",
        "from gpu.memory import AddressSpace\n",
        "from memory import UnsafePointer, stack_allocation\n",
        "from math import fma, ceildiv\n",
        "\n",
        "#######################\n",
        "# Types and Constants #\n",
        "#######################\n",
        "\n",
        "comptime packed_dtype = DType.uint8\n",
        "comptime f32_dtype = DType.float32\n",
        "comptime f16_dtype = DType.float16\n",
        "\n",
        "comptime U8 = Scalar[packed_dtype]\n",
        "comptime F32 = Scalar[f32_dtype]\n",
        "comptime F16 = Scalar[f16_dtype]\n",
        "\n",
        "# Hard-coded bitsandbytes NF4 codebook (fp32)\n",
        "comptime NF4_TABLE = InlineArray[F32, 16](\n",
        "    -1.0,\n",
        "    -0.6961928009986877,\n",
        "    -0.5250730514526367,\n",
        "    -0.39491748809814453,\n",
        "    -0.28444138169288635,\n",
        "    -0.18477343022823334,\n",
        "    -0.09105003625154495,\n",
        "    0.0,\n",
        "    0.07958029955625534,\n",
        "    0.16093020141124725,\n",
        "    0.24611230194568634,\n",
        "    0.33791524171829224,\n",
        "    0.44070982933044434,\n",
        "    0.5626170039176941,\n",
        "    0.7229568362236023,\n",
        "    1.0,\n",
        ")\n",
        "\n",
        "# NF4 layout / block structure\n",
        "comptime BLOCKSIZE_W = 64  # weights per NF4 block\n",
        "comptime PAIRS_PER_BLOCK = BLOCKSIZE_W // 2  # 32 bytes per 64 weights\n",
        "comptime STATE2_BLOCKSIZE = 256  # absmax entries per state2 scale\n",
        "\n",
        "# -----------------------------\n",
        "# GPU kernel:\n",
        "#   1 block = 1 NF4 block (64 weights)\n",
        "#   32 threads per block, each = 1 byte (2 weights)\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn nf4_dequant_kernel(\n",
        "    packed_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    out_ptr: UnsafePointer[F16, MutAnyOrigin],\n",
        "    n_pairs: Int,  # total bytes (2 weights per byte)\n",
        "    n_weights: Int,  # total weights\n",
        "    n_absmax: Int,  # number of 64-weight blocks\n",
        "):\n",
        "    # Each block handles exactly one NF4 block (64 weights)\n",
        "    var absmax_idx = Int(block_idx.x)\n",
        "    if absmax_idx >= n_absmax:\n",
        "        return\n",
        "\n",
        "    # Thread index inside this NF4 block\n",
        "    var local_pair = Int(thread_idx.x)\n",
        "    if local_pair >= PAIRS_PER_BLOCK:\n",
        "        return\n",
        "\n",
        "    # Global byte index\n",
        "    var global_pair = absmax_idx * PAIRS_PER_BLOCK + local_pair\n",
        "    if global_pair >= n_pairs:\n",
        "        return\n",
        "\n",
        "    # Shared scale: computed once per NF4 block\n",
        "    var shared_scale = stack_allocation[\n",
        "        1, F32, address_space = AddressSpace.SHARED\n",
        "    ]()\n",
        "\n",
        "    if thread_idx.x == 0:\n",
        "        # First-level absmax code for this block\n",
        "        var q_abs: U8 = absmax_q_ptr[absmax_idx]\n",
        "        var code_val: F32 = code2_ptr[Int(q_abs)]\n",
        "\n",
        "        # Second-level scale index (one per 256 absmax entries)\n",
        "        var scale_idx: Int = absmax_idx >> 8  # absmax_idx // 256\n",
        "        var scale_base: F32 = scale2_ptr[scale_idx]\n",
        "\n",
        "        shared_scale[0] = fma(code_val, scale_base, offset)\n",
        "\n",
        "    barrier()\n",
        "\n",
        "    var scale: F32 = shared_scale[0]\n",
        "\n",
        "    # Unpack two nf4 4-bit codes from this byte\n",
        "    var packed_val: U8 = packed_ptr[global_pair]\n",
        "    var packed_int: Int = Int(packed_val)\n",
        "\n",
        "    var hi_idx: Int = (packed_int >> 4) & 0x0F\n",
        "    var lo_idx: Int = packed_int & 0x0F\n",
        "\n",
        "    var v0: F32 = NF4_TABLE[hi_idx] * scale\n",
        "    var v1: F32 = NF4_TABLE[lo_idx] * scale\n",
        "\n",
        "    var i0: Int = global_pair * 2\n",
        "    var i1: Int = i0 + 1\n",
        "\n",
        "    if i0 < n_weights:\n",
        "        out_ptr[i0] = F16(v0)\n",
        "    if i1 < n_weights:\n",
        "        out_ptr[i1] = F16(v1)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# CPU reference (same math)\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn nf4_dequant_cpu(\n",
        "    packed: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    output: UnsafePointer[F16, MutAnyOrigin],\n",
        "    n_pairs: Int,\n",
        "    n_weights: Int,\n",
        "    n_absmax: Int,\n",
        "):\n",
        "    for absmax_idx in range(n_absmax):\n",
        "        var q_abs: U8 = absmax_q[absmax_idx]\n",
        "        var code_val: F32 = code2[Int(q_abs)]\n",
        "\n",
        "        var scale_idx = absmax_idx >> 8\n",
        "        var scale_base: F32 = scale2[scale_idx]\n",
        "        var scale: F32 = fma(code_val, scale_base, offset)\n",
        "\n",
        "        var base_pair = absmax_idx * PAIRS_PER_BLOCK\n",
        "\n",
        "        for local_pair in range(PAIRS_PER_BLOCK):\n",
        "            var pair_idx = base_pair + local_pair\n",
        "            if pair_idx >= n_pairs:\n",
        "                break\n",
        "\n",
        "            var i0: Int = pair_idx * 2\n",
        "            if i0 >= n_weights:\n",
        "                break\n",
        "            var i1: Int = i0 + 1\n",
        "\n",
        "            var packed_val: U8 = packed[pair_idx]\n",
        "            var packed_int: Int = Int(packed_val)\n",
        "\n",
        "            var hi_idx: Int = (packed_int >> 4) & 0x0F\n",
        "            var lo_idx: Int = packed_int & 0x0F\n",
        "\n",
        "            var v0: F32 = NF4_TABLE[hi_idx] * scale\n",
        "            var v1: F32 = NF4_TABLE[lo_idx] * scale\n",
        "\n",
        "            output[i0] = F16(v0)\n",
        "            if i1 < n_weights:\n",
        "                output[i1] = F16(v1)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Correctness sanity check\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def run_correctness_test(ctx: DeviceContext):\n",
        "    var n_weights: Int = 64\n",
        "    var n_pairs: Int = n_weights // 2\n",
        "    var n_absmax: Int = ceildiv(n_weights, BLOCKSIZE_W)\n",
        "    var n_scale2: Int = ceildiv(n_absmax, STATE2_BLOCKSIZE)\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_pairs)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_absmax)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "    var out_cpu_host = ctx.enqueue_create_host_buffer[f16_dtype](n_weights)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Fill deterministic pattern\n",
        "    for i in range(n_pairs):\n",
        "        var hi: Int = i % 16\n",
        "        var lo: Int = (15 - i) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    absmax_host[0] = U8(3)\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    # CPU ref\n",
        "    var packed_ptr = packed_host.unsafe_ptr()\n",
        "    var absmax_ptr = absmax_host.unsafe_ptr()\n",
        "    var code2_ptr = code2_host.unsafe_ptr()\n",
        "    var scale2_ptr = scale2_host.unsafe_ptr()\n",
        "    var out_cpu_ptr = out_cpu_host.unsafe_ptr()\n",
        "\n",
        "    nf4_dequant_cpu(\n",
        "        packed_ptr,\n",
        "        absmax_ptr,\n",
        "        code2_ptr,\n",
        "        scale2_ptr,\n",
        "        F32(offset),\n",
        "        out_cpu_ptr,\n",
        "        n_pairs,\n",
        "        n_weights,\n",
        "        n_absmax,\n",
        "    )\n",
        "\n",
        "    # Device buffers\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_pairs)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_absmax)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    var out_dev = ctx.enqueue_create_buffer[f16_dtype](n_weights)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "\n",
        "    # Launch kernel (1 block per NF4 block, 32 threads/block)\n",
        "    var threads_per_block: Int = PAIRS_PER_BLOCK\n",
        "    var blocks: Int = n_absmax\n",
        "\n",
        "    ctx.enqueue_function_checked[nf4_dequant_kernel, nf4_dequant_kernel](\n",
        "        packed_dev,\n",
        "        absmax_dev,\n",
        "        code2_dev,\n",
        "        scale2_dev,\n",
        "        F32(offset),\n",
        "        out_dev,\n",
        "        n_pairs,\n",
        "        n_weights,\n",
        "        n_absmax,\n",
        "        grid_dim=blocks,\n",
        "        block_dim=threads_per_block,\n",
        "    )\n",
        "    ctx.synchronize()\n",
        "\n",
        "    with out_dev.map_to_host() as out_gpu_host:\n",
        "        var max_abs_diff: F32 = 0.0\n",
        "\n",
        "        print(\"idx\\tCPU\\t\\tGPU\\t\\tdiff\")\n",
        "        for i in range(n_weights):\n",
        "            var cpu_val: F32 = F32(out_cpu_host[i])\n",
        "            var gpu_val: F32 = F32(out_gpu_host[i])\n",
        "            var diff: F32 = cpu_val - gpu_val\n",
        "            if diff < 0.0:\n",
        "                if -diff > max_abs_diff:\n",
        "                    max_abs_diff = -diff\n",
        "            else:\n",
        "                if diff > max_abs_diff:\n",
        "                    max_abs_diff = diff\n",
        "\n",
        "            if i < 16:\n",
        "                print(i, \"\\t\", cpu_val, \"\\t\", gpu_val, \"\\t\", diff)\n",
        "\n",
        "        print(\"max_abs_diff =\", max_abs_diff)\n",
        "        print(\n",
        "            \"Correctness test PASSED!\" if max_abs_diff\n",
        "            < 1e-3 else \"Correctness test FAILED!\"\n",
        "        )\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Benchmark a single weight matrix\n",
        "# (similar to one linear layer)\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn bench_layer(\n",
        "    ctx: DeviceContext,\n",
        "    n_weights: Int,\n",
        "    num_iters: Int,\n",
        ") raises -> Float64:\n",
        "    \"\"\"\n",
        "    Returns: seconds (total time for num_iters iterations)\n",
        "    \"\"\"\n",
        "    var n_pairs = n_weights // 2\n",
        "    var n_absmax = ceildiv(n_weights, BLOCKSIZE_W)\n",
        "    var n_scale2 = ceildiv(n_absmax, STATE2_BLOCKSIZE)\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_pairs)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_absmax)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Fill patterns\n",
        "    for i in range(n_pairs):\n",
        "        var hi: Int = i % 16\n",
        "        var lo: Int = (15 - i) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    for i in range(n_absmax):\n",
        "        absmax_host[i] = U8(i % 16)\n",
        "\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    # Device buffers\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_pairs)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_absmax)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    var out_dev = ctx.enqueue_create_buffer[f16_dtype](n_weights)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    var threads_per_block: Int = PAIRS_PER_BLOCK  # 32\n",
        "    var blocks: Int = n_absmax  # one block per NF4 block\n",
        "\n",
        "    # Compile once\n",
        "    var compiled_kernel = ctx.compile_function_checked[\n",
        "        nf4_dequant_kernel, nf4_dequant_kernel\n",
        "    ]()\n",
        "\n",
        "    @always_inline\n",
        "    @parameter\n",
        "    fn run_kernel(bench_ctx: DeviceContext) raises:\n",
        "        bench_ctx.enqueue_function_checked(\n",
        "            compiled_kernel,\n",
        "            packed_dev,\n",
        "            absmax_dev,\n",
        "            code2_dev,\n",
        "            scale2_dev,\n",
        "            F32(offset),\n",
        "            out_dev,\n",
        "            n_pairs,\n",
        "            n_weights,\n",
        "            n_absmax,\n",
        "            grid_dim=blocks,\n",
        "            block_dim=threads_per_block,\n",
        "        )\n",
        "\n",
        "    # Warmup\n",
        "    run_kernel(ctx)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    var total_ns = ctx.execution_time[run_kernel](num_iters)\n",
        "    var seconds: Float64 = Float64(total_ns) / 1e9\n",
        "\n",
        "    return seconds\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Unsloth-like benchmark harness\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def main():\n",
        "    with DeviceContext() as ctx:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"NF4 Dequantization Benchmark (Mojo kernel)\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        print(\"\\n--- Correctness Test ---\")\n",
        "        run_correctness_test(ctx)\n",
        "\n",
        "        # How many dequant kernel launches per layer we time.\n",
        "        var NUM_ITERS_PER_LAYER: Int = 1000\n",
        "\n",
        "        print(\"\\n--- Unsloth-style Dequant Bench ---\")\n",
        "        print(\"Each layer runs\", NUM_ITERS_PER_LAYER, \"kernel launches.\")\n",
        "        print(\"\\nDevice:\", ctx.api())\n",
        "\n",
        "        var total_time: Float64 = 0.0\n",
        "\n",
        "        # Config 1: hd=2048, m=8192\n",
        "        var hd1: Int = 2048\n",
        "        var m1: Int = 8192\n",
        "        var n_w1: Int = hd1 * m1\n",
        "        print(\"\\nConfig 1: hd=\", hd1, \", m=\", m1, \", n_weights=\", n_w1)\n",
        "\n",
        "        var t1_up = bench_layer(ctx, n_w1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t1_up, \" s\")\n",
        "        var t1_gate = bench_layer(ctx, n_w1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t1_gate, \" s\")\n",
        "        var t1_down = bench_layer(ctx, n_w1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t1_down, \" s\")\n",
        "\n",
        "        var config1_time = t1_up + t1_gate + t1_down\n",
        "        print(\"  Config 1 total: \", config1_time, \" s\")\n",
        "        total_time += config1_time\n",
        "\n",
        "        # Config 2: hd=1024, m=4096\n",
        "        var hd2: Int = 1024\n",
        "        var m2: Int = 4096\n",
        "        var n_w2: Int = hd2 * m2\n",
        "        print(\"\\nConfig 2: hd=\", hd2, \", m=\", m2, \", n_weights=\", n_w2)\n",
        "\n",
        "        var t2_up = bench_layer(ctx, n_w2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t2_up, \" s\")\n",
        "        var t2_gate = bench_layer(ctx, n_w2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t2_gate, \" s\")\n",
        "        var t2_down = bench_layer(ctx, n_w2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t2_down, \" s\")\n",
        "\n",
        "        var config2_time = t2_up + t2_gate + t2_down\n",
        "        print(\"  Config 2 total: \", config2_time, \" s\")\n",
        "        total_time += config2_time\n",
        "\n",
        "        # Config 3: hd=4096, m=14336\n",
        "        var hd3: Int = 4096\n",
        "        var m3: Int = 14336\n",
        "        var n_w3: Int = hd3 * m3\n",
        "        print(\"\\nConfig 3: hd=\", hd3, \", m=\", m3, \", n_weights=\", n_w3)\n",
        "\n",
        "        var t3_up = bench_layer(ctx, n_w3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t3_up, \" s\")\n",
        "        var t3_gate = bench_layer(ctx, n_w3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t3_gate, \" s\")\n",
        "        var t3_down = bench_layer(ctx, n_w3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t3_down, \" s\")\n",
        "\n",
        "        var config3_time = t3_up + t3_gate + t3_down\n",
        "        print(\"  Config 3 total: \", config3_time, \" s\")\n",
        "        total_time += config3_time\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"TOTAL Mojo NF4 dequant time:\", total_time, \"seconds\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Compare to Unsloth Triton reference time\n",
        "        var unsloth_time: Float64 = 5.320246934890747\n",
        "        var speedup = unsloth_time / total_time\n",
        "        print(\"\\nUnsloth Triton time (ref): \", unsloth_time, \" s\")\n",
        "        print(\"Mojo kernel time:          \", total_time, \" s\")\n",
        "        print(\"Speedup (Triton / Mojo):   \", speedup, \"x\")\n",
        "\n",
        "        if speedup >= 1.15:\n",
        "            print(\"\\n SUCCESS: Achieved >= 1.15x speedup!\")\n",
        "        else:\n",
        "            print(\"\\n Need more optimization to reach 1.15x speedup\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZjpDbYznu5fn",
        "outputId": "33d8beac-b0bb-4dab-ab30-aa398b24f135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "NF4 Dequantization Benchmark (Mojo kernel)\n",
            "============================================================\n",
            "\n",
            "--- Correctness Test ---\n",
            "idx\tCPU\t\tGPU\t\tdiff\n",
            "0 \t -0.45996094 \t -0.45996094 \t 0.0\n",
            "1 \t 0.45996094 \t 0.45996094 \t 0.0\n",
            "2 \t -0.3203125 \t -0.3203125 \t 0.0\n",
            "3 \t 0.33251953 \t 0.33251953 \t 0.0\n",
            "4 \t -0.24157715 \t -0.24157715 \t 0.0\n",
            "5 \t 0.25878906 \t 0.25878906 \t 0.0\n",
            "6 \t -0.18164062 \t -0.18164062 \t 0.0\n",
            "7 \t 0.20275879 \t 0.20275879 \t 0.0\n",
            "8 \t -0.13085937 \t -0.13085937 \t 0.0\n",
            "9 \t 0.15539551 \t 0.15539551 \t 0.0\n",
            "10 \t -0.08502197 \t -0.08502197 \t 0.0\n",
            "11 \t 0.113220215 \t 0.113220215 \t 0.0\n",
            "12 \t -0.041870117 \t -0.041870117 \t 0.0\n",
            "13 \t 0.074035645 \t 0.074035645 \t 0.0\n",
            "14 \t 0.0 \t 0.0 \t 0.0\n",
            "15 \t 0.036621094 \t 0.036621094 \t 0.0\n",
            "max_abs_diff = 0.0\n",
            "Correctness test PASSED!\n",
            "\n",
            "--- Unsloth-style Dequant Bench ---\n",
            "Each layer runs 1000 kernel launches.\n",
            "\n",
            "Device: cuda\n",
            "\n",
            "Config 1: hd= 2048 , m= 8192 , n_weights= 16777216\n",
            "  up_proj   :  0.541392883  s\n",
            "  gate_proj :  0.557131774  s\n",
            "  down_proj :  0.552584167  s\n",
            "  Config 1 total:  1.651108824  s\n",
            "\n",
            "Config 2: hd= 1024 , m= 4096 , n_weights= 4194304\n",
            "  up_proj   :  0.130182144  s\n",
            "  gate_proj :  0.129053695  s\n",
            "  down_proj :  0.129064956  s\n",
            "  Config 2 total:  0.38830079500000003  s\n",
            "\n",
            "Config 3: hd= 4096 , m= 14336 , n_weights= 58720256\n",
            "  up_proj   :  2.034995239  s\n",
            "  gate_proj :  2.041972778  s\n",
            "  down_proj :  2.042061767  s\n",
            "  Config 3 total:  6.119029784  s\n",
            "\n",
            "============================================================\n",
            "TOTAL Mojo NF4 dequant time: 8.158439403000001 seconds\n",
            "============================================================\n",
            "\n",
            "Unsloth Triton time (ref):  5.320246934890747  s\n",
            "Mojo kernel time:           8.158439403000001  s\n",
            "Speedup (Triton / Mojo):    0.6521157628423886 x\n",
            "\n",
            " Need more optimization to reach 1.15x speedup\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kernel 2D Tiling 16bit Store"
      ],
      "metadata": {
        "id": "fJ6RPWuLdAsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%mojo\n",
        "from gpu import block_idx, thread_idx, barrier\n",
        "from gpu.host import DeviceContext\n",
        "from gpu.memory import AddressSpace\n",
        "from memory import UnsafePointer, stack_allocation\n",
        "from math import fma, ceildiv\n",
        "\n",
        "#######################\n",
        "# Types and Constants #\n",
        "#######################\n",
        "\n",
        "comptime packed_dtype = DType.uint8\n",
        "comptime f32_dtype = DType.float32\n",
        "comptime f16_dtype = DType.float16\n",
        "\n",
        "comptime U8 = Scalar[packed_dtype]\n",
        "comptime F32 = Scalar[f32_dtype]\n",
        "comptime F16 = Scalar[f16_dtype]\n",
        "\n",
        "# Hard-coded bitsandbytes NF4 codebook (fp32)\n",
        "comptime NF4_TABLE = InlineArray[F32, 16](\n",
        "    -1.0,\n",
        "    -0.6961928009986877,\n",
        "    -0.5250730514526367,\n",
        "    -0.39491748809814453,\n",
        "    -0.28444138169288635,\n",
        "    -0.18477343022823334,\n",
        "    -0.09105003625154495,\n",
        "    0.0,\n",
        "    0.07958029955625534,\n",
        "    0.16093020141124725,\n",
        "    0.24611230194568634,\n",
        "    0.33791524171829224,\n",
        "    0.44070982933044434,\n",
        "    0.5626170039176941,\n",
        "    0.7229568362236023,\n",
        "    1.0,\n",
        ")\n",
        "\n",
        "# NF4 layout / block structure\n",
        "comptime BLOCKSIZE_W = 64  # weights per NF4 block\n",
        "comptime BLOCKSIZE_W_SHIFT = 6  # log2(64) for bit shift\n",
        "comptime STATE2_BLOCKSIZE = 256  # absmax entries per state2 scale\n",
        "comptime STATE2_SHIFT = 8  # log2(256) for bit shift\n",
        "\n",
        "# 2D tiling for T4 optimization\n",
        "comptime TILE_COLS = 256  # columns per block (matches THREADS_X)\n",
        "comptime TILE_ROWS = 4  # rows per block (matches THREADS_Y)\n",
        "comptime THREADS_X = 256\n",
        "comptime THREADS_Y = 4\n",
        "# Total: 1024 threads per block\n",
        "\n",
        "# -----------------------------\n",
        "# GPU kernel: 2D TILED approach\n",
        "#   - Each thread handles 1 output weight\n",
        "#   - 256Ã—4 = 1024 threads per CUDA block\n",
        "#   - Shared memory for NF4 codebook (16 floats)\n",
        "#   - 2D grid: (rows/4) Ã— (cols/256)\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn nf4_dequant_kernel_2d(\n",
        "    packed_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q_ptr: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2_ptr: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    out_ptr: UnsafePointer[F16, MutAnyOrigin],\n",
        "    n_rows: Int,\n",
        "    n_cols: Int,\n",
        "    blocks_per_row: Int,  # precomputed on host\n",
        "    groups_per_row: Int,  # precomputed on host\n",
        "):\n",
        "    # Shared memory for NF4 codebook (16 values)\n",
        "    var shared_nf4 = stack_allocation[\n",
        "        16, F32, address_space = AddressSpace.SHARED\n",
        "    ]()\n",
        "\n",
        "    # First 16 threads of first row load the NF4 codebook\n",
        "    var tx = Int(thread_idx.x)\n",
        "    var ty = Int(thread_idx.y)\n",
        "    if ty == 0 and tx < 16:\n",
        "        shared_nf4[tx] = NF4_TABLE[tx]\n",
        "\n",
        "    barrier()\n",
        "\n",
        "    # 2D position\n",
        "    var row = Int(block_idx.x) * TILE_ROWS + ty\n",
        "    var col = Int(block_idx.y) * TILE_COLS + tx\n",
        "\n",
        "    if row >= n_rows or col >= n_cols:\n",
        "        return\n",
        "\n",
        "    # Strides for 2D layout (row-major packed, row-major output)\n",
        "    var packed_stride = n_cols // 2  # bytes per row\n",
        "    var out_stride = n_cols  # weights per row\n",
        "\n",
        "    # Unpack 4-bit: each byte holds 2 weights\n",
        "    # Weight at col uses byte at col//2, nibble at (col & 1)\n",
        "    var byte_idx = col // 2\n",
        "    var nibble_shift = (\n",
        "        col & 1\n",
        "    ) * 4  # 0 for even col (low nibble), 4 for odd (high nibble)\n",
        "\n",
        "    var packed_byte: U8 = packed_ptr[row * packed_stride + byte_idx]\n",
        "    var q: Int = (Int(packed_byte) >> nibble_shift) & 0x0F\n",
        "\n",
        "    # NF4 lookup from shared memory\n",
        "    var normalized: F32 = shared_nf4[q]\n",
        "\n",
        "    # Compute block/group indices using bit shifts (faster than divides)\n",
        "    var block_id = col >> BLOCKSIZE_W_SHIFT  # col // 64\n",
        "    var absmax_idx = row * blocks_per_row + block_id\n",
        "\n",
        "    # First-level dequant: absmax_q -> code2 lookup\n",
        "    var q_scale: U8 = absmax_q_ptr[absmax_idx]\n",
        "    var code_val: F32 = code2_ptr[Int(q_scale)]\n",
        "\n",
        "    # Second-level dequant: group scale (using bit shift)\n",
        "    var group_id = block_id >> STATE2_SHIFT  # block_id // 256\n",
        "    var group_idx = row * groups_per_row + group_id\n",
        "    var scale_base: F32 = scale2_ptr[group_idx]\n",
        "\n",
        "    # Final scale = code2[absmax_q] * scale2 + offset\n",
        "    var scale: F32 = fma(code_val, scale_base, offset)\n",
        "\n",
        "    # Final dequantized value\n",
        "    var value: F32 = normalized * scale\n",
        "\n",
        "    # Store as fp16\n",
        "    out_ptr[row * out_stride + col] = F16(value)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# CPU reference (same 2D logic)\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn nf4_dequant_cpu_2d(\n",
        "    packed: UnsafePointer[U8, MutAnyOrigin],\n",
        "    absmax_q: UnsafePointer[U8, MutAnyOrigin],\n",
        "    code2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    scale2: UnsafePointer[F32, MutAnyOrigin],\n",
        "    offset: F32,\n",
        "    output: UnsafePointer[F16, MutAnyOrigin],\n",
        "    n_rows: Int,\n",
        "    n_cols: Int,\n",
        "):\n",
        "    # Hoist all invariants out of the loop\n",
        "    var packed_stride = n_cols >> 1  # n_cols // 2\n",
        "    var blocks_per_row = (n_cols + BLOCKSIZE_W - 1) >> BLOCKSIZE_W_SHIFT\n",
        "    var groups_per_row = (blocks_per_row + STATE2_BLOCKSIZE - 1) >> STATE2_SHIFT\n",
        "\n",
        "    for row in range(n_rows):\n",
        "        # Hoist row-dependent base offsets\n",
        "        var row_packed_base = row * packed_stride\n",
        "        var row_out_base = row * n_cols\n",
        "        var row_absmax_base = row * blocks_per_row\n",
        "        var row_group_base = row * groups_per_row\n",
        "\n",
        "        for col in range(n_cols):\n",
        "            # Unpack nibble using bit ops\n",
        "            var byte_idx = col >> 1  # col // 2\n",
        "            var nibble_shift = (col & 1) << 2  # (col & 1) * 4\n",
        "            var packed_byte: U8 = packed[row_packed_base + byte_idx]\n",
        "            var q: Int = (Int(packed_byte) >> nibble_shift) & 0x0F\n",
        "\n",
        "            # NF4 lookup\n",
        "            var normalized: F32 = NF4_TABLE[q]\n",
        "\n",
        "            # Block/group indices using bit shifts\n",
        "            var block_id = col >> BLOCKSIZE_W_SHIFT  # col // 64\n",
        "            var absmax_idx = row_absmax_base + block_id\n",
        "\n",
        "            var q_scale: U8 = absmax_q[absmax_idx]\n",
        "            var code_val: F32 = code2[Int(q_scale)]\n",
        "\n",
        "            var group_id = block_id >> STATE2_SHIFT  # block_id // 256\n",
        "            var group_idx = row_group_base + group_id\n",
        "            var scale_base: F32 = scale2[group_idx]\n",
        "\n",
        "            var scale: F32 = fma(code_val, scale_base, offset)\n",
        "            var value: F32 = normalized * scale\n",
        "\n",
        "            output[row_out_base + col] = F16(value)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Correctness sanity check\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def run_correctness_test(ctx: DeviceContext):\n",
        "    # Use a small 2D test case: 4 rows Ã— 128 cols\n",
        "    var n_rows: Int = 4\n",
        "    var n_cols: Int = 128\n",
        "    var n_weights: Int = n_rows * n_cols\n",
        "    var n_pairs: Int = n_weights // 2  # total bytes\n",
        "\n",
        "    var blocks_per_row = ceildiv(n_cols, BLOCKSIZE_W)\n",
        "    var n_absmax = n_rows * blocks_per_row\n",
        "    var groups_per_row = ceildiv(blocks_per_row, STATE2_BLOCKSIZE)\n",
        "    var n_scale2 = n_rows * groups_per_row\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_pairs)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_absmax)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "    var out_cpu_host = ctx.enqueue_create_host_buffer[f16_dtype](n_weights)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Fill deterministic pattern\n",
        "    for i in range(n_pairs):\n",
        "        # Pack two nibbles: low nibble = i%16, high nibble = (i+1)%16\n",
        "        var lo: Int = i % 16\n",
        "        var hi: Int = (i + 1) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    for i in range(n_absmax):\n",
        "        absmax_host[i] = U8(i % 16)\n",
        "\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    # CPU ref\n",
        "    nf4_dequant_cpu_2d(\n",
        "        packed_host.unsafe_ptr(),\n",
        "        absmax_host.unsafe_ptr(),\n",
        "        code2_host.unsafe_ptr(),\n",
        "        scale2_host.unsafe_ptr(),\n",
        "        F32(offset),\n",
        "        out_cpu_host.unsafe_ptr(),\n",
        "        n_rows,\n",
        "        n_cols,\n",
        "    )\n",
        "\n",
        "    # Device buffers\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_pairs)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_absmax)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    var out_dev = ctx.enqueue_create_buffer[f16_dtype](n_weights)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "\n",
        "    # 2D grid: grid_x = rows/TILE_ROWS, grid_y = cols/TILE_COLS\n",
        "    var grid_x: Int = ceildiv(n_rows, TILE_ROWS)\n",
        "    var grid_y: Int = ceildiv(n_cols, TILE_COLS)\n",
        "\n",
        "    ctx.enqueue_function_checked[nf4_dequant_kernel_2d, nf4_dequant_kernel_2d](\n",
        "        packed_dev,\n",
        "        absmax_dev,\n",
        "        code2_dev,\n",
        "        scale2_dev,\n",
        "        F32(offset),\n",
        "        out_dev,\n",
        "        n_rows,\n",
        "        n_cols,\n",
        "        blocks_per_row,\n",
        "        groups_per_row,\n",
        "        grid_dim=(grid_x, grid_y),\n",
        "        block_dim=(THREADS_X, THREADS_Y),\n",
        "    )\n",
        "    ctx.synchronize()\n",
        "\n",
        "    with out_dev.map_to_host() as out_gpu_host:\n",
        "        var max_abs_diff: F32 = 0.0\n",
        "\n",
        "        print(\"idx\\tCPU\\t\\tGPU\\t\\tdiff\")\n",
        "        for i in range(n_weights):\n",
        "            var cpu_val: F32 = F32(out_cpu_host[i])\n",
        "            var gpu_val: F32 = F32(out_gpu_host[i])\n",
        "            var diff: F32 = cpu_val - gpu_val\n",
        "            if diff < 0.0:\n",
        "                if -diff > max_abs_diff:\n",
        "                    max_abs_diff = -diff\n",
        "            else:\n",
        "                if diff > max_abs_diff:\n",
        "                    max_abs_diff = diff\n",
        "\n",
        "            if i < 16:\n",
        "                print(i, \"\\t\", cpu_val, \"\\t\", gpu_val, \"\\t\", diff)\n",
        "\n",
        "        print(\"max_abs_diff =\", max_abs_diff)\n",
        "        print(\n",
        "            \"Correctness test PASSED!\" if max_abs_diff\n",
        "            < 1e-3 else \"Correctness test FAILED!\"\n",
        "        )\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Benchmark a single weight matrix\n",
        "# For benchmark, treat n_weights as a 1D array reshaped to 2D\n",
        "# We'll use n_rows=hd, n_cols=m to match Unsloth's shapes\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "fn bench_layer_2d(\n",
        "    ctx: DeviceContext,\n",
        "    n_rows: Int,\n",
        "    n_cols: Int,\n",
        "    num_iters: Int,\n",
        ") raises -> Float64:\n",
        "    \"\"\"\n",
        "    Benchmark 2D dequant kernel.\n",
        "    \"\"\"\n",
        "    var n_weights = n_rows * n_cols\n",
        "    var n_pairs = n_weights // 2\n",
        "\n",
        "    var blocks_per_row = ceildiv(n_cols, BLOCKSIZE_W)\n",
        "    var n_absmax = n_rows * blocks_per_row\n",
        "    var groups_per_row = ceildiv(blocks_per_row, STATE2_BLOCKSIZE)\n",
        "    var n_scale2 = n_rows * groups_per_row\n",
        "    if n_scale2 < 1:\n",
        "        n_scale2 = 1\n",
        "\n",
        "    var offset: F32 = 0.01\n",
        "\n",
        "    # Host buffers\n",
        "    var packed_host = ctx.enqueue_create_host_buffer[packed_dtype](n_pairs)\n",
        "    var absmax_host = ctx.enqueue_create_host_buffer[packed_dtype](n_absmax)\n",
        "    var code2_host = ctx.enqueue_create_host_buffer[f32_dtype](16)\n",
        "    var scale2_host = ctx.enqueue_create_host_buffer[f32_dtype](n_scale2)\n",
        "\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # Fill patterns\n",
        "    for i in range(n_pairs):\n",
        "        var lo: Int = i % 16\n",
        "        var hi: Int = (i + 1) % 16\n",
        "        var byte_val: Int = (hi << 4) | lo\n",
        "        packed_host[i] = U8(byte_val)\n",
        "\n",
        "    for i in range(n_absmax):\n",
        "        absmax_host[i] = U8(i % 16)\n",
        "\n",
        "    for i in range(16):\n",
        "        code2_host[i] = F32(0.1 * Float64(i))\n",
        "\n",
        "    for i in range(n_scale2):\n",
        "        scale2_host[i] = F32(1.5)\n",
        "\n",
        "    # Device buffers\n",
        "    var packed_dev = ctx.enqueue_create_buffer[packed_dtype](n_pairs)\n",
        "    var absmax_dev = ctx.enqueue_create_buffer[packed_dtype](n_absmax)\n",
        "    var code2_dev = ctx.enqueue_create_buffer[f32_dtype](16)\n",
        "    var scale2_dev = ctx.enqueue_create_buffer[f32_dtype](n_scale2)\n",
        "    var out_dev = ctx.enqueue_create_buffer[f16_dtype](n_weights)\n",
        "\n",
        "    ctx.enqueue_copy(dst_buf=packed_dev, src_buf=packed_host)\n",
        "    ctx.enqueue_copy(dst_buf=absmax_dev, src_buf=absmax_host)\n",
        "    ctx.enqueue_copy(dst_buf=code2_dev, src_buf=code2_host)\n",
        "    ctx.enqueue_copy(dst_buf=scale2_dev, src_buf=scale2_host)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    # 2D grid\n",
        "    var grid_x: Int = ceildiv(n_rows, TILE_ROWS)\n",
        "    var grid_y: Int = ceildiv(n_cols, TILE_COLS)\n",
        "\n",
        "    # Compile once\n",
        "    var compiled_kernel = ctx.compile_function_checked[\n",
        "        nf4_dequant_kernel_2d, nf4_dequant_kernel_2d\n",
        "    ]()\n",
        "\n",
        "    @always_inline\n",
        "    @parameter\n",
        "    fn run_kernel(bench_ctx: DeviceContext) raises:\n",
        "        bench_ctx.enqueue_function_checked(\n",
        "            compiled_kernel,\n",
        "            packed_dev,\n",
        "            absmax_dev,\n",
        "            code2_dev,\n",
        "            scale2_dev,\n",
        "            F32(offset),\n",
        "            out_dev,\n",
        "            n_rows,\n",
        "            n_cols,\n",
        "            blocks_per_row,\n",
        "            groups_per_row,\n",
        "            grid_dim=(grid_x, grid_y),\n",
        "            block_dim=(THREADS_X, THREADS_Y),\n",
        "        )\n",
        "\n",
        "    # Warmup\n",
        "    run_kernel(ctx)\n",
        "    ctx.synchronize()\n",
        "\n",
        "    var total_ns = ctx.execution_time[run_kernel](num_iters)\n",
        "    var seconds: Float64 = Float64(total_ns) / 1e9\n",
        "\n",
        "    return seconds\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Unsloth-like benchmark harness\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def main():\n",
        "    with DeviceContext() as ctx:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"NF4 Dequantization Benchmark (Mojo 2D Tiled Kernel)\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        print(\"\\n--- Correctness Test ---\")\n",
        "        run_correctness_test(ctx)\n",
        "\n",
        "        # Dequant kernel launches per layer\n",
        "        var NUM_ITERS_PER_LAYER: Int = 1000\n",
        "\n",
        "        print(\"\\n--- Unsloth-style Dequant Bench ---\")\n",
        "        print(\"Each layer runs\", NUM_ITERS_PER_LAYER, \"kernel launches.\")\n",
        "        print(\n",
        "            \"Using 2D tiled kernel: \",\n",
        "            THREADS_X,\n",
        "            \"x\",\n",
        "            THREADS_Y,\n",
        "            \" = 1024 threads/block\",\n",
        "        )\n",
        "        print(\"\\nDevice:\", ctx.api())\n",
        "\n",
        "        var total_time: Float64 = 0.0\n",
        "\n",
        "        # Config 1: hd=2048, m=8192 (treat as 2048 rows Ã— 8192 cols)\n",
        "        var hd1: Int = 2048\n",
        "        var m1: Int = 8192\n",
        "        print(\"\\nConfig 1: rows=\", hd1, \", cols=\", m1, \", n_weights=\", hd1 * m1)\n",
        "\n",
        "        var t1_up = bench_layer_2d(ctx, hd1, m1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t1_up, \" s\")\n",
        "        var t1_gate = bench_layer_2d(ctx, hd1, m1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t1_gate, \" s\")\n",
        "        var t1_down = bench_layer_2d(ctx, hd1, m1, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t1_down, \" s\")\n",
        "\n",
        "        var config1_time = t1_up + t1_gate + t1_down\n",
        "        print(\"  Config 1 total: \", config1_time, \" s\")\n",
        "        total_time += config1_time\n",
        "\n",
        "        # Config 2: hd=1024, m=4096\n",
        "        var hd2: Int = 1024\n",
        "        var m2: Int = 4096\n",
        "        print(\"\\nConfig 2: rows=\", hd2, \", cols=\", m2, \", n_weights=\", hd2 * m2)\n",
        "\n",
        "        var t2_up = bench_layer_2d(ctx, hd2, m2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t2_up, \" s\")\n",
        "        var t2_gate = bench_layer_2d(ctx, hd2, m2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t2_gate, \" s\")\n",
        "        var t2_down = bench_layer_2d(ctx, hd2, m2, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t2_down, \" s\")\n",
        "\n",
        "        var config2_time = t2_up + t2_gate + t2_down\n",
        "        print(\"  Config 2 total: \", config2_time, \" s\")\n",
        "        total_time += config2_time\n",
        "\n",
        "        # Config 3: hd=4096, m=14336\n",
        "        var hd3: Int = 4096\n",
        "        var m3: Int = 14336\n",
        "        print(\"\\nConfig 3: rows=\", hd3, \", cols=\", m3, \", n_weights=\", hd3 * m3)\n",
        "\n",
        "        var t3_up = bench_layer_2d(ctx, hd3, m3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  up_proj   : \", t3_up, \" s\")\n",
        "        var t3_gate = bench_layer_2d(ctx, hd3, m3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  gate_proj : \", t3_gate, \" s\")\n",
        "        var t3_down = bench_layer_2d(ctx, hd3, m3, NUM_ITERS_PER_LAYER)\n",
        "        print(\"  down_proj : \", t3_down, \" s\")\n",
        "\n",
        "        var config3_time = t3_up + t3_gate + t3_down\n",
        "        print(\"  Config 3 total: \", config3_time, \" s\")\n",
        "        total_time += config3_time\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"TOTAL Mojo NF4 dequant time:\", total_time, \"seconds\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Compare to Unsloth Triton reference time\n",
        "        var unsloth_time: Float64 = 5.320246934890747\n",
        "        var speedup = unsloth_time / total_time\n",
        "        print(\"\\nUnsloth Triton time (ref): \", unsloth_time, \" s\")\n",
        "        print(\"Mojo kernel time:          \", total_time, \" s\")\n",
        "        print(\"Speedup (Triton / Mojo):   \", speedup, \"x\")\n",
        "\n",
        "        if speedup >= 1.15:\n",
        "            print(\"\\nâœ… SUCCESS: Achieved >= 1.15x speedup!\")\n",
        "        else:\n",
        "            print(\"\\nâŒ Need more optimization to reach 1.15x speedup\")\n",
        "\n"
      ],
      "metadata": {
        "id": "CHkAkXxYdFuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db6c8368-7c20-4110-a80b-a17f61509f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "NF4 Dequantization Benchmark (Mojo 2D Tiled Kernel)\n",
            "============================================================\n",
            "\n",
            "--- Correctness Test ---\n",
            "idx\tCPU\t\tGPU\t\tdiff\n",
            "0 \t -0.010002136 \t -0.010002136 \t 0.0\n",
            "1 \t -0.0069618225 \t -0.0069618225 \t 0.0\n",
            "2 \t -0.0069618225 \t -0.0069618225 \t 0.0\n",
            "3 \t -0.0052490234 \t -0.0052490234 \t 0.0\n",
            "4 \t -0.0052490234 \t -0.0052490234 \t 0.0\n",
            "5 \t -0.0039482117 \t -0.0039482117 \t 0.0\n",
            "6 \t -0.0039482117 \t -0.0039482117 \t 0.0\n",
            "7 \t -0.0028438568 \t -0.0028438568 \t 0.0\n",
            "8 \t -0.0028438568 \t -0.0028438568 \t 0.0\n",
            "9 \t -0.0018472672 \t -0.0018472672 \t 0.0\n",
            "10 \t -0.0018472672 \t -0.0018472672 \t 0.0\n",
            "11 \t -0.00091028214 \t -0.00091028214 \t 0.0\n",
            "12 \t -0.00091028214 \t -0.00091028214 \t 0.0\n",
            "13 \t 0.0 \t 0.0 \t 0.0\n",
            "14 \t 0.0 \t 0.0 \t 0.0\n",
            "15 \t 0.0007958412 \t 0.0007958412 \t 0.0\n",
            "max_abs_diff = 0.0\n",
            "Correctness test PASSED!\n",
            "\n",
            "--- Unsloth-style Dequant Bench ---\n",
            "Each layer runs 1000 kernel launches.\n",
            "Using 2D tiled kernel:  256 x 4  = 1024 threads/block\n",
            "\n",
            "Device: cuda\n",
            "\n",
            "Config 1: rows= 2048 , cols= 8192 , n_weights= 16777216\n",
            "  up_proj   :  0.243986434  s\n",
            "  gate_proj :  0.250721282  s\n",
            "  down_proj :  0.250297348  s\n",
            "  Config 1 total:  0.7450050639999999  s\n",
            "\n",
            "Config 2: rows= 1024 , cols= 4096 , n_weights= 4194304\n",
            "  up_proj   :  0.057777153  s\n",
            "  gate_proj :  0.0504832  s\n",
            "  down_proj :  0.050326526  s\n",
            "  Config 2 total:  0.15858687900000001  s\n",
            "\n",
            "Config 3: rows= 4096 , cols= 14336 , n_weights= 58720256\n",
            "  up_proj   :  1.132766235  s\n",
            "  gate_proj :  1.134144531  s\n",
            "  down_proj :  1.135756347  s\n",
            "  Config 3 total:  3.402667113  s\n",
            "\n",
            "============================================================\n",
            "TOTAL Mojo NF4 dequant time: 4.306259056 seconds\n",
            "============================================================\n",
            "\n",
            "Unsloth Triton time (ref):  5.320246934890747  s\n",
            "Mojo kernel time:           4.306259056  s\n",
            "Speedup (Triton / Mojo):    1.2354683881542001 x\n",
            "\n",
            "âœ… SUCCESS: Achieved >= 1.15x speedup!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rest of the Unsloth Puzzles"
      ],
      "metadata": {
        "id": "YC9qv5BcTlzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B) Make `QLoRA` work with `FSDP2` [Difficulty: Medium to Hard] [Max points: 10]"
      ],
      "metadata": {
        "id": "na3sbSYhTdhP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXshnajO44Kb"
      },
      "source": [
        "<a name=\"FSDP2\"></a>\n",
        "\n",
        "1. Goal: Write a single Python script to finetune Llama 3.1 8B on 2x or more GPUs with FSDP2.\n",
        "\n",
        "2. You must showcase this working in a free **Kaggle notebook with 2 x Tesla T4 GPUs**.\n",
        "\n",
        "3. Pipeline parallelism is also fine, but must utilize [`zero bubble scheduling`](https://pytorch.org/docs/stable/distributed.pipelining.html#torch.distributed.pipelining.schedules.ScheduleInterleavedZeroBubble) somehow.\n",
        "\n",
        "4. Can use a pre-quantized 4bit BnB safetensor file from [Unsloth's HF page](https://huggingface.co/unsloth) or a full 16bit one, but must do QLoRA.\n",
        "\n",
        "5. Can use `accelerate` but must be FSDP2 or related - you can investigate https://github.com/huggingface/accelerate/pull/3394, Torch Titan, other repos etc.\n",
        "\n",
        "6. Must be fully `transformers` compatible - so we must use `TrainingArguments` and `Trainer`, or `TRL` related classes.\n",
        "\n",
        "7. The loss must be equivalent to single GPU training.\n",
        "\n",
        "8. You must enable all features in FSDP2 - ie showcase offloading, checkpointing, mixed precision training etc.\n",
        "\n",
        "9. You can use `nf4` from `torch AO`, but best from `bitsandbytes`.\n",
        "\n",
        "10. Finally showcase everything working in a free Kaggle 2x Tesla T4 notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjo8K1lHAyI0"
      },
      "outputs": [],
      "source": [
        "# HELPFUL functions to undo Unsloth patches:\n",
        "import sys\n",
        "\n",
        "def remove_patched_module(package_name):\n",
        "    modules_to_delete = [\n",
        "        name for name in sys.modules\n",
        "        if name == package_name or name.startswith(package_name + \".\")\n",
        "    ]\n",
        "    for name in modules_to_delete: del sys.modules[name]\n",
        "\n",
        "remove_patched_module(\"trl\")\n",
        "remove_patched_module(\"transformers\")\n",
        "remove_patched_module(\"peft\")\n",
        "remove_patched_module(\"bitsandbytes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QYoe7A0PwXY"
      },
      "source": [
        "Below is an example script which should run fine in Kaggle 2x Telsa T4s:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328,
          "referenced_widgets": [
            "d33171e7f9f7435e9609ebce0a7bae64",
            "cb46e9b7a8a540a1a7a09dd64823052b",
            "c402aa198f36471aae5499024f8d6d66",
            "edb68a122c334c5193fe21fde4eedc66",
            "6eadec6ada3640e5827d4a69a4b96132",
            "1f1d6c05ab1547da96a10ca82e003b92",
            "14c092ed314c4dc28b17e8c41e3d70f7",
            "d4d30920fadb42e688e7d935f5d388de",
            "a041a5627ac949068ae137f36a5f4dd0",
            "d8b246969dba462faf712ca1a742ba37",
            "5381b6e7723b41a4b6a7f903759a1a7b",
            "02a7355fe4e4487c9f93adc03b0965c2",
            "d4b583ad5b1841d1b17f7d9e624adb7f",
            "34623fb46fbc43409ecfa76aafde60fb",
            "dccc44fdef36476d9053466e95ef3a03",
            "51befa7ea9444beb974cd898fd269c49",
            "dd0d238272494a9ebab48d9f9b3cc07f",
            "b1ea87cf2c6346db987d9ebe67d970e0",
            "3fec812d653f43aab6daef1ad96b25bb",
            "6b47182ca29c4efba3d1a985bdd6154b",
            "9217b9e57e134811a71c5689dc10dfb3",
            "8393a23d15454a18bbd2daefb7880047",
            "60745962f179450ea4d09848cd469a13",
            "60d5707fab6b4f1cb693caba407ca242",
            "c63f9a8cfc4347c29716689640b82438",
            "171067bb692449deb203d823aaf354ae",
            "4c0e101302144196834f21146ae86a56",
            "87a9db0c3e1342718d2a92a3331b931e",
            "e5f319c7991844e78f5f191e022352eb",
            "9416cc1dc4d2499aa80ed637ecb2524c",
            "ca1bf7a5cb9543f3a6e5d597c99da7cf",
            "c00c50c3e304452993bc14864fd803e1",
            "5c1eea500ca6417e8633e177b7e454f0",
            "4ca05f7a7f2c4a6b9411d932a581b96f",
            "557ccd6d1129493390e9de5af5047803",
            "aa8c7b1f23954bcdb6b6b5307231f324",
            "07a37e2cd57c40f291c453252946d7ae",
            "44f869ff4bbd4774b870a25f1c5ed7d3",
            "feff1dc3c37440c5a1457c4d6fae2814",
            "fb05393aac774c8196da8d2cca207f97",
            "2c2b659c738846818fd669d59ffea530",
            "e5e1e6c9f11f460ba59ebe947bd9c36a",
            "9c85585806d741a88a99732ba74266b8",
            "2ff3472c871842eabb81b1963e59fd63",
            "7bc08a39aa144c3391e9152ab590d345",
            "f9d3ca662f2e479a83d0fbbd40cb2cdd",
            "5c9c61b46fd94e8982fef8dc23c8835d",
            "bd012dbe82844efebf286fdfe6698685",
            "ecf789c2c2054120a7470a7f1c2de51e",
            "0875f4cfb3e04b72870389ade4aca0dc",
            "4f2247c6f3ab484e93c13ea16407784a",
            "e4d6416795d046a69279025141db9028",
            "8db8ffc5db77427080a6adeff922718d",
            "66e1a997a07341dc9e433aeee69796a1",
            "7e304840b3194b63a35429312f60bbd0",
            "8d8e553c2da34ea0b39b8876172feacc",
            "f68b4512f73047a4a34795c4afb8c02e",
            "cd40dcff85454a668104c90c7f7df805",
            "913472fdbb59469698c710707ab23ef9",
            "b5224851afa040f49ad1d627cc1a770c",
            "0ba82e790b954e78b5807e82c4e97e21",
            "7188c0a589c54560ae13f9d438a211d1",
            "7a7535c05c394abf80bc1421bf5aaff5",
            "39763d4b0744409db567dcc5792d6a4d",
            "d91a18b3322c47159f971b4fe6101228",
            "80b51d6d9e66498b8b830282d5ea678d",
            "b10a9ec495a94fd08076841eb67a9e3e",
            "306412737a9c4098a27329966f3f364c",
            "51268827e9d44ce5844f2959646355e9",
            "cae52970160a4a52b3d4a52deda0d96d",
            "35e697a93d4b4040a5b27d67987a2bb6",
            "014be59294894ed6bc68f839cf3de5e9",
            "7c174a9af7624b8584fd63ecc195fd31",
            "3c8ae3592bca4bc0b091b7db4b025c44",
            "60144d2c919744f7b7934c9d523b523a",
            "c8459c680f4d4e46a156714642178fe4",
            "54862b67e81547b197560323e3fedc08",
            "b0780c6be64c46e99bdc40a6044d518d",
            "1ba8c5c7ab9e4552907ca55247d510e2",
            "3a213a5a54b94b14a95a439b5950754b",
            "12ef112247ee4464a9af2496afd2ca56",
            "66427fa7a07a4cc6befa8f4ddf863487",
            "22ae3abacb844fe2b30faff45bb5c1ff",
            "63a697198d7c4eae8fbe7b304f2f9e21",
            "6a02115f60154e6e9a5cc85bddba58b9",
            "988bc7535aba4886adff9a8aaac8ba55",
            "e6c07f50c49f4d6aa3783b535e4c5c06",
            "c9f98890e58d4b91a5b10d4acf765b4f"
          ]
        },
        "id": "fxY0ycaRB4PY",
        "outputId": "b64671d7-512b-4b29-b996-77bcaecd4720"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d33171e7f9f7435e9609ebce0a7bae64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02a7355fe4e4487c9f93adc03b0965c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60745962f179450ea4d09848cd469a13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/55.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ca05f7a7f2c4a6b9411d932a581b96f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bc08a39aa144c3391e9152ab590d345"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d8e553c2da34ea0b39b8876172feacc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unified_chip2.jsonl:   0%|          | 0.00/95.6M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b10a9ec495a94fd08076841eb67a9e3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0780c6be64c46e99bdc40a6044d518d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,\"\\\n",
        "    \"roundup_power2_divisions:[32:256,64:128,256:64,>:32]\"\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "max_seq_length = 2048\n",
        "torch.set_default_dtype(torch.float16)\n",
        "model_name = \"unsloth/meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
        "dtype = torch.float16\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit              = True,\n",
        "    bnb_4bit_use_double_quant = True,\n",
        "    bnb_4bit_quant_type       = \"nf4\",\n",
        "    bnb_4bit_compute_dtype    = dtype,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map = \"auto\",\n",
        "    attn_implementation = \"sdpa\",\n",
        "    quantization_config = bnb_config,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r = 64,\n",
        "    lora_alpha = 128,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    task_type = TaskType.CAUSAL_LM,\n",
        ")\n",
        "\n",
        "# Get LoRA and setup model\n",
        "model = get_peft_model(model, lora_config)\n",
        "with torch.no_grad():\n",
        "    for name, param in model.named_parameters():\n",
        "        if \".lora_A.\" in name or \".lora_B.\" in name: param.requires_grad_(True)\n",
        "        else: param.requires_grad_(False)\n",
        "model.gradient_checkpointing_enable()\n",
        "model.enable_input_require_grads()\n",
        "\n",
        "# Get dataset\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "url = \"https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl\"\n",
        "dataset = load_dataset(\"json\", data_files = {\"train\" : url}, split = \"train[:10%]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71dEjjtGmtuH"
      },
      "source": [
        "Reminder your code must have the same loss curve over 60 steps or so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600,
          "referenced_widgets": [
            "c78a6c11d9124e5a92920422d122c852",
            "287cc5d4be704e70b9590a67725013ad",
            "4cf101f8733e440ca126ed0128581f8e",
            "2788b87a6db64edf987ea456f2d7269a",
            "749b7205bc35409196003d174ec44375",
            "536152188fd9436fbc936f46aed55e83",
            "d039da580f404715aca774ea535e9c71",
            "2ed9f2257feb45e09d68cd0b96082a1d",
            "1b394c083a144afe9f785e48a31cedb3",
            "ad0d75c3655e418fb4dcbafd0a639632",
            "c68c4c0fc48c42548e7e399a0f7485f7",
            "43e589f13119463ab3f25cbab46d10e7",
            "7954981b42c64509aad1ead118cba61d",
            "9c99c79f2f5e4afbae5c3b1cc342e700",
            "385eb08545164b9f8eb455fc4ef6e097",
            "7b22ea5fd5ca444280d8cf8a43136099",
            "1023af6301f44ebeab7a8d899eb58522",
            "52a6557e482d446ea1e98ffa83441e9b",
            "0cb5711d02dd43218e4955e1be601e54",
            "85e9bbf72bb6422591fe9d84e6acd391",
            "f889097fad314f59ac0f27c097ac28ae",
            "57af46dfdba74fa58bcf7db42a378f60",
            "5b8ef0c9583b4879a7f0ae04a60fb39f",
            "ecb68987b074428380ea39a71ea4560c",
            "995a7668bdc74fb8a4fdec8ca802db4d",
            "1c64b2646537410693cf41f077b9f40f",
            "ae0ace153e6e42429bc80707effc7c97",
            "6630d0e47d2842f7a5261f89e9235ae4",
            "996c93f8e21649fea2720ab9cb8e21fc",
            "f7678cabf31849e493628c4fb260b98e",
            "16129167e0be4d77989b5cfb8d840bd3",
            "9b7470b87b804d868f5430769c230592",
            "b43cf65240104debb35756801cee867b"
          ]
        },
        "id": "BV2WK_wEDtUn",
        "outputId": "57ac1b9a-ca27-4e2f-f894-e44510a2ecbf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Applying chat template to train dataset (num_proc=4):   0%|          | 0/21029 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c78a6c11d9124e5a92920422d122c852"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset (num_proc=4):   0%|          | 0/21029 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43e589f13119463ab3f25cbab46d10e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset (num_proc=4):   0%|          | 0/21029 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b8ef0c9583b4879a7f0ae04a60fb39f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 01:23, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.039400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.254400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.649500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.936600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.886300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.873100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.577100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.687100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.540900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.792700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10, training_loss=1.9237143635749816, metrics={'train_runtime': 91.7565, 'train_samples_per_second': 0.872, 'train_steps_per_second': 0.109, 'total_flos': 461650822987776.0, 'train_loss': 1.9237143635749816})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    train_dataset = dataset,\n",
        "    processing_class = tokenizer,\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 1,\n",
        "        max_steps = 10,\n",
        "        logging_steps = 1,\n",
        "        output_dir = \"outputs\",\n",
        "        seed = 3407,\n",
        "        max_seq_length = max_seq_length,\n",
        "        fp16 = model.get_input_embeddings().weight.dtype == torch.float16,\n",
        "        bf16 = model.get_input_embeddings().weight.dtype == torch.bfloat16,\n",
        "        report_to = \"none\", # For W&B\n",
        "        dataset_num_proc = 4,\n",
        "    ),\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnm9AlVvpPhb"
      },
      "outputs": [],
      "source": [
        "del model\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vIg_ZjYt1Tq"
      },
      "source": [
        "## Marking Criteria for B) Max points = 10\n",
        "```python\n",
        "if attemped_B:\n",
        "    B_score = 0\n",
        "    if FSDP2_works_with_QLoRA:\n",
        "        if torch_compile_works: B_score += 5\n",
        "        else: B_score += 3\n",
        "        if uses_part_A_and_single_kernel_and_faster: B_score += 3\n",
        "        elif uses_torchAO:\n",
        "            if torchAO_slower_than_BnB: B_score -= 3\n",
        "    elif TP_or_PP_with_QLoRA:\n",
        "        if zero_bubble: B_score += 3\n",
        "        else: B_score += 2\n",
        "    elif FSDP1_works_with_QLoRA:\n",
        "        B_score += 1\n",
        "    if kaggle_notebook_2_tesla_t4_example:\n",
        "        B_score += 2\n",
        "    else:\n",
        "        B_score = 0\n",
        "    final_score += B_score\n",
        "else:\n",
        "    final_score -= 2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C) Make `torch.compile` work without graph breaks for QLoRA [Difficulty: Easy to Medium] [Max points: 9]"
      ],
      "metadata": {
        "id": "Z3vJsA0MToZw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pukEsR2YnIHQ"
      },
      "source": [
        "<a name=\"COMPILE\"></a>\n",
        "\n",
        "1. Goal: Write a single Python script like task B), except the goal is to `torch.compile` all modules if possible.\n",
        "\n",
        "2. There must NOT be graph breaks, and excessive re-compilations should not be seen.\n",
        "\n",
        "3. You should have say max 30 compilations. Over 60 is definitely wrong.\n",
        "\n",
        "4. The loss must match with the non compiled module.\n",
        "\n",
        "5. Utilize patching as much as possible.\n",
        "\n",
        "6. Think about which areas might need disabling for compilation. Think about regional compilation. How do we compile sections efficiently?\n",
        "\n",
        "7. Log memory / VRAM usage, and monitor speedups as well.\n",
        "\n",
        "8. Must work for QLoRA.\n",
        "\n",
        "We provided a script below, and showcased how to detect if graph breaks are seen. We also torch compiled the MLP for Llama:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFOXncAVNqmK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch_compile_options = torch_compile_options = {\n",
        "    \"epilogue_fusion\"   : True,\n",
        "    \"max_autotune\"      : True,\n",
        "    \"shape_padding\"     : True,\n",
        "    \"trace.enabled\"     : True,\n",
        "    \"triton.cudagraphs\" : False,\n",
        "}\n",
        "\n",
        "@torch.compile(fullgraph = False, dynamic = True, options = torch_compile_options)\n",
        "def compiled_llama_mlp(self, x):\n",
        "    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
        "    return down_proj\n",
        "\n",
        "import transformers.models.llama.modeling_llama\n",
        "transformers.models.llama.modeling_llama.LlamaMLP.forward = compiled_llama_mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "2650669091e449f7a12f3ead7d4c20ad",
            "3dc8d64196b14f4197cd3339742a34bc",
            "7158ed68d61d4d80b2e3747c390fda80",
            "641623b174014cf1a971e3e09acf9164",
            "a2de6c359c5449b19f2f20534b3cddfc",
            "5fdf71c34276475b9f06d1f0f3df43a0",
            "0a3d0e0a03d047a8b90bbe9d98c26f3f",
            "09299fa4aa0e41ce87f9b27df73600f1",
            "4e7bcee3a16949b3a6ea93bba773e43f",
            "92a1f52385ef425eafd685fc7dc351c7",
            "e3a2d60dd4c24aacb6425b4bb0ee066e",
            "83a069d07e62433fbdeccd446629f933",
            "7f598a003c3a46d8b1bc9b9e09961d8f",
            "c8759c84b0cc41d1b26c9ebb8d1c1bd8",
            "6d472692e8ef41568614da4c8524ac90",
            "06831f66e5ea482e93837ee00fce9413",
            "559908d1ab2247e693e273b9da52c5a7",
            "cd3fc5a7061c4ce6b66c3ee70b0dc4ab",
            "4210ab573d8e4eb586989b74b51c7244",
            "5da5844a476641679e995289c3e6701c",
            "7df04b49b6d14d7fb4900c315c1d9369",
            "6186d0196b584ebc9debb77ed3835fc3",
            "85cacea45f094105921c3430f0f9ff16",
            "4120cf65fc154f7aa0f339a0ca9ccf04",
            "a397ac9ead5644e79e3201669253bbee",
            "a2ab9f82bf8949df8fcec7067153ced0",
            "472ff429959940a09c8ba6d08b50991c",
            "0c3c7a2269ab4099b8a9232ccd358fd7",
            "056f3c7e217140e384b934511108a211",
            "2bd03db6056546698822b83c0aae3519",
            "28eef2874a974ffd887bbed667a44161",
            "a97ff63c9116491284dcc086330a68a9",
            "56f84a989c0b4637a5f4695f7e255d03",
            "9867e25e17a24d59935f0fbed4aed30e",
            "3edc46c5a96d4e9c9fea69c1e180abd4",
            "1efa9da14cd94d0e9e50d97fa326fe74",
            "86febc74651a47ffb4d02ee4e34340de",
            "eeff3f5036cb4642a6cdbf34f1342c07",
            "d2161b9b632d4c2e9ad5667c189ce7bf",
            "52eb5d70f7d540c28ce8e39d7eb3569e",
            "67ea2cdb7b424448882e76b8f7fa767d",
            "6df34bb109bc49909b15b58a76027d04",
            "fb452d291e9f42c5ba93f4a7a4a17ca7",
            "e1cd8b04457b4943b6027cde16089378",
            "358313f3922d439fa511a83f01faa2db",
            "28c1d59998ea4c278f75b9f1fb8f62ca",
            "e730ff355cb4498e83cbc92e5edd7274",
            "1705fd65a03a4e4e9b5d9b5a09691a2f",
            "1e9a88491bf6473db41743d92ff3dbe7",
            "4e374cbbaa1849f5856bae0e3023352e",
            "c5c42f84490340e78c0f972c3108ed47",
            "d6ece92b44074841bda3a29889fa0363",
            "61ec012bc6b242f39b8b67e47db3b6b4",
            "fcf382a7918641ebb174928df69ce161",
            "00e10167b3164042bee7a2495181e2f0",
            "f9d5827a6d9648fd812228e9af59495b",
            "f9aa215287dd4b6aa89530e7454be6e0",
            "713ff98c8a4e4703a843ebf5fdcf7bc7",
            "1e7e6d5390804c12a0d14481686fdaec",
            "9045d8eca08b4889a8706893de6702b9",
            "201b0ed743184b73ae61038d5552c233",
            "221f4d520dc7498fad01f741688e7606",
            "8654cb9bfe994d0fa53a3dbde9a2e38e",
            "ec1df11660394fc69591c3f1c946b406",
            "369110b87c79404b9e4e9dea18d3ab99",
            "42abe8c63c4d46bdbc7077f0d546f2d8"
          ]
        },
        "id": "WmoQzMDzm1zL",
        "outputId": "34baecbb-30b6-4057-ae96-c4c0f0017e7a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2650669091e449f7a12f3ead7d4c20ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.03G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83a069d07e62433fbdeccd446629f933"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85cacea45f094105921c3430f0f9ff16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9867e25e17a24d59935f0fbed4aed30e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "358313f3922d439fa511a83f01faa2db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9d5827a6d9648fd812228e9af59495b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \\\n",
        "    \"expandable_segments:True,\"\\\n",
        "    \"roundup_power2_divisions:[32:256,64:128,256:64,>:32]\"\n",
        "\n",
        "max_seq_length = 1024\n",
        "torch.set_default_dtype(torch.float16)\n",
        "model_name = \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\"\n",
        "dtype = torch.float16\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit              = True,\n",
        "    bnb_4bit_use_double_quant = True,\n",
        "    bnb_4bit_quant_type       = \"nf4\",\n",
        "    bnb_4bit_compute_dtype    = dtype,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map = \"auto\",\n",
        "    attn_implementation = \"sdpa\",\n",
        "    quantization_config = bnb_config,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r = 32,\n",
        "    lora_alpha = 64,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    task_type = TaskType.CAUSAL_LM,\n",
        ")\n",
        "\n",
        "# Get LoRA and setup model\n",
        "model = get_peft_model(model, lora_config)\n",
        "with torch.no_grad():\n",
        "    for name, param in model.named_parameters():\n",
        "        if \".lora_A.\" in name or \".lora_B.\" in name: param.requires_grad_(True)\n",
        "        else: param.requires_grad_(False)\n",
        "\n",
        "# Currently GC will cause torch.compile to be disabled, so disable it\n",
        "# model.gradient_checkpointing_enable()\n",
        "model.enable_input_require_grads()\n",
        "\n",
        "# Get dataset\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "url = \"https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl\"\n",
        "dataset = load_dataset(\"json\", data_files = {\"train\" : url}, split = \"train[:10%]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbVNGNQ5LlpJ"
      },
      "source": [
        "We provide full logging for `torch.compile` like below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsekFGdsK5hZ"
      },
      "outputs": [],
      "source": [
        "# Must show all graph breaks are not seen with torch.compile\n",
        "import os\n",
        "os.environ[\"TORCHDYNAMO_VERBOSE\"] = \"1\"\n",
        "os.environ[\"TORCHINDUCTOR_FORCE_DISABLE_CACHES\"] = \"1\"\n",
        "os.environ[\"TORCHINDUCTOR_COMPILE_THREADS\"] = \"1\"\n",
        "\n",
        "import logging\n",
        "torch._inductor.config.debug = True\n",
        "torch._logging.set_logs(\n",
        "    dynamo = logging.WARN,\n",
        "    inductor = logging.WARN,\n",
        "    graph_breaks = True,\n",
        "    recompiles = True,\n",
        "    recompiles_verbose = True,\n",
        "    compiled_autograd_verbose = True,\n",
        "    # aot_joint_graph = True, # Enable for more logs\n",
        "    # aot_graphs = True,\n",
        ")\n",
        "torch._dynamo.config.verbose = True\n",
        "torch._dynamo.config.suppress_errors = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RdragY7P-dL"
      },
      "source": [
        "When we execute the code below, we can see graph breaks - remove them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHOBZGLepYgg"
      },
      "outputs": [],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    train_dataset = dataset,\n",
        "    processing_class = tokenizer,\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 1,\n",
        "        gradient_accumulation_steps = 2,\n",
        "        warmup_steps = 1,\n",
        "        max_steps = 10,\n",
        "        logging_steps = 1,\n",
        "        output_dir = \"outputs\",\n",
        "        seed = 3407,\n",
        "        max_seq_length = max_seq_length,\n",
        "        fp16 = model.get_input_embeddings().weight.dtype == torch.float16,\n",
        "        bf16 = model.get_input_embeddings().weight.dtype == torch.bfloat16,\n",
        "        report_to = \"none\", # For W&B\n",
        "        dataset_num_proc = 4,\n",
        "    ),\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPbbwd5uDOL1"
      },
      "source": [
        "Log all your steps for debugging in a Colab (maybe this one). Edward's blog http://blog.ezyang.com/, Horace's blogs https://www.thonking.ai/, Slaying OOMs by Jane & Mark: ttps://www.youtube.com/watch?v=UvRl4ansfCg could be useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wojg8SDjv3fu"
      },
      "source": [
        "## Marking Criteria for C) Max points = 9\n",
        "```python\n",
        "if attemped_C:\n",
        "    C_score = 0\n",
        "    if uses_flex_attention:\n",
        "        if dynamic_sequence_length_works: C_score += 3\n",
        "        else: C_score += 1\n",
        "    if no_torch_compile_BnB: C_score -= 2\n",
        "    elif use_part_A: C_score += 1\n",
        "    elif torch_compile_BnB: C_score += 1\n",
        "\n",
        "    if attention_compiled:\n",
        "        if excessive_recompilation: C_score -= 3\n",
        "        else: C_score += 2\n",
        "    if mlp_compiled:\n",
        "        if excessive_recompilation: C_score -= 3\n",
        "        C_score += 1\n",
        "\n",
        "    if not loss_compiled: C_score -= 1\n",
        "    if not layernorms_compiled: C_score -= 3\n",
        "\n",
        "    if max_autotune_triton_matmul:\n",
        "        if excessive_recompilation: C_score -= 2\n",
        "        else: C_score += 2\n",
        "    \n",
        "    final_score += C_score\n",
        "else:\n",
        "    final_score -= 1\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D) Help solve ðŸ¦¥ Unsloth issues! [Difficulty: Varies] [Max points: 12]"
      ],
      "metadata": {
        "id": "0PyQfFK4Tyi9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKcvFLCsQLtL"
      },
      "source": [
        "<a name=\"ISSUES\"></a>\n",
        "\n",
        "Head over to https://github.com/unslothai/unsloth, and find some issues which are still left standing / not resolved. The tag **currently fixing** might be useful.\n",
        "\n",
        "Each successfully accepted and solved issue will also have \\$100 to \\$1000 of bounties.\n",
        "\n",
        "It's best to attempt these features:\n",
        "\n",
        "* **<ins>Tool Calling</ins>** [Points = 1] Provide a tool calling Colab notebook and make it work inside of Unsloth. <ins>Bounty: \\$1000</ins>\n",
        "\n",
        "* **<ins>GGUF Vision support</ins>** [Points = 1] Allow exporting vision finetunes to GGUF directly. Llava and Qwen VL must work. <ins>Bounty: \\$500</ins>\n",
        "\n",
        "* **<ins>Refactor Attention</ins>** [Points = 2] Refactor and merge xformers, SDPA, flash-attn, flex-attention into a simpler interface. Must work seamlessly inside of Unsloth. <ins>Bounty: \\$350</ins>\n",
        "\n",
        "* <font color='red'>DONE</font> ** <ins><del>Windows support</del></ins>** [Points = 2] Allow `pip install unsloth` to work in Windows - Triton, Xformers, bitsandbytes should all function. You might need to edit `pyproject.toml`. Confirm it works. <ins>Bounty: \\$300</ins>\n",
        "\n",
        "* **<ins>Support Sequence Classification</ins>** [Points = 1] Create patching functions to patch over AutoModelForSequenceClassification, and allow finetuner to use AutoModelForSequenceClassification. <ins>Bounty: \\$200</ins>\n",
        "\n",
        "* **<ins>VLMs Data Collator</ins>** [Points = 1] Make text & image mixing work efficiently -so some inputs can be text only. Must work on Qwen, Llama, Pixtral. <ins>Bounty: \\$100</ins>\n",
        "\n",
        "* <font color='red'>DONE</font> **<ins>VLMs image resizing</ins>** [Points = 1] Allow finetuner to specify maximum image size, or get it from the config.json file. Resize all images to specific size to reduce VRAM. <ins>Bounty: \\$100</ins>\n",
        "\n",
        "* **<ins>Support Flex Attention</ins>** [Points = 2] Allow dynamic sequence lengths without excessive recompilation. Make this work on SWAs and normal causal masks. Also packed sequence masks. <ins>Bounty: \\$100</ins>\n",
        "\n",
        "* <font color='red'>DONE</font> **<ins>VLMs train only on completions</ins>** [Points = 1] Edit `train_on_responses_only` to allow it to work on VLMs. <ins>Bounty: \\$100</ins>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VfYZjuMxujG"
      },
      "source": [
        "## Marking Criteria for D) Max points = 12\n",
        "```python\n",
        "if attemped_D:\n",
        "    D_score = 0\n",
        "    for subtask in subtasks:\n",
        "        if sucessfully_completed_subtask:\n",
        "            D_score += score_for_subtask\n",
        "    final_score += D_score\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## E) Memory Efficient Backprop [Difficulty: Medium to Hard] [Max points: 10]"
      ],
      "metadata": {
        "id": "uEngsbCOT39W"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrJzggfH2YEG"
      },
      "source": [
        "<a name=\"MATH\"></a>\n",
        "\n",
        "In LLMs, the last layer is a projection matrix to calculate the probabilities of the next token, ie $\\sigma(XW)$. However, if the vocabulary size is very large, say 128K, then the materialization of the logits causes VRAM spikes.\n",
        "\n",
        "For example, if the `bsz = 4, qlen = 4096, hd = 4096, vocab = 128K`, then the memory usage for the logits in bfloat16 would be 4GB. In the worst case, we might even need to upcast logits to float32, so 8GB is needed.\n",
        "\n",
        "In Unsloth, we utilize [Apple's Cut Cross Entropy Loss](https://machinelearning.apple.com/research/cut-your-losses) to reduce VRAM usage, by allowing a Triton kernel to create the logits on the fly to calculate the cross entropy loss. But this does not generalize well to other functions.\n",
        "\n",
        "Our goal is to generalize this ultimately, but directly creating logits on the fly will be hard. Instead, let's take a slightly less complex approach. Let's first review some stuff. We first notice that during the normal case after forming the intermediate logits for 2 batches, we then do a gather function to aggregate the intermediate results into a single column:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\times W &= \\begin{bmatrix} x_1 W \\\\ x_2 W \\end{bmatrix} \\\\\n",
        "f \\bigg( \\begin{bmatrix} x_1 W \\\\ x_2 W \\end{bmatrix} \\bigg) &= \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "So, if we can somehow skip the materialization of the intermediate logits, and just output the output of `f`, we can save a lot of VRAM!\n",
        "\n",
        "Notice during backpropagation we can use the chain rule:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{dL}{dX} &= \\frac{dL}{dy} \\frac{dy}{dX} ; \\frac{dL}{dW} = \\frac{dL}{dy} \\frac{dy}{dW} \\\\\n",
        "\\frac{dL}{dy} &= \\text{Downstream from backprop} \\\\\n",
        "\\frac{dy}{dX} &= W^T \\\\\n",
        "\\frac{dy}{dW} &= X^T \\\\\n",
        "\\frac{dL}{dX} &= \\frac{dL}{dy} W^T \\\\\n",
        "\\frac{dL}{dW} &= X^T \\frac{dL}{dy} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "If we simply compute the intermediate tensors on the fly via batches, say we do batch 1, then batch 2, we can reduce VRAM usage from 4GB to 2GB!\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{dL}{dX} &= \\begin{bmatrix} \\frac{dL_1}{dy_1} W^T \\\\ \\frac{dL_2}{dy_2} W^T \\end{bmatrix} \\\\\n",
        "\\frac{dL}{dW} &= \\bigg( X_1^T \\frac{dL_1}{dy_1} + X_2^T  \\frac{dL_2}{dy_2} \\bigg)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "1. Your goal is to write a `torch.autograd.Function` with a `forward` and `backward` pass showcasing this memory efficient implementation.\n",
        "\n",
        "2. You must NOT hard code the derivatives - move the transformation function from the logits / intermeditate tensors to a smaller tensor as a separate function which can allow `autograd` to pass through it.\n",
        "\n",
        "3. As a hint, look at `torch.checkpoint` at https://github.com/pytorch/pytorch/blob/main/torch/utils/checkpoint.py. Also, don't forget about the upstream gradients! We need to multiply them to the current gradients!\n",
        "\n",
        "4. Make the Cross Entropy Loss work. You must show other functions working as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp-IJIbv90f6"
      },
      "outputs": [],
      "source": [
        "def transformation_function(batch, linear, labels):\n",
        "    x = linear(batch).float() # Up projection to large space\n",
        "    from torch.nn import CrossEntropyLoss\n",
        "    down_projection_function = CrossEntropyLoss(reduction = \"mean\")\n",
        "    # Down projection to small space\n",
        "    loss = down_projection_function(x.view(-1, x.shape[-1]), labels.view(-1))\n",
        "    return loss\n",
        "\n",
        "class MemoryEfficientLinear(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, X, linear, labels, forward_function):\n",
        "        outputs = []\n",
        "        # EDIT THIS FUNCTION\n",
        "        output = forward_function(X, linear, labels)\n",
        "        ctx.save_for_backward(X)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, dY):\n",
        "        X = ctx.saved_tensors\n",
        "        # EDIT THIS FUNCTION\n",
        "        return X, None, None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lIczyn8-2-o"
      },
      "source": [
        "To test your implementation, it should not OOM for large inputs. Also, check the gradient is actually equivalent via `torch.allclose` in the normal approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVZ414R2Dk8M"
      },
      "source": [
        "## Marking Criteria for E) Max points = 10\n",
        "```python\n",
        "if attemped_E:\n",
        "    E_score = 0\n",
        "    if VRAM_50_percent_reduction: E_score += 2\n",
        "    if remove_float32_upcast: E_score = 0\n",
        "    if show_ce_loss_works: E_score += 1\n",
        "    if show_other_functions_work: E_score += 1\n",
        "    if hardcoded_gradients: E_score = 0\n",
        "    if allows_dynamic_chunk_sizes: E_score += 1\n",
        "    if llama_1B_training_loss_matches: E_score += 1\n",
        "    else: E_score = 0\n",
        "    if GRPO_memory_efficient_linear_works: E_score += 4\n",
        "    final_score += E_score\n",
        "else:\n",
        "    final_score += 0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission Steps"
      ],
      "metadata": {
        "id": "LO4aSXYxUCNF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvrVlTmUN8nV"
      },
      "source": [
        "<a name=\"SUBMISSION\"></a>\n",
        "\n",
        "1. All code should be in a public Github (Apache 2 Licensed)\n",
        "2. Kaggle notebooks and Colab notebooks should be linked in the README, and can be accessible through Colab / Kaggle.\n",
        "3. If attaching notebooks, must attach fully run ones - do not just add a notebook without running it. Kaggle notebook must be public, and run.\n",
        "4. Submit the Github to https://forms.gle/crSYnsGq3t1ck5TB9 If you want to send a private repo, please add me as a Github collaborate @danielhanchen\n",
        "5. Provide screenshots, graphs, plots, etc especially for training loss curves.\n",
        "6. We will comment and respond inside your Github repo. There will get 1 interview as well as a final step!\n",
        "\n",
        "### Clarifications:\n",
        "1. We'll compensate you if we interview you but don't hire you\n",
        "2. \\$100-\\$1000 bounties for Task 4\n",
        "3. Submissions must be Apache-2 licensed\n",
        "4. Task 4 involves solving Github issues for OSS Unsloth\n",
        "5. No time limit: rolling basis\n",
        "6. US based preferred"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d33171e7f9f7435e9609ebce0a7bae64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb46e9b7a8a540a1a7a09dd64823052b",
              "IPY_MODEL_c402aa198f36471aae5499024f8d6d66",
              "IPY_MODEL_edb68a122c334c5193fe21fde4eedc66"
            ],
            "layout": "IPY_MODEL_6eadec6ada3640e5827d4a69a4b96132"
          }
        },
        "cb46e9b7a8a540a1a7a09dd64823052b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f1d6c05ab1547da96a10ca82e003b92",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_14c092ed314c4dc28b17e8c41e3d70f7",
            "value": "config.json:â€‡100%"
          }
        },
        "c402aa198f36471aae5499024f8d6d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4d30920fadb42e688e7d935f5d388de",
            "max": 1532,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a041a5627ac949068ae137f36a5f4dd0",
            "value": 1532
          }
        },
        "edb68a122c334c5193fe21fde4eedc66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8b246969dba462faf712ca1a742ba37",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5381b6e7723b41a4b6a7f903759a1a7b",
            "value": "â€‡1.53k/1.53kâ€‡[00:00&lt;00:00,â€‡78.3kB/s]"
          }
        },
        "6eadec6ada3640e5827d4a69a4b96132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f1d6c05ab1547da96a10ca82e003b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14c092ed314c4dc28b17e8c41e3d70f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4d30920fadb42e688e7d935f5d388de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a041a5627ac949068ae137f36a5f4dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8b246969dba462faf712ca1a742ba37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5381b6e7723b41a4b6a7f903759a1a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02a7355fe4e4487c9f93adc03b0965c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4b583ad5b1841d1b17f7d9e624adb7f",
              "IPY_MODEL_34623fb46fbc43409ecfa76aafde60fb",
              "IPY_MODEL_dccc44fdef36476d9053466e95ef3a03"
            ],
            "layout": "IPY_MODEL_51befa7ea9444beb974cd898fd269c49"
          }
        },
        "d4b583ad5b1841d1b17f7d9e624adb7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd0d238272494a9ebab48d9f9b3cc07f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b1ea87cf2c6346db987d9ebe67d970e0",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "34623fb46fbc43409ecfa76aafde60fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fec812d653f43aab6daef1ad96b25bb",
            "max": 5702746383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b47182ca29c4efba3d1a985bdd6154b",
            "value": 5702746383
          }
        },
        "dccc44fdef36476d9053466e95ef3a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9217b9e57e134811a71c5689dc10dfb3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8393a23d15454a18bbd2daefb7880047",
            "value": "â€‡5.70G/5.70Gâ€‡[02:15&lt;00:00,â€‡42.5MB/s]"
          }
        },
        "51befa7ea9444beb974cd898fd269c49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd0d238272494a9ebab48d9f9b3cc07f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1ea87cf2c6346db987d9ebe67d970e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fec812d653f43aab6daef1ad96b25bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b47182ca29c4efba3d1a985bdd6154b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9217b9e57e134811a71c5689dc10dfb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8393a23d15454a18bbd2daefb7880047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60745962f179450ea4d09848cd469a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60d5707fab6b4f1cb693caba407ca242",
              "IPY_MODEL_c63f9a8cfc4347c29716689640b82438",
              "IPY_MODEL_171067bb692449deb203d823aaf354ae"
            ],
            "layout": "IPY_MODEL_4c0e101302144196834f21146ae86a56"
          }
        },
        "60d5707fab6b4f1cb693caba407ca242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87a9db0c3e1342718d2a92a3331b931e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e5f319c7991844e78f5f191e022352eb",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "c63f9a8cfc4347c29716689640b82438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9416cc1dc4d2499aa80ed637ecb2524c",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca1bf7a5cb9543f3a6e5d597c99da7cf",
            "value": 239
          }
        },
        "171067bb692449deb203d823aaf354ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c00c50c3e304452993bc14864fd803e1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5c1eea500ca6417e8633e177b7e454f0",
            "value": "â€‡239/239â€‡[00:00&lt;00:00,â€‡11.1kB/s]"
          }
        },
        "4c0e101302144196834f21146ae86a56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a9db0c3e1342718d2a92a3331b931e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f319c7991844e78f5f191e022352eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9416cc1dc4d2499aa80ed637ecb2524c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca1bf7a5cb9543f3a6e5d597c99da7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c00c50c3e304452993bc14864fd803e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c1eea500ca6417e8633e177b7e454f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ca05f7a7f2c4a6b9411d932a581b96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_557ccd6d1129493390e9de5af5047803",
              "IPY_MODEL_aa8c7b1f23954bcdb6b6b5307231f324",
              "IPY_MODEL_07a37e2cd57c40f291c453252946d7ae"
            ],
            "layout": "IPY_MODEL_44f869ff4bbd4774b870a25f1c5ed7d3"
          }
        },
        "557ccd6d1129493390e9de5af5047803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feff1dc3c37440c5a1457c4d6fae2814",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fb05393aac774c8196da8d2cca207f97",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "aa8c7b1f23954bcdb6b6b5307231f324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c2b659c738846818fd669d59ffea530",
            "max": 55493,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5e1e6c9f11f460ba59ebe947bd9c36a",
            "value": 55493
          }
        },
        "07a37e2cd57c40f291c453252946d7ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c85585806d741a88a99732ba74266b8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2ff3472c871842eabb81b1963e59fd63",
            "value": "â€‡55.5k/55.5kâ€‡[00:00&lt;00:00,â€‡2.33MB/s]"
          }
        },
        "44f869ff4bbd4774b870a25f1c5ed7d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feff1dc3c37440c5a1457c4d6fae2814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb05393aac774c8196da8d2cca207f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c2b659c738846818fd669d59ffea530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5e1e6c9f11f460ba59ebe947bd9c36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c85585806d741a88a99732ba74266b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ff3472c871842eabb81b1963e59fd63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bc08a39aa144c3391e9152ab590d345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9d3ca662f2e479a83d0fbbd40cb2cdd",
              "IPY_MODEL_5c9c61b46fd94e8982fef8dc23c8835d",
              "IPY_MODEL_bd012dbe82844efebf286fdfe6698685"
            ],
            "layout": "IPY_MODEL_ecf789c2c2054120a7470a7f1c2de51e"
          }
        },
        "f9d3ca662f2e479a83d0fbbd40cb2cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0875f4cfb3e04b72870389ade4aca0dc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4f2247c6f3ab484e93c13ea16407784a",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "5c9c61b46fd94e8982fef8dc23c8835d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4d6416795d046a69279025141db9028",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8db8ffc5db77427080a6adeff922718d",
            "value": 17209920
          }
        },
        "bd012dbe82844efebf286fdfe6698685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66e1a997a07341dc9e433aeee69796a1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7e304840b3194b63a35429312f60bbd0",
            "value": "â€‡17.2M/17.2Mâ€‡[00:00&lt;00:00,â€‡45.4MB/s]"
          }
        },
        "ecf789c2c2054120a7470a7f1c2de51e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0875f4cfb3e04b72870389ade4aca0dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2247c6f3ab484e93c13ea16407784a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4d6416795d046a69279025141db9028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8db8ffc5db77427080a6adeff922718d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66e1a997a07341dc9e433aeee69796a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e304840b3194b63a35429312f60bbd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d8e553c2da34ea0b39b8876172feacc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f68b4512f73047a4a34795c4afb8c02e",
              "IPY_MODEL_cd40dcff85454a668104c90c7f7df805",
              "IPY_MODEL_913472fdbb59469698c710707ab23ef9"
            ],
            "layout": "IPY_MODEL_b5224851afa040f49ad1d627cc1a770c"
          }
        },
        "f68b4512f73047a4a34795c4afb8c02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ba82e790b954e78b5807e82c4e97e21",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7188c0a589c54560ae13f9d438a211d1",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "cd40dcff85454a668104c90c7f7df805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a7535c05c394abf80bc1421bf5aaff5",
            "max": 454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39763d4b0744409db567dcc5792d6a4d",
            "value": 454
          }
        },
        "913472fdbb59469698c710707ab23ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d91a18b3322c47159f971b4fe6101228",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_80b51d6d9e66498b8b830282d5ea678d",
            "value": "â€‡454/454â€‡[00:00&lt;00:00,â€‡31.8kB/s]"
          }
        },
        "b5224851afa040f49ad1d627cc1a770c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ba82e790b954e78b5807e82c4e97e21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7188c0a589c54560ae13f9d438a211d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a7535c05c394abf80bc1421bf5aaff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39763d4b0744409db567dcc5792d6a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d91a18b3322c47159f971b4fe6101228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80b51d6d9e66498b8b830282d5ea678d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b10a9ec495a94fd08076841eb67a9e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_306412737a9c4098a27329966f3f364c",
              "IPY_MODEL_51268827e9d44ce5844f2959646355e9",
              "IPY_MODEL_cae52970160a4a52b3d4a52deda0d96d"
            ],
            "layout": "IPY_MODEL_35e697a93d4b4040a5b27d67987a2bb6"
          }
        },
        "306412737a9c4098a27329966f3f364c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_014be59294894ed6bc68f839cf3de5e9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7c174a9af7624b8584fd63ecc195fd31",
            "value": "unified_chip2.jsonl:â€‡100%"
          }
        },
        "51268827e9d44ce5844f2959646355e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c8ae3592bca4bc0b091b7db4b025c44",
            "max": 95645860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60144d2c919744f7b7934c9d523b523a",
            "value": 95645860
          }
        },
        "cae52970160a4a52b3d4a52deda0d96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8459c680f4d4e46a156714642178fe4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_54862b67e81547b197560323e3fedc08",
            "value": "â€‡95.6M/95.6Mâ€‡[00:00&lt;00:00,â€‡224MB/s]"
          }
        },
        "35e697a93d4b4040a5b27d67987a2bb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "014be59294894ed6bc68f839cf3de5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c174a9af7624b8584fd63ecc195fd31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c8ae3592bca4bc0b091b7db4b025c44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60144d2c919744f7b7934c9d523b523a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8459c680f4d4e46a156714642178fe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54862b67e81547b197560323e3fedc08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0780c6be64c46e99bdc40a6044d518d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ba8c5c7ab9e4552907ca55247d510e2",
              "IPY_MODEL_3a213a5a54b94b14a95a439b5950754b",
              "IPY_MODEL_12ef112247ee4464a9af2496afd2ca56"
            ],
            "layout": "IPY_MODEL_66427fa7a07a4cc6befa8f4ddf863487"
          }
        },
        "1ba8c5c7ab9e4552907ca55247d510e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22ae3abacb844fe2b30faff45bb5c1ff",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_63a697198d7c4eae8fbe7b304f2f9e21",
            "value": "Generatingâ€‡trainâ€‡split:â€‡"
          }
        },
        "3a213a5a54b94b14a95a439b5950754b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a02115f60154e6e9a5cc85bddba58b9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_988bc7535aba4886adff9a8aaac8ba55",
            "value": 1
          }
        },
        "12ef112247ee4464a9af2496afd2ca56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6c07f50c49f4d6aa3783b535e4c5c06",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c9f98890e58d4b91a5b10d4acf765b4f",
            "value": "â€‡210289/0â€‡[00:00&lt;00:00,â€‡268879.27â€‡examples/s]"
          }
        },
        "66427fa7a07a4cc6befa8f4ddf863487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22ae3abacb844fe2b30faff45bb5c1ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a697198d7c4eae8fbe7b304f2f9e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a02115f60154e6e9a5cc85bddba58b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "988bc7535aba4886adff9a8aaac8ba55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6c07f50c49f4d6aa3783b535e4c5c06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9f98890e58d4b91a5b10d4acf765b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c78a6c11d9124e5a92920422d122c852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_287cc5d4be704e70b9590a67725013ad",
              "IPY_MODEL_4cf101f8733e440ca126ed0128581f8e",
              "IPY_MODEL_2788b87a6db64edf987ea456f2d7269a"
            ],
            "layout": "IPY_MODEL_749b7205bc35409196003d174ec44375"
          }
        },
        "287cc5d4be704e70b9590a67725013ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_536152188fd9436fbc936f46aed55e83",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d039da580f404715aca774ea535e9c71",
            "value": "Applyingâ€‡chatâ€‡templateâ€‡toâ€‡trainâ€‡datasetâ€‡(num_proc=4):â€‡100%"
          }
        },
        "4cf101f8733e440ca126ed0128581f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ed9f2257feb45e09d68cd0b96082a1d",
            "max": 21029,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b394c083a144afe9f785e48a31cedb3",
            "value": 21029
          }
        },
        "2788b87a6db64edf987ea456f2d7269a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad0d75c3655e418fb4dcbafd0a639632",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c68c4c0fc48c42548e7e399a0f7485f7",
            "value": "â€‡21029/21029â€‡[00:04&lt;00:00,â€‡16271.39â€‡examples/s]"
          }
        },
        "749b7205bc35409196003d174ec44375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "536152188fd9436fbc936f46aed55e83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d039da580f404715aca774ea535e9c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ed9f2257feb45e09d68cd0b96082a1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b394c083a144afe9f785e48a31cedb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad0d75c3655e418fb4dcbafd0a639632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c68c4c0fc48c42548e7e399a0f7485f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43e589f13119463ab3f25cbab46d10e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7954981b42c64509aad1ead118cba61d",
              "IPY_MODEL_9c99c79f2f5e4afbae5c3b1cc342e700",
              "IPY_MODEL_385eb08545164b9f8eb455fc4ef6e097"
            ],
            "layout": "IPY_MODEL_7b22ea5fd5ca444280d8cf8a43136099"
          }
        },
        "7954981b42c64509aad1ead118cba61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1023af6301f44ebeab7a8d899eb58522",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_52a6557e482d446ea1e98ffa83441e9b",
            "value": "Tokenizingâ€‡trainâ€‡datasetâ€‡(num_proc=4):â€‡100%"
          }
        },
        "9c99c79f2f5e4afbae5c3b1cc342e700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cb5711d02dd43218e4955e1be601e54",
            "max": 21029,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85e9bbf72bb6422591fe9d84e6acd391",
            "value": 21029
          }
        },
        "385eb08545164b9f8eb455fc4ef6e097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f889097fad314f59ac0f27c097ac28ae",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_57af46dfdba74fa58bcf7db42a378f60",
            "value": "â€‡21029/21029â€‡[00:12&lt;00:00,â€‡2299.60â€‡examples/s]"
          }
        },
        "7b22ea5fd5ca444280d8cf8a43136099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1023af6301f44ebeab7a8d899eb58522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a6557e482d446ea1e98ffa83441e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cb5711d02dd43218e4955e1be601e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85e9bbf72bb6422591fe9d84e6acd391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f889097fad314f59ac0f27c097ac28ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57af46dfdba74fa58bcf7db42a378f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b8ef0c9583b4879a7f0ae04a60fb39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecb68987b074428380ea39a71ea4560c",
              "IPY_MODEL_995a7668bdc74fb8a4fdec8ca802db4d",
              "IPY_MODEL_1c64b2646537410693cf41f077b9f40f"
            ],
            "layout": "IPY_MODEL_ae0ace153e6e42429bc80707effc7c97"
          }
        },
        "ecb68987b074428380ea39a71ea4560c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6630d0e47d2842f7a5261f89e9235ae4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_996c93f8e21649fea2720ab9cb8e21fc",
            "value": "Tokenizingâ€‡trainâ€‡datasetâ€‡(num_proc=4):â€‡100%"
          }
        },
        "995a7668bdc74fb8a4fdec8ca802db4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7678cabf31849e493628c4fb260b98e",
            "max": 21029,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16129167e0be4d77989b5cfb8d840bd3",
            "value": 21029
          }
        },
        "1c64b2646537410693cf41f077b9f40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b7470b87b804d868f5430769c230592",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b43cf65240104debb35756801cee867b",
            "value": "â€‡21029/21029â€‡[00:04&lt;00:00,â€‡2800.69â€‡examples/s]"
          }
        },
        "ae0ace153e6e42429bc80707effc7c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6630d0e47d2842f7a5261f89e9235ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "996c93f8e21649fea2720ab9cb8e21fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7678cabf31849e493628c4fb260b98e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16129167e0be4d77989b5cfb8d840bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b7470b87b804d868f5430769c230592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b43cf65240104debb35756801cee867b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2650669091e449f7a12f3ead7d4c20ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3dc8d64196b14f4197cd3339742a34bc",
              "IPY_MODEL_7158ed68d61d4d80b2e3747c390fda80",
              "IPY_MODEL_641623b174014cf1a971e3e09acf9164"
            ],
            "layout": "IPY_MODEL_a2de6c359c5449b19f2f20534b3cddfc"
          }
        },
        "3dc8d64196b14f4197cd3339742a34bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fdf71c34276475b9f06d1f0f3df43a0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0a3d0e0a03d047a8b90bbe9d98c26f3f",
            "value": "config.json:â€‡100%"
          }
        },
        "7158ed68d61d4d80b2e3747c390fda80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09299fa4aa0e41ce87f9b27df73600f1",
            "max": 1520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e7bcee3a16949b3a6ea93bba773e43f",
            "value": 1520
          }
        },
        "641623b174014cf1a971e3e09acf9164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92a1f52385ef425eafd685fc7dc351c7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e3a2d60dd4c24aacb6425b4bb0ee066e",
            "value": "â€‡1.52k/1.52kâ€‡[00:00&lt;00:00,â€‡31.3kB/s]"
          }
        },
        "a2de6c359c5449b19f2f20534b3cddfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fdf71c34276475b9f06d1f0f3df43a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a3d0e0a03d047a8b90bbe9d98c26f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09299fa4aa0e41ce87f9b27df73600f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e7bcee3a16949b3a6ea93bba773e43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92a1f52385ef425eafd685fc7dc351c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3a2d60dd4c24aacb6425b4bb0ee066e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83a069d07e62433fbdeccd446629f933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f598a003c3a46d8b1bc9b9e09961d8f",
              "IPY_MODEL_c8759c84b0cc41d1b26c9ebb8d1c1bd8",
              "IPY_MODEL_6d472692e8ef41568614da4c8524ac90"
            ],
            "layout": "IPY_MODEL_06831f66e5ea482e93837ee00fce9413"
          }
        },
        "7f598a003c3a46d8b1bc9b9e09961d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_559908d1ab2247e693e273b9da52c5a7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cd3fc5a7061c4ce6b66c3ee70b0dc4ab",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "c8759c84b0cc41d1b26c9ebb8d1c1bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4210ab573d8e4eb586989b74b51c7244",
            "max": 1027676737,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5da5844a476641679e995289c3e6701c",
            "value": 1027676737
          }
        },
        "6d472692e8ef41568614da4c8524ac90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7df04b49b6d14d7fb4900c315c1d9369",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6186d0196b584ebc9debb77ed3835fc3",
            "value": "â€‡1.03G/1.03Gâ€‡[00:24&lt;00:00,â€‡42.3MB/s]"
          }
        },
        "06831f66e5ea482e93837ee00fce9413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "559908d1ab2247e693e273b9da52c5a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd3fc5a7061c4ce6b66c3ee70b0dc4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4210ab573d8e4eb586989b74b51c7244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5da5844a476641679e995289c3e6701c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7df04b49b6d14d7fb4900c315c1d9369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6186d0196b584ebc9debb77ed3835fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85cacea45f094105921c3430f0f9ff16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4120cf65fc154f7aa0f339a0ca9ccf04",
              "IPY_MODEL_a397ac9ead5644e79e3201669253bbee",
              "IPY_MODEL_a2ab9f82bf8949df8fcec7067153ced0"
            ],
            "layout": "IPY_MODEL_472ff429959940a09c8ba6d08b50991c"
          }
        },
        "4120cf65fc154f7aa0f339a0ca9ccf04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c3c7a2269ab4099b8a9232ccd358fd7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_056f3c7e217140e384b934511108a211",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "a397ac9ead5644e79e3201669253bbee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bd03db6056546698822b83c0aae3519",
            "max": 234,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28eef2874a974ffd887bbed667a44161",
            "value": 234
          }
        },
        "a2ab9f82bf8949df8fcec7067153ced0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a97ff63c9116491284dcc086330a68a9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_56f84a989c0b4637a5f4695f7e255d03",
            "value": "â€‡234/234â€‡[00:00&lt;00:00,â€‡12.0kB/s]"
          }
        },
        "472ff429959940a09c8ba6d08b50991c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c3c7a2269ab4099b8a9232ccd358fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "056f3c7e217140e384b934511108a211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bd03db6056546698822b83c0aae3519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28eef2874a974ffd887bbed667a44161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a97ff63c9116491284dcc086330a68a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f84a989c0b4637a5f4695f7e255d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9867e25e17a24d59935f0fbed4aed30e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3edc46c5a96d4e9c9fea69c1e180abd4",
              "IPY_MODEL_1efa9da14cd94d0e9e50d97fa326fe74",
              "IPY_MODEL_86febc74651a47ffb4d02ee4e34340de"
            ],
            "layout": "IPY_MODEL_eeff3f5036cb4642a6cdbf34f1342c07"
          }
        },
        "3edc46c5a96d4e9c9fea69c1e180abd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2161b9b632d4c2e9ad5667c189ce7bf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_52eb5d70f7d540c28ce8e39d7eb3569e",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "1efa9da14cd94d0e9e50d97fa326fe74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67ea2cdb7b424448882e76b8f7fa767d",
            "max": 54674,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6df34bb109bc49909b15b58a76027d04",
            "value": 54674
          }
        },
        "86febc74651a47ffb4d02ee4e34340de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb452d291e9f42c5ba93f4a7a4a17ca7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e1cd8b04457b4943b6027cde16089378",
            "value": "â€‡54.7k/54.7kâ€‡[00:00&lt;00:00,â€‡3.12MB/s]"
          }
        },
        "eeff3f5036cb4642a6cdbf34f1342c07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2161b9b632d4c2e9ad5667c189ce7bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52eb5d70f7d540c28ce8e39d7eb3569e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67ea2cdb7b424448882e76b8f7fa767d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6df34bb109bc49909b15b58a76027d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb452d291e9f42c5ba93f4a7a4a17ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1cd8b04457b4943b6027cde16089378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "358313f3922d439fa511a83f01faa2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28c1d59998ea4c278f75b9f1fb8f62ca",
              "IPY_MODEL_e730ff355cb4498e83cbc92e5edd7274",
              "IPY_MODEL_1705fd65a03a4e4e9b5d9b5a09691a2f"
            ],
            "layout": "IPY_MODEL_1e9a88491bf6473db41743d92ff3dbe7"
          }
        },
        "28c1d59998ea4c278f75b9f1fb8f62ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e374cbbaa1849f5856bae0e3023352e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c5c42f84490340e78c0f972c3108ed47",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "e730ff355cb4498e83cbc92e5edd7274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ece92b44074841bda3a29889fa0363",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61ec012bc6b242f39b8b67e47db3b6b4",
            "value": 17209920
          }
        },
        "1705fd65a03a4e4e9b5d9b5a09691a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcf382a7918641ebb174928df69ce161",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_00e10167b3164042bee7a2495181e2f0",
            "value": "â€‡17.2M/17.2Mâ€‡[00:00&lt;00:00,â€‡43.4MB/s]"
          }
        },
        "1e9a88491bf6473db41743d92ff3dbe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e374cbbaa1849f5856bae0e3023352e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5c42f84490340e78c0f972c3108ed47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6ece92b44074841bda3a29889fa0363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61ec012bc6b242f39b8b67e47db3b6b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcf382a7918641ebb174928df69ce161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00e10167b3164042bee7a2495181e2f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9d5827a6d9648fd812228e9af59495b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9aa215287dd4b6aa89530e7454be6e0",
              "IPY_MODEL_713ff98c8a4e4703a843ebf5fdcf7bc7",
              "IPY_MODEL_1e7e6d5390804c12a0d14481686fdaec"
            ],
            "layout": "IPY_MODEL_9045d8eca08b4889a8706893de6702b9"
          }
        },
        "f9aa215287dd4b6aa89530e7454be6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_201b0ed743184b73ae61038d5552c233",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_221f4d520dc7498fad01f741688e7606",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "713ff98c8a4e4703a843ebf5fdcf7bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8654cb9bfe994d0fa53a3dbde9a2e38e",
            "max": 454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec1df11660394fc69591c3f1c946b406",
            "value": 454
          }
        },
        "1e7e6d5390804c12a0d14481686fdaec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_369110b87c79404b9e4e9dea18d3ab99",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_42abe8c63c4d46bdbc7077f0d546f2d8",
            "value": "â€‡454/454â€‡[00:00&lt;00:00,â€‡29.6kB/s]"
          }
        },
        "9045d8eca08b4889a8706893de6702b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "201b0ed743184b73ae61038d5552c233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "221f4d520dc7498fad01f741688e7606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8654cb9bfe994d0fa53a3dbde9a2e38e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec1df11660394fc69591c3f1c946b406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "369110b87c79404b9e4e9dea18d3ab99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42abe8c63c4d46bdbc7077f0d546f2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}